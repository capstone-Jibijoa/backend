import os
import logging
import re 
import pandas as pd
from typing import List, Dict, Any, Tuple
from collections import Counter, defaultdict
from concurrent.futures import ThreadPoolExecutor, as_completed
import numpy as np
from sklearn.cluster import DBSCAN

# --- LLM ê´€ë ¨ ---
from llm import generate_stats_summary, generate_demographic_summary

# --- Repository & Helpers ---
from repository import PanelRepository, VectorRepository 
from search_helpers import initialize_embeddings 
from utils import (
    calculate_distribution,
    find_top_category,
    WELCOME_OBJECTIVE_FIELDS,
    get_age_group
)

# --- Mappings & Rules ---
from mapping_rules import (
    get_field_mapping, 
    QPOLL_FIELD_TO_TEXT, 
    QPOLL_ANSWER_TEMPLATES, 
    VALUE_TRANSLATION_MAP, 
    find_target_columns_dynamic,
    FIELD_NAME_MAP,
    FIELD_ALIAS_MAP
)
from semantic_router import router 

def _clean_label(text: Any, max_length: int = 25) -> str:
    """ë¼ë²¨ ì •ì œ í•¨ìˆ˜"""
    if not text: return ""
    text_str = str(text)
    cleaned = re.sub(r'\([^)]*\)', '', text_str).strip()
    cleaned = " ".join(cleaned.split())
    if len(cleaned) > max_length:
        return cleaned[:max_length] + ".."
    return cleaned

def _extract_core_value(field_name: str, sentence: str) -> str:
    """ë¬¸ì¥í˜• ë°ì´í„°ì—ì„œ í•µì‹¬ ë‹µë³€ë§Œ ì¶”ì¶œ"""
    if not sentence: return ""
    
    if field_name == "ott_count":
        match = re.search(r'(\d+ê°œ|ì´ìš© ì•ˆ í•¨|ì—†ìŒ)', sentence)
        if match: return match.group(1)
    elif field_name == "skincare_spending":
        match = re.search(r'(\d+ë§Œ\s*ì›|\d+~\d+ë§Œ\s*ì›|\d+ì›)', sentence)
        if match: return match.group(1)
    
    template = QPOLL_ANSWER_TEMPLATES.get(field_name)
    if template:
        try:
            pattern_str = re.escape(template)
            pattern_str = pattern_str.replace(re.escape("{answer_str}"), r"(.*?)")
            pattern_str = pattern_str.replace(r"\(ì´\)ë‹¤", r"(?:ì´)?ë‹¤")
            pattern_str = pattern_str.replace(r"\(ìœ¼\)ë¡œ", r"(?:ìœ¼)?ë¡œ")
            pattern_str = pattern_str.replace(r"\(ê°€\)", r"(?:ê°€)?")
            pattern_str = pattern_str.replace(r"\ ", r"\s*")
            match = re.search(pattern_str, sentence)
            if match:
                return _clean_label(match.group(1))
        except: pass

    return _clean_label(sentence)

def _limit_distribution_top_k(distribution: Dict[str, float], k: int = 10) -> Dict[str, float]:
    """[ë§‰ëŒ€ ì°¨íŠ¸ìš©] ìƒìœ„ Kê°œë§Œ ë‚¨ê¸°ê³  ë‚˜ë¨¸ì§€ëŠ” 'ê¸°íƒ€'ë¡œ í•©ì¹©ë‹ˆë‹¤."""
    if not distribution or len(distribution) <= k:
        return distribution
    sorted_items = sorted(distribution.items(), key=lambda x: x[1], reverse=True)
    top_items = dict(sorted_items[:k])
    other_sum = sum(v for _, v in sorted_items[k:])
    if other_sum > 0:
        top_items['ê¸°íƒ€'] = round(other_sum, 1)
    return top_items

def _sort_distribution(distribution: Dict[str, float]) -> Dict[str, float]:
    """[ì›í˜• ì°¨íŠ¸ìš©] 'ê¸°íƒ€'ë¡œ ë¬¶ì§€ ì•Šê³  ì „ì²´ë¥¼ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤."""
    if not distribution: return {}
    return dict(sorted(distribution.items(), key=lambda x: x[1], reverse=True))

def get_field_distribution_from_db(field_name: str, limit: int = 50) -> Dict[str, float]:
    """PostgreSQL ì§‘ê³„ (Repository ìœ„ì„)"""
    
    if field_name == "birth_year":
        query = f"""
            WITH age_groups AS (
                SELECT 
                    CASE 
                        WHEN (date_part('year', CURRENT_DATE) - (structured_data->>'birth_year')::int) < 20 THEN '10ëŒ€'
                        WHEN (date_part('year', CURRENT_DATE) - (structured_data->>'birth_year')::int) < 30 THEN '20ëŒ€'
                        WHEN (date_part('year', CURRENT_DATE) - (structured_data->>'birth_year')::int) < 40 THEN '30ëŒ€'
                        WHEN (date_part('year', CURRENT_DATE) - (structured_data->>'birth_year')::int) < 50 THEN '40ëŒ€'
                        WHEN (date_part('year', CURRENT_DATE) - (structured_data->>'birth_year')::int) < 60 THEN '50ëŒ€'
                        ELSE '60ëŒ€ ì´ìƒ'
                    END as age_group
                FROM welcome_meta2
                WHERE structured_data->>'birth_year' IS NOT NULL
            )
            SELECT age_group, COUNT(*), ROUND(COUNT(*) * 100.0 / SUM(COUNT(*)) OVER (), 1)
            FROM age_groups GROUP BY age_group ORDER BY 3 DESC LIMIT {limit}
        """
    elif field_name == "children_count":
        query = f"""
            SELECT 
                CONCAT((structured_data->>'{field_name}')::numeric::int, 'ëª…') as val, 
                COUNT(*) as count,
                ROUND(COUNT(*) * 100.0 / SUM(COUNT(*)) OVER (), 1) as percentage
            FROM welcome_meta2
            WHERE structured_data->>'{field_name}' IS NOT NULL
            GROUP BY val ORDER BY percentage DESC LIMIT {limit}
        """
    else:
        query = f"""
            SELECT structured_data->>'{field_name}', COUNT(*), ROUND(COUNT(*) * 100.0 / SUM(COUNT(*)) OVER (), 1)
            FROM welcome_meta2 WHERE structured_data->>'{field_name}' IS NOT NULL
            GROUP BY 1 ORDER BY 3 DESC LIMIT {limit}
        """
    
    return PanelRepository.aggregate_field(query)
    
def get_qpoll_distribution_from_db(qpoll_field: str, limit: int = 50) -> Dict[str, float]:
    """Qdrant ì§‘ê³„ (Repository ìœ„ì„)"""
    question_text = QPOLL_FIELD_TO_TEXT.get(qpoll_field)
    if not question_text: return {}
    
    all_points = VectorRepository.fetch_qpoll_by_question(question_text)
    
    if not all_points: return {}
    extracted_values = []
    
    for p in all_points:
        if p.payload and p.payload.get("sentence"):
            raw_sentence = p.payload.get("sentence")
            core_val = _extract_core_value(qpoll_field, raw_sentence)
            if core_val: extracted_values.append(core_val)
    
    if not extracted_values: return {}
    
    val_counts = Counter(extracted_values)
    total = len(extracted_values)
    return {k: round((v / total) * 100, 1) for k, v in val_counts.most_common(limit)}

def create_chart_data_optimized(
    keyword: str,
    field_name: str,
    korean_name: str,
    panels_data: List[Dict],
    use_full_db: bool = False,
    max_categories: int = 50
) -> Dict:
    """ì°¨íŠ¸ ë°ì´í„° ìƒì„± (SQL ì§‘ê³„ ìš°ì„ )"""
    
    # 1. DB ì „ì²´ ì§‘ê³„ê°€ í•„ìš”í•œ ê²½ìš° (ë‚˜ì´, ìë…€ ìˆ˜ ë“±)
    if use_full_db or field_name == "children_count":
        logging.info(f"       â†’ DB ì§‘ê³„ë¡œ '{field_name}' ë¶„ì„")
        distribution = get_field_distribution_from_db(field_name, max_categories)
        if not distribution: return {"topic": korean_name, "ratio": "0.0%", "chart_data": [], "description": "ë°ì´í„° ì—†ìŒ"}
        
        cleaned_distribution = defaultdict(float)
        for k, v in distribution.items(): cleaned_distribution[_clean_label(k)] += v
        
        final_distribution = _limit_distribution_top_k(dict(cleaned_distribution), k=8)
        top_category, top_ratio = find_top_category(final_distribution)
        
        return {
            "topic": f"{korean_name} ë¶„í¬",
            "description": f"ì „ì²´ ê¸°ì¤€: {top_ratio}%ê°€ '{top_category}'ì…ë‹ˆë‹¤.",
            "ratio": f"{top_ratio}%",
            "chart_data": [{"label": korean_name, "values": final_distribution}],
            "field": field_name 
        }

    # 2. ê²€ìƒ‰ ê²°ê³¼ ë‚´ ì§‘ê³„ (ë¦¬ìŠ¤íŠ¸í˜• í•„ë“œ ë“±)
    else:
        values = []
        
        if field_name == 'birth_year':
            values = [get_age_group(item.get(field_name)) for item in panels_data if item.get(field_name)]
        else:
            raw_values = [item.get(field_name) for item in panels_data if item.get(field_name)]
            for val in raw_values:
                if isinstance(val, list):
                    for v in val:
                        cleaned = _clean_label(v)
                        if cleaned: values.append(cleaned)
                elif val is not None:
                    cleaned = _clean_label(val)
                    if cleaned: values.append(cleaned)
        
        if not values: return {"topic": korean_name, "description": "ë°ì´í„° ë¶€ì¡±", "ratio": "0.0%", "chart_data": [], "field": field_name}
        
        distribution = calculate_distribution(values)
        final_distribution = _limit_distribution_top_k(distribution, k=12)
        top_category, top_ratio = find_top_category(final_distribution)
        
        return {
            "topic": f"{korean_name} ë¶„í¬",
            "description": f"ê²€ìƒ‰ ê²°ê³¼: {top_ratio}%ê°€ '{top_category}'ì…ë‹ˆë‹¤.",
            "ratio": f"{top_ratio}%",
            "chart_data": [{"label": korean_name, "values": final_distribution}],
            "field": field_name
        }

def create_qpoll_chart_data(qpoll_field: str, max_categories: int = 50) -> Dict:
    """Q-Poll ì°¨íŠ¸ ë°ì´í„° ìƒì„±"""
    question_text = QPOLL_FIELD_TO_TEXT.get(qpoll_field, qpoll_field) 
    distribution = get_qpoll_distribution_from_db(qpoll_field, max_categories)
    
    if not distribution: return {"topic": question_text, "ratio": "0.0%", "chart_data": [], "description": "ë°ì´í„° ì—†ìŒ", "field": qpoll_field}
    
    top_category, top_ratio = find_top_category(distribution)
    
    template = QPOLL_ANSWER_TEMPLATES.get(qpoll_field)
    if template and top_category != "ê¸°íƒ€":
        try:
            formatted_answer = template.format(answer_str=f"'{top_category}'")
            description = f"ê°€ì¥ ë§ì€ ì‘ë‹µìëŠ” {formatted_answer} ({top_ratio}%)"
        except: description = f"ê°€ì¥ ë§ì€ ì‘ë‹µì€ '{top_category}'({top_ratio}%)ì…ë‹ˆë‹¤."
    else: description = f"ê°€ì¥ ë§ì€ ì‘ë‹µì€ '{top_category}'({top_ratio}%)ì…ë‹ˆë‹¤."

    return {
        "topic": question_text, 
        "description": description,
        "ratio": f"{top_ratio}%",
        "chart_data": [{"label": question_text, "values": distribution}],
        "field": qpoll_field
    }

def calculate_column_stats(df: pd.DataFrame, columns: List[str]) -> str:
    """
    DataFrameì—ì„œ íŠ¹ì • ì»¬ëŸ¼ë“¤ì˜ ë¶„í¬ë¥¼ ê³„ì‚°í•˜ì—¬ í…ìŠ¤íŠ¸ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    stats_report = []
    
    for col in columns:
        if col not in df.columns:
            continue
            
        korean_name = FIELD_NAME_MAP.get(col, QPOLL_FIELD_TO_TEXT.get(col, col))
        
        try:
            # ê²°ì¸¡ì¹˜ ì œì™¸
            valid_series = df[col].dropna()
            total_count = len(valid_series)
            if total_count == 0:
                continue

            # ë¦¬ìŠ¤íŠ¸í˜• ë°ì´í„° ì²˜ë¦¬
            if valid_series.apply(lambda x: isinstance(x, list)).any():
                exploded = valid_series.explode()
                counts = exploded.value_counts().head(5)
            else:
                counts = valid_series.value_counts().head(5)

            report_lines = [f"\nğŸ“Œ [{korean_name}] ({col}) ë¶„í¬ (ìƒìœ„ 5ê°œ):"]
            for val, count in counts.items():
                percent = (count / len(df)) * 100 # ì „ì²´ ëª¨ìˆ˜ ëŒ€ë¹„ ë¹„ìœ¨
                report_lines.append(f"  - {val}: {count}ëª… ({percent:.1f}%)")
            
            stats_report.append("\n".join(report_lines))
            
        except Exception as e:
            logging.error(f"í†µê³„ ê³„ì‚° ì¤‘ ì—ëŸ¬ ({col}): {e}")
            
    return "\n".join(stats_report)

async def get_ai_summary(panel_ids: List[str], question: str):
    """
    1. Repositoryì—ì„œ ë°ì´í„° ë¡œë“œ
    2. ë™ì  ë§¤í•‘ (ì§ˆë¬¸ -> ì»¬ëŸ¼)
    3. í†µê³„ ê³„ì‚° (Python)
    4. LLM ìš”ì•½ ìƒì„±
    """
    target_ids = panel_ids[:1000]
    
    panels_data = PanelRepository.fetch_panels_data(target_ids)
    
    if not panels_data:
        return {"summary": "ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.", "used_fields": []}

    df = pd.DataFrame(panels_data)
    target_columns = find_target_columns_dynamic(question)
    
    if not target_columns:
        stats_context = calculate_column_stats(df, ['gender', 'birth_year', 'region_major'])
        target_columns = ['ê¸°ë³¸ ì¸êµ¬í†µê³„']
    else:
        stats_context = calculate_column_stats(df, target_columns)

    summary_text = generate_stats_summary(question, stats_context)

    return {
        "summary": summary_text,
        "used_fields": target_columns
    }

async def get_search_result_overview(query: str, panel_ids: List[str], classification: Dict) -> str:
    """
    Lite ëª¨ë“œ ê²€ìƒ‰ ê²°ê³¼ì— ëŒ€í•œ í…ìŠ¤íŠ¸ ìš”ì•½ì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    if not panel_ids:
        return "ê²€ìƒ‰ëœ íŒ¨ë„ì´ ì—†ìŠµë‹ˆë‹¤."

    sample_ids = panel_ids[:1000]
    
    panels_data = PanelRepository.fetch_panels_data(sample_ids)
    
    if not panels_data:
        return "ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    df = pd.DataFrame(panels_data)
    
    stats_context = [] 
    
    # 1. íƒ€ê²Ÿ í•„ë“œ í†µê³„
    target_field = classification.get('target_field')
    if target_field and target_field in df.columns:
        counts = df[target_field].value_counts(normalize=True).head(3)
        if not counts.empty:
            korean_name = FIELD_NAME_MAP.get(target_field, target_field)
            items_str = []
            for val, ratio in counts.items():
                items_str.append(f"{val}({ratio*100:.1f}%)")
            distribution_desc = ", ".join(items_str)
            stats_context.append(f"[{korean_name} ë¶„í¬]: {distribution_desc}")

    # 2. ì¸êµ¬í†µê³„ (ì„±ë³„, ì—°ë ¹, ì§€ì—­)
    demos = ['gender', 'region_major']
    if 'birth_year' in df.columns:
        df['age_group'] = df['birth_year'].apply(lambda x: get_age_group(x) if x else None)
        age_counts = df['age_group'].value_counts(normalize=True)
        top_ages = age_counts.head(3)
        if not top_ages.empty:
            age_desc = []
            for age, ratio in top_ages.items():
                age_desc.append(f"{age}({ratio*100:.1f}%)")
            stats_context.append(f"[ì—°ë ¹ëŒ€ ë¶„í¬]: {', '.join(age_desc)}")

    for col in demos:
        if col in df.columns:
            top = df[col].value_counts(normalize=True).head(1)
            if not top.empty:
                val, ratio = top.index[0], top.values[0]
                feature = f"{val} ({ratio*100:.1f}%)"
                if ratio >= 0.5: feature += " - ê³¼ë°˜ìˆ˜ ì´ìƒ"
                col_name = FIELD_NAME_MAP.get(col, col)
                stats_context.append(f"[{col_name}]: {feature}")

    # 3. ì†Œë“ ìˆ˜ì¤€
    if 'income_personal_monthly' in df.columns:
        top_income = df['income_personal_monthly'].value_counts(normalize=True).head(1)
        if not top_income.empty and top_income.values[0] > 0.3:
             stats_context.append(f"[ì£¼ìš” ì†Œë“êµ¬ê°„]: {top_income.index[0]} ({top_income.values[0]*100:.1f}%)")

    full_stats_text = "\n".join(stats_context)
    summary = generate_demographic_summary(query, full_stats_text, len(panel_ids))
    
    return summary

def create_crosstab_chart(
    panels_data: List[Dict],
    field1: str,
    field2: str,
    field1_korean: str,
    field2_korean: str,
    max_categories: int = 5
) -> Dict:
    """êµì°¨ ë¶„ì„ ì°¨íŠ¸ ìƒì„±"""
    logging.info(f"       â†’ êµì°¨ ë¶„ì„: '{field1}' vs '{field2}'")
    
    all_values_field2 = []
    for item in panels_data:
        val2 = item.get(field2)
        if not val2: continue
        
        if isinstance(val2, list):
            for v in val2:
                cleaned = _clean_label(v)
                if cleaned: all_values_field2.append(cleaned)
        else:
            cleaned = _clean_label(val2)
            if cleaned: all_values_field2.append(cleaned)
            
    if not all_values_field2:
        return {}

    global_counter = Counter(all_values_field2)
    top_7_keys = [k for k, v in global_counter.most_common(7)]
    top_7_set = set(top_7_keys)

    crosstab_data = {} 

    for item in panels_data:
        val1 = item.get(field1)
        val2 = item.get(field2)
        
        if val1 is None or val2 is None: continue

        raw_key1 = get_age_group(val1) if field1 == 'birth_year' else str(val1)
        key1 = _clean_label(raw_key1)
        
        if key1 not in crosstab_data:
            crosstab_data[key1] = []
            
        values_to_process = val2 if isinstance(val2, list) else [val2]
        
        for v in values_to_process:
            cleaned_v = _clean_label(v)
            if not cleaned_v: continue
            
            if cleaned_v in top_7_set:
                crosstab_data[key1].append(cleaned_v)
            else:
                crosstab_data[key1].append("ê¸°íƒ€")

    if not crosstab_data:
        return {}

    # Pie Chart
    if len(crosstab_data) <= 1:
        only_group = list(crosstab_data.keys())[0]
        distribution = calculate_distribution(crosstab_data[only_group])
        final_distribution = _sort_distribution(distribution)
        
        return {
            "topic": f"{field1_korean}ë³„ {field2_korean} ë¶„í¬ ({only_group})",
            "description": f"'{only_group}' ì§‘ë‹¨ì˜ '{field2_korean}' ë¶„í¬ì…ë‹ˆë‹¤.",
            "chart_type": "pie", 
            "chart_data": [{"label": field2_korean, "values": final_distribution}],
            "fields": [field1, field2]
        }

    # Bar Chart
    chart_values = {}
    sorted_groups = sorted(crosstab_data.keys(), key=lambda k: len(crosstab_data[k]), reverse=True)
    target_groups = sorted_groups[:max_categories]

    for group in target_groups:
        items = crosstab_data[group]
        distribution = calculate_distribution(items)
        chart_values[group] = _limit_distribution_top_k(distribution, k=7)

    return {
        "topic": f"{field1_korean}ë³„ {field2_korean} ë¶„í¬",
        "description": f"'{field1_korean}'ì— ë”°ë¥¸ ì£¼ìš” '{field2_korean}' ë¶„í¬ì…ë‹ˆë‹¤.",
        "chart_type": "crosstab",
        "chart_data": [{"label": f"{field1_korean}ë³„ {field2_korean}", "values": chart_values}],
        "fields": [field1, field2] 
    }

def _analyze_fields_in_parallel(panels_data: List[Dict], candidate_fields: List[Tuple[str, str]]) -> List[Dict]:
    """ë³‘ë ¬ í•„ë“œ ë¶„ì„"""
    field_values = {fname: [] for fname, _ in candidate_fields}
    field_map = dict(candidate_fields)

    for item in panels_data:
        for fname in field_values.keys():
            val = item.get(fname)
            if val is None: continue

            if fname == "birth_year":
                field_values[fname].append(get_age_group(val))
            elif isinstance(val, list):
                for v in val:
                    cleaned = _clean_label(v)
                    if cleaned: field_values[fname].append(cleaned)
            else:
                cleaned = _clean_label(val)
                if cleaned: field_values[fname].append(cleaned)

    results = []
    for fname, vals in field_values.items():
        if not vals: continue
        try:
            dist = calculate_distribution(vals)
            final_dist = _sort_distribution(dist)
            if not final_dist: continue
            
            results.append({
                "field": fname,
                "korean_name": field_map[fname],
                "distribution": final_dist,
            })
        except: pass
    return results

def find_high_ratio_fields_optimized(
    panels_data: List[Dict], 
    exclude_fields: List[str], 
    threshold: float = 50.0,
    max_charts: int = 3
) -> List[Dict]:
    """ë†’ì€ ë¹„ìœ¨ í•„ë“œ ì°¾ê¸° (98% ì´ìƒ ì œì™¸)"""
    candidate_fields = []
    for fname, kname in WELCOME_OBJECTIVE_FIELDS:
        if fname not in exclude_fields:
            candidate_fields.append((fname, kname))
    
    if not candidate_fields: return []
    
    analysis_results = _analyze_fields_in_parallel(panels_data, candidate_fields)
    
    high_ratio_results = []
    for result in analysis_results:
        distribution = result['distribution']
        top_category, top_ratio = find_top_category(distribution)
        
        if top_ratio >= threshold:
            if top_ratio >= 98.0:
                continue

            high_ratio_results.append({
                "field": result['field'],
                "korean_name": result['korean_name'],
                "distribution": distribution,
                "top_category": top_category,
                "top_ratio": top_ratio
            })
    
    high_ratio_results.sort(key=lambda x: x["top_ratio"], reverse=True)
    return high_ratio_results[:max_charts]

def analyze_search_results_optimized(
    query: str,
    classified_keywords: dict,
    panel_id_list: List[str]
) -> Tuple[Dict, int]:
    logging.info(f"ğŸ“Š ë¶„ì„ ì‹œì‘ (ìµœì í™”) - panel_id ìˆ˜: {len(panel_id_list)}ê°œ")
    
    if not panel_id_list:
        return {"main_summary": "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.", "charts": []}, 200
    
    try:
        panels_data = PanelRepository.fetch_panels_data(panel_id_list)

        if not panels_data: return {"main_summary": "ë°ì´í„° ì—†ìŒ", "charts": []}, 200
        fixed_filters = set()
        
        # 1. Demographic Filters í™•ì¸
        demographic_filters = classified_keywords.get('demographic_filters', {})
        if demographic_filters:
            for k, v in demographic_filters.items():
                if not isinstance(v, list) or len(v) == 1:
                    fixed_filters.add(k)
                    mapped_field = FIELD_ALIAS_MAP.get(k)
                    if mapped_field: fixed_filters.add(mapped_field)

        # 2. Structured Filters í™•ì¸
        structured_filters = classified_keywords.get('structured_filters', [])
        for f in structured_filters:
            if f.get('operator') in ['eq', 'like', 'ilike']: 
                 if f.get('field'): fixed_filters.add(f['field'])
    
        target_field = classified_keywords.get('target_field')
        
        if target_field:
            if target_field == 'job_duty_raw':
                logging.info(f"   ğŸ”„ ëŒ€ì²´ í•„ë“œ ì ìš©: job_duty_raw -> job_title_raw")
                target_field = 'job_title_raw'
                classified_keywords['target_field'] = target_field
            elif target_field == 'region_major':
                logging.info(f"   ğŸ”„ ëŒ€ì²´ í•„ë“œ ì ìš©: region_major -> region_minor")
                target_field = 'region_minor'
                classified_keywords['target_field'] = target_field
            elif target_field in ['income_personal_monthly', 'income_household_monthly']:
                logging.info(f"   ğŸ”„ ëŒ€ì²´ í•„ë“œ ì ìš©: {target_field} -> happiest_self_spending")
                target_field = 'happiest_self_spending' 
                classified_keywords['target_field'] = target_field
            elif target_field == 'car_ownership':
                logging.info(f"   ğŸ”„ ëŒ€ì²´ í•„ë“œ ì ìš©: car_ownership -> car_model_raw")
                target_field = 'car_model_raw'
                classified_keywords['target_field'] = target_field
            elif target_field == 'phone_brand_raw':
                logging.info(f"   ğŸ”„ ëŒ€ì²´ í•„ë“œ ì ìš©: phone_brand_raw -> phone_model_raw")
                target_field = 'phone_model_raw'
                classified_keywords['target_field'] = target_field
            elif target_field == 'marital_status':
                logging.info(f"   ğŸ”„ ëŒ€ì²´ í•„ë“œ ì ìš©: marital_status -> children_count")
                target_field = 'children_count'
                classified_keywords['target_field'] = target_field
            else:
                if target_field in fixed_filters:
                    logging.info(f"   ğŸš« '{target_field}'ì— ëŒ€í•œ ëŒ€ì²´ í•„ë“œ ì—†ìŒ -> íƒ€ê²Ÿ í•´ì œí•˜ì—¬ 100% ì°¨íŠ¸ ë°©ì§€")
                    target_field = None 
                    classified_keywords['target_field'] = None

        
        raw_keywords = classified_keywords.get('ranked_keywords_raw', [])
        ranked_keywords = []
        search_used_fields = set()

        charts = []
        used_fields = [] 
        chart_tasks = []
        objective_fields = set([f[0] for f in WELCOME_OBJECTIVE_FIELDS])

        demographic_filters = classified_keywords.get('demographic_filters', {})
        if demographic_filters:
            if 'age_range' in demographic_filters: search_used_fields.add('birth_year')
            for key in demographic_filters: 
                if key != 'age_range': search_used_fields.add(key)

        if 'children_count' in demographic_filters or 'children_count' in search_used_fields:
            used_fields.append('marital_status')

        if 'region_major' in demographic_filters and 'region_minor' not in used_fields:
            logging.info("ğŸ“ ì§€ì—­ í•„í„° ê°ì§€ -> ì„¸ë¶€ ì§€ì—­(region_minor) ë¶„ì„ ìë™ ì¶”ê°€")
            chart_tasks.append({
                "type": "filter",
                "kw_info": {
                    "field": "region_minor",
                    "description": "ì„¸ë¶€ ì§€ì—­ ë¶„í¬", 
                    "priority": 0 
                }
            })
            used_fields.append("region_minor")

        structured_filters = classified_keywords.get('structured_filters', [])
        for f in structured_filters:
            if f.get('field'): search_used_fields.add(f['field'])

        if raw_keywords:
            for i, kw in enumerate(raw_keywords):
                mapping = get_field_mapping(kw)
                ranked_keywords.append({
                    "keyword": kw, "field": mapping["field"], "description": mapping["description"],
                    "type": mapping.get("type", "unknown"), "priority": i + 10
                })
                if mapping.get("type") == 'filter' and mapping["field"] != 'unknown':
                    search_used_fields.add(mapping["field"])

        # 1. Main Target Field (0ìˆœìœ„)
        if target_field and target_field != 'unknown' and target_field not in used_fields:
            if target_field in QPOLL_FIELD_TO_TEXT:
                chart_tasks.append({"type": "qpoll", "kw_info": {"field": target_field, "description": QPOLL_FIELD_TO_TEXT[target_field], "priority": 0}})
                used_fields.append(target_field)
            elif target_field in objective_fields:
                chart_tasks.append({"type": "filter", "kw_info": {"field": target_field, "description": FIELD_NAME_MAP.get(target_field, target_field), "priority": 0}})
                used_fields.append(target_field)

        # Q-Poll íƒ€ê²Ÿì¸ ê²½ìš° ê¸°ë³¸ ì¸êµ¬í†µê³„ ìë™ ì¶”ê°€
        if target_field and target_field in QPOLL_FIELD_TO_TEXT:
            basic_demos = [('gender', 'ì„±ë³„'), ('birth_year', 'ì—°ë ¹ëŒ€'), ('region_major', 'ê±°ì£¼ ì§€ì—­')]
            for field, label in basic_demos:
                if field not in used_fields and field not in search_used_fields:
                    chart_tasks.append({
                        "type": "filter",
                        "kw_info": {"field": field, "description": label, "priority": 1}
                    })
                    used_fields.append(field)

        # 2. Semantic Conditions
        semantic_conditions = classified_keywords.get('semantic_conditions', [])
        for condition in semantic_conditions:
            original_keyword = condition.get('original_keyword')
            if not original_keyword: continue
            
            field_info = router.find_closest_field(original_keyword)
            if field_info:
                found_field = field_info['field']
                if found_field in used_fields: continue
                
                if found_field in fixed_filters:
                     continue

                logging.info(f"   ğŸ’¡ 2ì°¨ ì˜ë„ ë°œê²¬: '{original_keyword}' -> '{field_info['description']}' ({found_field})")
                
                if found_field in QPOLL_FIELD_TO_TEXT:
                    chart_tasks.append({"type": "qpoll", "kw_info": {"field": found_field, "description": QPOLL_FIELD_TO_TEXT[found_field], "priority": 1}})
                    used_fields.append(found_field)
                elif found_field in objective_fields:
                    chart_tasks.append({"type": "filter", "kw_info": {"field": found_field, "description": FIELD_NAME_MAP.get(found_field, found_field), "priority": 1}})
                    used_fields.append(found_field)

        # 3. ë‚˜ë¨¸ì§€ í‚¤ì›Œë“œ
        for kw_info in ranked_keywords:
            if len(chart_tasks) >= 5: break
            field = kw_info.get('field', '')
            if field in used_fields: continue
            
            if field in fixed_filters:
                logging.info(f"ğŸš« í‚¤ì›Œë“œ ì°¨íŠ¸ ì œì™¸: '{field}'ëŠ” ì´ë¯¸ í•„í„°ë¡œ ê³ ì •ë¨")
                continue

            if kw_info.get('type') == 'qpoll':
                kw_info['priority'] = 2
                chart_tasks.append({"type": "qpoll", "kw_info": kw_info})
                used_fields.append(field)
            elif kw_info.get('type') == 'filter' and field not in search_used_fields:
                if field in objective_fields and field != 'unknown':
                    kw_info['priority'] = 2
                    chart_tasks.append({"type": "filter", "kw_info": kw_info})
                    used_fields.append(field)

        # 1ì¸ ê°€êµ¬ ë¡œì§
        is_single_household = False
        fam_val = demographic_filters.get('family_size') or demographic_filters.get('household_size')
        if fam_val and (isinstance(fam_val, list) and any(str(v).startswith('1') for v in fam_val) or str(fam_val).startswith('1')): is_single_household = True
        if not is_single_household:
            for f in structured_filters:
                if f.get('field') in ['family_size', 'household_size']:
                    val = f.get('value')
                    if (isinstance(val, list) and any(str(v).startswith('1') for v in val) or str(val).startswith('1')): is_single_household = True
        if is_single_household: used_fields.append('income_household_monthly')

        # ì°¨ëŸ‰ ì†Œìœ  ë¹„ìœ¨ 70% ì´ìƒ ì‹œ ì°¨ì¢… ì°¨íŠ¸ ì¶”ê°€
        car_ownership_values = [p.get('car_ownership') for p in panels_data if p.get('car_ownership')]
        if car_ownership_values:
            flat_values = []
            car_map = VALUE_TRANSLATION_MAP.get('car_ownership', {}) 
            
            for v in car_ownership_values:
                if isinstance(v, list):
                    for sub_v in v:
                        cleaned = _clean_label(sub_v)
                        normalized = car_map.get(cleaned, cleaned)
                        flat_values.append(normalized)
                else:
                    cleaned = _clean_label(v)
                    normalized = car_map.get(cleaned, cleaned)
                    flat_values.append(normalized)
            
            car_dist = calculate_distribution(flat_values)
            if car_dist.get('ìˆìŒ', 0) >= 70.0:
                if 'car_model_raw' not in used_fields:
                    logging.info("ğŸš— ì°¨ëŸ‰ ë³´ìœ  ë¹„ìœ¨ 70% ì´ìƒ -> ì°¨ì¢…(car_model_raw) ë¶„ì„ ìë™ ì¶”ê°€")
                    chart_tasks.append({
                        "type": "filter",
                        "kw_info": {
                            "field": "car_model_raw",
                            "description": "ë³´ìœ  ì°¨ëŸ‰ ëª¨ë¸",
                            "priority": 1 
                        }
                    })
                    used_fields.append("car_model_raw")
                
                if 'car_ownership' not in used_fields:
                    used_fields.append("car_ownership")

        with ThreadPoolExecutor(max_workers=len(chart_tasks) or 1) as executor:
            futures = []
            for task in chart_tasks:
                kw = task['kw_info']
                if task['type'] == 'filter':
                    futures.append(executor.submit(create_chart_data_optimized, kw.get('keyword',''), kw.get('field'), kw.get('description'), panels_data))
                else:
                    futures.append(executor.submit(create_qpoll_chart_data, kw.get('field')))
                
                futures[-1].priority = kw.get('priority', 99)
            
            temp_results = []
            for future in as_completed(futures):
                try:
                    chart = future.result()
                    if chart.get('chart_data'):
                        temp_results.append((future.priority, chart))
                except: pass
            
            temp_results.sort(key=lambda x: x[0])
            charts.extend([res[1] for res in temp_results])

        # êµì°¨ ë¶„ì„
        if len(charts) < 5:
            topic_info = None
            if target_field and target_field in used_fields:
                topic_info = {'field': target_field, 'description': QPOLL_FIELD_TO_TEXT.get(target_field, FIELD_NAME_MAP.get(target_field))}
            if not topic_info:
                for task in chart_tasks:
                    if task['type'] == 'qpoll':
                        topic_info = task['kw_info']
                        break
            
            if topic_info:
                t_field = topic_info['field']
                t_name = topic_info['description']
                axes = []
                standard_axes = [('birth_year','ì—°ë ¹ëŒ€'), ('gender','ì„±ë³„'), ('region_major','ì§€ì—­'), ('job_title_raw','ì§ì—…')]
                for ax in standard_axes:
                    if ax[0] not in search_used_fields and ax[0] != t_field: axes.append(ax)
                for ax_field, ax_name in axes:
                    if len(charts) >= 5: break
                    crosstab = create_crosstab_chart(panels_data, ax_field, t_field, ax_name, t_name)
                    if crosstab and crosstab.get('chart_data'):
                        charts.append(crosstab)
                        used_fields.extend([ax_field, t_field])

        if len(charts) < 5:
            high_ratio = find_high_ratio_fields_optimized(panels_data, list(set(used_fields)|search_used_fields), max_charts=5-len(charts))
            for info in high_ratio:
                charts.append({"topic": f"{info['korean_name']} ë¶„í¬", "description": f"{info['top_ratio']}%ê°€ '{info['top_category']}'ì…ë‹ˆë‹¤.", "ratio": f"{info['top_ratio']}%", "chart_data": [{"label": info['korean_name'], "values": info['distribution']}]})

        return {
            "query": query, 
            "total_count": len(panels_data), 
            "main_summary": f"ì´ {len(panels_data)}ëª… ë°ì´í„° ë¶„ì„ ì™„ë£Œ", 
            "charts": charts
        }, 200

    except Exception as e:
        logging.error(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}", exc_info=True)
        return {"main_summary": "ì˜¤ë¥˜ ë°œìƒ", "charts": []}, 500

async def generate_dynamic_insight(panel_ids: List[str], target_field: str, field_desc: str) -> Dict:
    if not panel_ids or not target_field: return {}
    logging.info(f"ğŸ“Š ë™ì  ì¸ì‚¬ì´íŠ¸ ìƒì„± ì¤‘... (Field: {target_field})")
    
    panels_data = PanelRepository.fetch_panels_data(panel_ids)
    
    cleaned_answers = []
    for p in panels_data:
        val = p.get(target_field)
        if val:
            if isinstance(val, list):
                for v in val:
                    cleaned = _clean_label(v)
                    if cleaned: cleaned_answers.append(cleaned)
            else:
                cleaned = _clean_label(val)
                if cleaned: cleaned_answers.append(cleaned)
    
    if not cleaned_answers: return {"error": "ë°ì´í„° ë¶€ì¡±"}

    unique_answers = list(set(cleaned_answers))
    chart_data = {}
    
    if len(unique_answers) <= 15:
        chart_data = calculate_distribution(cleaned_answers)
    else:
        chart_data = _group_answers_with_vectors(cleaned_answers, threshold=0.82)

    final_chart_data = _limit_distribution_top_k(chart_data, k=7)
    if not final_chart_data: return {}

    top_category, top_ratio = find_top_category(final_chart_data)
    
    return {
        "topic": f"{field_desc} ë¶„ì„",
        "description": f"'{field_desc}'ì— ëŒ€í•´ '{top_category}'({top_ratio}%) ì‘ë‹µì´ ê°€ì¥ ë§ì•˜ìŠµë‹ˆë‹¤.",
        "ratio": f"{top_ratio}%",
        "chart_data": [{"label": field_desc, "values": final_chart_data}]
    }

def _group_answers_with_vectors(answers: List[str], threshold: float = 0.75) -> Dict[str, float]:
    if not answers: return {}
    embeddings_model = initialize_embeddings()
    unique_answers = list(set(answers))
    if len(unique_answers) < 2: return calculate_distribution(answers)

    try:
        vectors = embeddings_model.embed_documents(unique_answers)
        vectors = np.array(vectors)
        clustering = DBSCAN(eps=1-threshold, min_samples=1, metric='cosine').fit(vectors)
        labels = clustering.labels_
        
        cluster_map = {}
        for i, label in enumerate(labels):
            if label not in cluster_map: cluster_map[label] = []
            cluster_map[label].append(unique_answers[i])
            
        total_counts = Counter(answers)
        cluster_to_repr = {}
        for label, group_members in cluster_map.items():
            repr_word = max(group_members, key=lambda x: (total_counts[x], -len(x)))
            cluster_to_repr[label] = repr_word
            
        ans_to_label = {ans: labels[i] for i, ans in enumerate(unique_answers)}
        mapped_answers = [cluster_to_repr[ans_to_label[ans]] for ans in answers]
            
        return calculate_distribution(mapped_answers)
    except Exception as e:
        logging.error(f"ë²¡í„° í´ëŸ¬ìŠ¤í„°ë§ ì‹¤íŒ¨: {e}", exc_info=True)
        return calculate_distribution(answers)