import os
import logging
import re 
from typing import List, Dict, Any, Tuple
from collections import Counter, defaultdict
from concurrent.futures import ThreadPoolExecutor, as_completed
from qdrant_client.http.models import Filter, FieldCondition, MatchValue
import numpy as np
from sklearn.cluster import DBSCAN
from search_helpers import initialize_embeddings 

from utils import (
    extract_field_values,
    calculate_distribution,
    find_top_category,
    FIELD_NAME_MAP,
    WELCOME_OBJECTIVE_FIELDS,
    get_panels_data_from_db,
    get_age_group
)
from mapping_rules import get_field_mapping, QPOLL_FIELD_TO_TEXT, QPOLL_ANSWER_TEMPLATES, KEYWORD_MAPPINGS
from db import get_db_connection_context, get_qdrant_client
from semantic_router import router 


def _clean_label(text: Any, max_length: int = 25) -> str:
    """ë¼ë²¨ ì •ì œ í•¨ìˆ˜"""
    if not text: return ""
    text_str = str(text)
    cleaned = re.sub(r'\([^)]*\)', '', text_str).strip()
    cleaned = " ".join(cleaned.split())
    if len(cleaned) > max_length:
        return cleaned[:max_length] + ".."
    return cleaned

def _extract_core_value(field_name: str, sentence: str) -> str:
    """ë¬¸ì¥í˜• ë°ì´í„°ì—ì„œ í•µì‹¬ ë‹µë³€ë§Œ ì¶”ì¶œ"""
    if not sentence: return ""
    
    if field_name == "ott_count":
        match = re.search(r'(\d+ê°œ|ì´ìš© ì•ˆ í•¨|ì—†ìŒ)', sentence)
        if match: return match.group(1)
    elif field_name == "skincare_spending":
        match = re.search(r'(\d+ë§Œ\s*ì›|\d+~\d+ë§Œ\s*ì›|\d+ì›)', sentence)
        if match: return match.group(1)
    
    template = QPOLL_ANSWER_TEMPLATES.get(field_name)
    if template:
        try:
            pattern_str = re.escape(template)
            pattern_str = pattern_str.replace(re.escape("{answer_str}"), r"(.*?)")
            pattern_str = pattern_str.replace(r"\(ì´\)ë‹¤", r"(?:ì´)?ë‹¤")
            pattern_str = pattern_str.replace(r"\(ìœ¼\)ë¡œ", r"(?:ìœ¼)?ë¡œ")
            pattern_str = pattern_str.replace(r"\(ê°€\)", r"(?:ê°€)?")
            pattern_str = pattern_str.replace(r"\ ", r"\s*")
            match = re.search(pattern_str, sentence)
            if match:
                return _clean_label(match.group(1))
        except: pass

    return _clean_label(sentence)

def _limit_distribution_top_k(distribution: Dict[str, float], k: int = 7) -> Dict[str, float]:
    """[ë§‰ëŒ€ ì°¨íŠ¸ìš©] ìƒìœ„ Kê°œë§Œ ë‚¨ê¸°ê³  ë‚˜ë¨¸ì§€ëŠ” 'ê¸°íƒ€'ë¡œ í•©ì¹©ë‹ˆë‹¤."""
    if not distribution or len(distribution) <= k:
        return distribution
    sorted_items = sorted(distribution.items(), key=lambda x: x[1], reverse=True)
    top_items = dict(sorted_items[:k])
    other_sum = sum(v for _, v in sorted_items[k:])
    if other_sum > 0:
        top_items['ê¸°íƒ€'] = round(other_sum, 1)
    return top_items

def _sort_distribution(distribution: Dict[str, float]) -> Dict[str, float]:
    """[ì›í˜• ì°¨íŠ¸ìš©] 'ê¸°íƒ€'ë¡œ ë¬¶ì§€ ì•Šê³  ì „ì²´ë¥¼ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤."""
    if not distribution: return {}
    return dict(sorted(distribution.items(), key=lambda x: x[1], reverse=True))

def get_field_distribution_from_db(field_name: str, limit: int = 50) -> Dict[str, float]:
    """PostgreSQL ì§ì ‘ ì§‘ê³„"""
    try:
        with get_db_connection_context() as conn:
            if not conn: return {}
            cur = conn.cursor()
            
            if field_name == "birth_year":
                query = f"""
                    WITH age_groups AS (
                        SELECT 
                            CASE 
                                WHEN (date_part('year', CURRENT_DATE) - (structured_data->>'birth_year')::int) < 20 THEN '10ëŒ€'
                                WHEN (date_part('year', CURRENT_DATE) - (structured_data->>'birth_year')::int) < 30 THEN '20ëŒ€'
                                WHEN (date_part('year', CURRENT_DATE) - (structured_data->>'birth_year')::int) < 40 THEN '30ëŒ€'
                                WHEN (date_part('year', CURRENT_DATE) - (structured_data->>'birth_year')::int) < 50 THEN '40ëŒ€'
                                WHEN (date_part('year', CURRENT_DATE) - (structured_data->>'birth_year')::int) < 60 THEN '50ëŒ€'
                                ELSE '60ëŒ€ ì´ìƒ'
                            END as age_group
                        FROM welcome_meta2
                        WHERE structured_data->>'birth_year' IS NOT NULL
                    )
                    SELECT age_group, COUNT(*), ROUND(COUNT(*) * 100.0 / SUM(COUNT(*)) OVER (), 1)
                    FROM age_groups GROUP BY age_group ORDER BY 3 DESC LIMIT {limit}
                """
            elif field_name == "children_count":
                query = f"""
                    SELECT 
                        CONCAT((structured_data->>'{field_name}')::numeric::int, 'ëª…') as val, 
                        COUNT(*) as count,
                        ROUND(COUNT(*) * 100.0 / SUM(COUNT(*)) OVER (), 1) as percentage
                    FROM welcome_meta2
                    WHERE structured_data->>'{field_name}' IS NOT NULL
                    GROUP BY val ORDER BY percentage DESC LIMIT {limit}
                """
            else:
                query = f"""
                    SELECT structured_data->>'{field_name}', COUNT(*), ROUND(COUNT(*) * 100.0 / SUM(COUNT(*)) OVER (), 1)
                    FROM welcome_meta2 WHERE structured_data->>'{field_name}' IS NOT NULL
                    GROUP BY 1 ORDER BY 3 DESC LIMIT {limit}
                """
            
            cur.execute(query)
            rows = cur.fetchall()
            cur.close()
            return {row[0]: float(row[2]) for row in rows if row[0]}
            
    except Exception as e:
        logging.error(f"DB ì§‘ê³„ ì‹¤íŒ¨ ({field_name}): {e}")
        return {}
    
def get_qpoll_distribution_from_db(qpoll_field: str, limit: int = 50) -> Dict[str, float]:
    """Qdrant ì§‘ê³„"""
    question_text = QPOLL_FIELD_TO_TEXT.get(qpoll_field)
    if not question_text: return {}
    client = get_qdrant_client()
    if not client: return {}
    try:
        COLLECTION_NAME = os.getenv("QDRANT_COLLECTION_QPOLL_NAME", "qpoll_vectors_v2")
        query_filter = Filter(must=[FieldCondition(key="question", match=MatchValue(value=question_text))])
        all_points = []
        next_offset = None
        while True:
            points, next_offset = client.scroll(
                collection_name=COLLECTION_NAME, scroll_filter=query_filter, limit=1000, offset=next_offset, with_payload=True, with_vectors=False
            )
            all_points.extend(points)
            if next_offset is None: break
        
        if not all_points: return {}
        extracted_values = []
        for p in all_points:
            if p.payload and p.payload.get("sentence"):
                raw_sentence = p.payload.get("sentence")
                core_val = _extract_core_value(qpoll_field, raw_sentence)
                if core_val: extracted_values.append(core_val)
        
        if not extracted_values: return {}
        val_counts = Counter(extracted_values)
        total = len(extracted_values)
        return {k: round((v / total) * 100, 1) for k, v in val_counts.most_common(limit)}
    except Exception as e:
        logging.error(f"Q-Poll ì§‘ê³„ ì‹¤íŒ¨: {e}")
        return {}

def create_chart_data_optimized(
    keyword: str,
    field_name: str,
    korean_name: str,
    panels_data: List[Dict],
    use_full_db: bool = False,
    max_categories: int = 50
) -> Dict:
    """ì°¨íŠ¸ ë°ì´í„° ìƒì„± (SQL ì§‘ê³„ ìš°ì„ )"""
    
    # 1. DB ì „ì²´ ì§‘ê³„ê°€ í•„ìš”í•œ ê²½ìš° (ë‚˜ì´, ìë…€ ìˆ˜ ë“±)
    if use_full_db or field_name == "children_count":
        logging.info(f"       â†’ DB ì§‘ê³„ë¡œ '{field_name}' ë¶„ì„")
        distribution = get_field_distribution_from_db(field_name, max_categories)
        if not distribution: return {"topic": korean_name, "ratio": "0.0%", "chart_data": [], "description": "ë°ì´í„° ì—†ìŒ"}
        
        cleaned_distribution = defaultdict(float)
        for k, v in distribution.items(): cleaned_distribution[_clean_label(k)] += v
        
        # [ìˆ˜ì •] DB ì§‘ê³„ ê²°ê³¼ë„ ë„ˆë¬´ ë§ìœ¼ë©´ ì¤„ì„ (limit=8)
        final_distribution = _limit_distribution_top_k(dict(cleaned_distribution), k=8)
        top_category, top_ratio = find_top_category(final_distribution)
        
        return {
            "topic": f"{korean_name} ë¶„í¬",
            "description": f"ì „ì²´ ê¸°ì¤€: {top_ratio}%ê°€ '{top_category}'ì…ë‹ˆë‹¤.",
            "ratio": f"{top_ratio}%",
            "chart_data": [{"label": korean_name, "values": final_distribution}],
            "field": field_name 
        }

    # 2. ê²€ìƒ‰ ê²°ê³¼ ë‚´ ì§‘ê³„ (ë¦¬ìŠ¤íŠ¸í˜• í•„ë“œ ë“±)
    else:
        values = []
        raw_values = [item.get(field_name) for item in panels_data if item.get(field_name)]
        
        for val in raw_values:
            if isinstance(val, list):
                for v in val:
                    cleaned = _clean_label(v)
                    if cleaned: values.append(cleaned)
            elif val is not None:
                cleaned = _clean_label(val)
                if cleaned: values.append(cleaned)
        
        if not values: return {"topic": korean_name, "description": "ë°ì´í„° ë¶€ì¡±", "ratio": "0.0%", "chart_data": [], "field": field_name}
        
        distribution = calculate_distribution(values)
        
        # í•­ëª© ê°œìˆ˜ë¥¼ ì œí•œí•˜ì—¬ ì°¨íŠ¸ ê°„ì†Œí™”
        final_distribution = _limit_distribution_top_k(distribution, k=10)
        
        top_category, top_ratio = find_top_category(final_distribution)
        
        return {
            "topic": f"{korean_name} ë¶„í¬",
            "description": f"ê²€ìƒ‰ ê²°ê³¼: {top_ratio}%ê°€ '{top_category}'ì…ë‹ˆë‹¤.",
            "ratio": f"{top_ratio}%",
            "chart_data": [{"label": korean_name, "values": final_distribution}],
            "field": field_name
        }

def create_qpoll_chart_data(qpoll_field: str, max_categories: int = 50) -> Dict:
    """Q-Poll ì°¨íŠ¸ ë°ì´í„° ìƒì„±"""
    question_text = QPOLL_FIELD_TO_TEXT.get(qpoll_field, qpoll_field) 
    distribution = get_qpoll_distribution_from_db(qpoll_field, max_categories)
    
    if not distribution: return {"topic": question_text, "ratio": "0.0%", "chart_data": [], "description": "ë°ì´í„° ì—†ìŒ", "field": qpoll_field}
    
    top_category, top_ratio = find_top_category(distribution)
    
    template = QPOLL_ANSWER_TEMPLATES.get(qpoll_field)
    if template and top_category != "ê¸°íƒ€":
        try:
            formatted_answer = template.format(answer_str=f"'{top_category}'")
            description = f"ê°€ì¥ ë§ì€ ì‘ë‹µìëŠ” {formatted_answer} ({top_ratio}%)"
        except: description = f"ê°€ì¥ ë§ì€ ì‘ë‹µì€ '{top_category}'({top_ratio}%)ì…ë‹ˆë‹¤."
    else: description = f"ê°€ì¥ ë§ì€ ì‘ë‹µì€ '{top_category}'({top_ratio}%)ì…ë‹ˆë‹¤."

    return {
        "topic": question_text, 
        "description": description,
        "ratio": f"{top_ratio}%",
        "chart_data": [{"label": question_text, "values": distribution}],
        "field": qpoll_field
    }

def create_crosstab_chart(
    panels_data: List[Dict],
    field1: str,
    field2: str,
    field1_korean: str,
    field2_korean: str,
    max_categories: int = 5
) -> Dict:
    """êµì°¨ ë¶„ì„ ì°¨íŠ¸ ìƒì„±"""
    logging.info(f"       â†’ êµì°¨ ë¶„ì„: '{field1}' vs '{field2}'")
    
    all_values_field2 = []
    for item in panels_data:
        val2 = item.get(field2)
        if not val2: continue
        
        if isinstance(val2, list):
            for v in val2:
                cleaned = _clean_label(v)
                if cleaned: all_values_field2.append(cleaned)
        else:
            cleaned = _clean_label(val2)
            if cleaned: all_values_field2.append(cleaned)
            
    if not all_values_field2:
        return {}

    global_counter = Counter(all_values_field2)
    top_7_keys = [k for k, v in global_counter.most_common(7)]
    top_7_set = set(top_7_keys)

    crosstab_data = {} 

    for item in panels_data:
        val1 = item.get(field1)
        val2 = item.get(field2)
        
        if val1 is None or val2 is None: continue

        raw_key1 = get_age_group(val1) if field1 == 'birth_year' else str(val1)
        key1 = _clean_label(raw_key1)
        
        if key1 not in crosstab_data:
            crosstab_data[key1] = []
            
        values_to_process = val2 if isinstance(val2, list) else [val2]
        
        for v in values_to_process:
            cleaned_v = _clean_label(v)
            if not cleaned_v: continue
            
            if cleaned_v in top_7_set:
                crosstab_data[key1].append(cleaned_v)
            else:
                crosstab_data[key1].append("ê¸°íƒ€")

    if not crosstab_data:
        return {}

    # [Case 1] ë‹¨ì¼ ê·¸ë£¹ -> Pie Chart (ì „ì²´ í‘œì‹œ)
    if len(crosstab_data) <= 1:
        only_group = list(crosstab_data.keys())[0]
        distribution = calculate_distribution(crosstab_data[only_group])
        final_distribution = _sort_distribution(distribution)
        
        return {
            "topic": f"{field1_korean}ë³„ {field2_korean} ë¶„í¬ ({only_group})",
            "description": f"'{only_group}' ì§‘ë‹¨ì˜ '{field2_korean}' ë¶„í¬ì…ë‹ˆë‹¤.",
            "chart_type": "pie", 
            "chart_data": [{"label": field2_korean, "values": final_distribution}],
            "fields": [field1, field2]
        }

    # [Case 2] ë‹¤ì¤‘ ê·¸ë£¹ -> Bar Chart (Top 7)
    chart_values = {}
    sorted_groups = sorted(crosstab_data.keys(), key=lambda k: len(crosstab_data[k]), reverse=True)
    target_groups = sorted_groups[:max_categories]

    for group in target_groups:
        items = crosstab_data[group]
        distribution = calculate_distribution(items)
        chart_values[group] = _limit_distribution_top_k(distribution, k=7)

    return {
        "topic": f"{field1_korean}ë³„ {field2_korean} ë¶„í¬",
        "description": f"'{field1_korean}'ì— ë”°ë¥¸ ì£¼ìš” '{field2_korean}' ë¶„í¬ì…ë‹ˆë‹¤.",
        "chart_type": "crosstab",
        "chart_data": [{"label": f"{field1_korean}ë³„ {field2_korean}", "values": chart_values}],
        "fields": [field1, field2] 
    }

def _analyze_fields_in_parallel(panels_data: List[Dict], candidate_fields: List[Tuple[str, str]]) -> List[Dict]:
    """ë³‘ë ¬ í•„ë“œ ë¶„ì„"""
    field_values = {fname: [] for fname, _ in candidate_fields}
    field_map = dict(candidate_fields)

    for item in panels_data:
        for fname in field_values.keys():
            val = item.get(fname)
            if val is None: continue

            if fname == "birth_year":
                field_values[fname].append(get_age_group(val))
            elif isinstance(val, list):
                for v in val:
                    cleaned = _clean_label(v)
                    if cleaned: field_values[fname].append(cleaned)
            else:
                cleaned = _clean_label(val)
                if cleaned: field_values[fname].append(cleaned)

    results = []
    for fname, vals in field_values.items():
        if not vals: continue
        try:
            dist = calculate_distribution(vals)
            final_dist = _sort_distribution(dist)
            if not final_dist: continue
            
            results.append({
                "field": fname,
                "korean_name": field_map[fname],
                "distribution": final_dist,
            })
        except: pass
    return results


def find_high_ratio_fields_optimized(
    panels_data: List[Dict], 
    exclude_fields: List[str], 
    threshold: float = 50.0,
    max_charts: int = 3
) -> List[Dict]:
    """ë†’ì€ ë¹„ìœ¨ í•„ë“œ ì°¾ê¸° (98% ì´ìƒ ì œì™¸)"""
    candidate_fields = []
    for fname, kname in WELCOME_OBJECTIVE_FIELDS:
        if fname not in exclude_fields:
            candidate_fields.append((fname, kname))
    
    if not candidate_fields: return []
    
    analysis_results = _analyze_fields_in_parallel(panels_data, candidate_fields)
    
    high_ratio_results = []
    for result in analysis_results:
        distribution = result['distribution']
        top_category, top_ratio = find_top_category(distribution)
        
        if top_ratio >= threshold:
            if top_ratio >= 98.0:
                continue

            high_ratio_results.append({
                "field": result['field'],
                "korean_name": result['korean_name'],
                "distribution": distribution,
                "top_category": top_category,
                "top_ratio": top_ratio
            })
    
    high_ratio_results.sort(key=lambda x: x["top_ratio"], reverse=True)
    return high_ratio_results[:max_charts]

def _generate_no_results_tips(classified_keywords: dict) -> str:
    return "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ì¡°ê±´ì„ ì™„í™”í•´ ë³´ì„¸ìš”."

def analyze_search_results_optimized(
    query: str,
    classified_keywords: dict,
    panel_id_list: List[str]
) -> Tuple[Dict, int]:
    logging.info(f"ğŸ“Š ë¶„ì„ ì‹œì‘ (ìµœì í™”) - panel_id ìˆ˜: {len(panel_id_list)}ê°œ")
    
    if not panel_id_list:
        return {"main_summary": _generate_no_results_tips(classified_keywords), "charts": []}, 200
    
    try:
        panels_data = get_panels_data_from_db(panel_id_list)
        if not panels_data: return {"main_summary": "ë°ì´í„° ì—†ìŒ", "charts": []}, 200
        
        raw_keywords = classified_keywords.get('ranked_keywords_raw', [])
        ranked_keywords = []
        search_used_fields = set()

        charts = []
        used_fields = [] 
        chart_tasks = []
        objective_fields = set([f[0] for f in WELCOME_OBJECTIVE_FIELDS])

        demographic_filters = classified_keywords.get('demographic_filters', {})
        if demographic_filters:
            if 'age_range' in demographic_filters: search_used_fields.add('birth_year')
            for key in demographic_filters: 
                if key != 'age_range': search_used_fields.add(key)

        if 'region_major' in demographic_filters and 'region_minor' not in used_fields:
            logging.info("ğŸ“ ì§€ì—­ í•„í„° ê°ì§€ -> ì„¸ë¶€ ì§€ì—­(region_minor) ë¶„ì„ ìë™ ì¶”ê°€")
            chart_tasks.append({
                "type": "filter",
                "kw_info": {
                    "field": "region_minor",
                    "description": "ì„¸ë¶€ ì§€ì—­ ë¶„í¬", 
                    "priority": 0 
                }
            })
            used_fields.append("region_minor")

        structured_filters = classified_keywords.get('structured_filters', [])
        for f in structured_filters:
            if f.get('field'): search_used_fields.add(f['field'])

        if raw_keywords:
            for i, kw in enumerate(raw_keywords):
                mapping = get_field_mapping(kw)
                ranked_keywords.append({
                    "keyword": kw, "field": mapping["field"], "description": mapping["description"],
                    "type": mapping.get("type", "unknown"), "priority": i + 10
                })
                if mapping.get("type") == 'filter' and mapping["field"] != 'unknown':
                    search_used_fields.add(mapping["field"])

        analysis_notes = classified_keywords.get('analysis_notes', {})
        dist_field = analysis_notes.get('distribution_field')
        
        # 1. LLMì´ ë†“ì³¤ì„ ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ Regexë¡œ ì§ì ‘ ìŠ¤ìº”
        if not dist_field or dist_field == 'unknown':
            for pattern, mapping_info in KEYWORD_MAPPINGS:
                if isinstance(pattern, re.Pattern):
                    if pattern.search(query):
                        if "ë¶„í¬" in query or "ë¹„ìœ¨" in query or "ìˆ˜" in query:
                            if mapping_info['field'] in ["children_count", "family_size"]:
                                dist_field = mapping_info['field']
                                break
        
        # 2. ì°¾ì•„ë‚¸ dist_fieldê°€ ìˆìœ¼ë©´ 0ìˆœìœ„ë¡œ ì¶”ê°€
        if dist_field and dist_field != 'unknown' and dist_field not in used_fields:
            logging.info(f"   âœ¨ [ë¶„ì„ í•„ë“œ ê°ì§€] ë¶„í¬ ë¶„ì„ ëŒ€ìƒ: {dist_field}")
            kw_info = {
                "field": dist_field, 
                "description": FIELD_NAME_MAP.get(dist_field, dist_field), 
                "priority": -1 # ìµœìš°ì„  ìˆœìœ„
            }
            
            if dist_field in QPOLL_FIELD_TO_TEXT:
                chart_tasks.append({"type": "qpoll", "kw_info": kw_info})
            else:
                chart_tasks.append({"type": "filter", "kw_info": kw_info})
            used_fields.append(dist_field)

        # 1. Main Target Field (0ìˆœìœ„)
        target_field = classified_keywords.get('target_field')
        if target_field and target_field != 'unknown' and target_field not in used_fields:
            if target_field in QPOLL_FIELD_TO_TEXT:
                chart_tasks.append({"type": "qpoll", "kw_info": {"field": target_field, "description": QPOLL_FIELD_TO_TEXT[target_field], "priority": 0}})
                used_fields.append(target_field)
            elif target_field in objective_fields:
                chart_tasks.append({"type": "filter", "kw_info": {"field": target_field, "description": FIELD_NAME_MAP.get(target_field, target_field), "priority": 0}})
                used_fields.append(target_field)

        # 2. Semantic Conditions (1ìˆœìœ„)
        semantic_conditions = classified_keywords.get('semantic_conditions', [])
        for condition in semantic_conditions:
            original_keyword = condition.get('original_keyword')
            if not original_keyword: continue
            
            field_info = router.find_closest_field(original_keyword)
            if field_info:
                found_field = field_info['field']
                if found_field in used_fields: continue
                
                logging.info(f"   ğŸ’¡ 2ì°¨ ì˜ë„ ë°œê²¬: '{original_keyword}' -> '{field_info['description']}' ({found_field})")
                
                if found_field in QPOLL_FIELD_TO_TEXT:
                    chart_tasks.append({"type": "qpoll", "kw_info": {"field": found_field, "description": QPOLL_FIELD_TO_TEXT[found_field], "priority": 1}})
                    used_fields.append(found_field)
                elif found_field in objective_fields:
                    chart_tasks.append({"type": "filter", "kw_info": {"field": found_field, "description": FIELD_NAME_MAP.get(found_field, found_field), "priority": 1}})
                    used_fields.append(found_field)

        # 3. ë‚˜ë¨¸ì§€ í‚¤ì›Œë“œ
        for kw_info in ranked_keywords:
            if len(chart_tasks) >= 5: break
            field = kw_info.get('field', '')
            if field in used_fields: continue
            
            if kw_info.get('type') == 'qpoll':
                kw_info['priority'] = 2
                chart_tasks.append({"type": "qpoll", "kw_info": kw_info})
                used_fields.append(field)
            elif kw_info.get('type') == 'filter' and field not in search_used_fields:
                if field in objective_fields and field != 'unknown':
                    kw_info['priority'] = 2
                    chart_tasks.append({"type": "filter", "kw_info": kw_info})
                    used_fields.append(field)

        # 1ì¸ ê°€êµ¬ ë¡œì§
        is_single_household = False
        fam_val = demographic_filters.get('family_size') or demographic_filters.get('household_size')
        if fam_val and (isinstance(fam_val, list) and any(str(v).startswith('1') for v in fam_val) or str(fam_val).startswith('1')): is_single_household = True
        if not is_single_household:
            for f in structured_filters:
                if f.get('field') in ['family_size', 'household_size']:
                    val = f.get('value')
                    if (isinstance(val, list) and any(str(v).startswith('1') for v in val) or str(val).startswith('1')): is_single_household = True
        if is_single_household: used_fields.append('income_household_monthly')

        with ThreadPoolExecutor(max_workers=len(chart_tasks) or 1) as executor:
            futures = []
            for task in chart_tasks:
                kw = task['kw_info']
                if task['type'] == 'filter':
                    futures.append(executor.submit(create_chart_data_optimized, kw.get('keyword',''), kw.get('field'), kw.get('description'), panels_data))
                else:
                    futures.append(executor.submit(create_qpoll_chart_data, kw.get('field')))
                
                futures[-1].priority = kw.get('priority', 99)
            
            temp_results = []
            for future in as_completed(futures):
                try:
                    chart = future.result()
                    if chart.get('chart_data'):
                        temp_results.append((future.priority, chart))
                except: pass
            
            temp_results.sort(key=lambda x: x[0])
            charts.extend([res[1] for res in temp_results])

        # êµì°¨ ë¶„ì„
        if len(charts) < 5:
            topic_info = None
            if target_field and target_field in used_fields:
                topic_info = {'field': target_field, 'description': QPOLL_FIELD_TO_TEXT.get(target_field, FIELD_NAME_MAP.get(target_field))}
            if not topic_info:
                for task in chart_tasks:
                    if task['type'] == 'qpoll':
                        topic_info = task['kw_info']
                        break
            
            if topic_info:
                t_field = topic_info['field']
                t_name = topic_info['description']
                axes = []
                standard_axes = [('birth_year','ì—°ë ¹ëŒ€'), ('gender','ì„±ë³„'), ('region_major','ì§€ì—­'), ('job_title_raw','ì§ì—…')]
                for ax in standard_axes:
                    if ax[0] not in search_used_fields and ax[0] != t_field: axes.append(ax)
                for ax_field, ax_name in axes:
                    if len(charts) >= 5: break
                    crosstab = create_crosstab_chart(panels_data, ax_field, t_field, ax_name, t_name)
                    if crosstab and crosstab.get('chart_data'):
                        charts.append(crosstab)
                        used_fields.extend([ax_field, t_field])

        if len(charts) < 5:
            high_ratio = find_high_ratio_fields_optimized(panels_data, list(set(used_fields)|search_used_fields), max_charts=5-len(charts))
            for info in high_ratio:
                charts.append({"topic": f"{info['korean_name']} ë¶„í¬", "description": f"{info['top_ratio']}%ê°€ '{info['top_category']}'ì…ë‹ˆë‹¤.", "ratio": f"{info['top_ratio']}%", "chart_data": [{"label": info['korean_name'], "values": info['distribution']}]})

        return {"query": query, "total_count": len(panels_data), "main_summary": f"ì´ {len(panels_data)}ëª… ë°ì´í„° ë¶„ì„ ì™„ë£Œ", "charts": charts}, 200

    except Exception as e:
        logging.error(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}", exc_info=True)
        return {"main_summary": "ì˜¤ë¥˜ ë°œìƒ", "charts": []}, 500

async def generate_dynamic_insight(panel_ids: List[str], target_field: str, field_desc: str) -> Dict:
    if not panel_ids or not target_field: return {}
    logging.info(f"ğŸ“Š ë™ì  ì¸ì‚¬ì´íŠ¸ ìƒì„± ì¤‘... (Field: {target_field})")
    panels_data = get_panels_data_from_db(panel_ids)
    
    cleaned_answers = []
    for p in panels_data:
        val = p.get(target_field)
        if val:
            if isinstance(val, list):
                for v in val:
                    cleaned = _clean_label(v)
                    if cleaned: cleaned_answers.append(cleaned)
            else:
                cleaned = _clean_label(val)
                if cleaned: cleaned_answers.append(cleaned)
    
    if not cleaned_answers: return {"error": "ë°ì´í„° ë¶€ì¡±"}

    unique_answers = list(set(cleaned_answers))
    chart_data = {}
    
    if len(unique_answers) <= 15:
        chart_data = calculate_distribution(cleaned_answers)
    else:
        chart_data = _group_answers_with_vectors(cleaned_answers, threshold=0.82)

    final_chart_data = _limit_distribution_top_k(chart_data, k=7)
    if not final_chart_data: return {}

    top_category, top_ratio = find_top_category(final_chart_data)
    
    return {
        "topic": f"{field_desc} ë¶„ì„",
        "description": f"'{field_desc}'ì— ëŒ€í•´ '{top_category}'({top_ratio}%) ì‘ë‹µì´ ê°€ì¥ ë§ì•˜ìŠµë‹ˆë‹¤.",
        "ratio": f"{top_ratio}%",
        "chart_data": [{"label": field_desc, "values": final_chart_data}]
    }

def _group_answers_with_vectors(answers: List[str], threshold: float = 0.75) -> Dict[str, float]:
    if not answers: return {}
    embeddings_model = initialize_embeddings()
    unique_answers = list(set(answers))
    if len(unique_answers) < 2: return calculate_distribution(answers)

    try:
        vectors = embeddings_model.embed_documents(unique_answers)
        vectors = np.array(vectors)
        clustering = DBSCAN(eps=1-threshold, min_samples=1, metric='cosine').fit(vectors)
        labels = clustering.labels_
        
        cluster_map = {}
        for i, label in enumerate(labels):
            if label not in cluster_map: cluster_map[label] = []
            cluster_map[label].append(unique_answers[i])
            
        total_counts = Counter(answers)
        cluster_to_repr = {}
        for label, group_members in cluster_map.items():
            repr_word = max(group_members, key=lambda x: (total_counts[x], -len(x)))
            cluster_to_repr[label] = repr_word
            
        ans_to_label = {ans: labels[i] for i, ans in enumerate(unique_answers)}
        mapped_answers = [cluster_to_repr[ans_to_label[ans]] for ans in answers]
            
        return calculate_distribution(mapped_answers)
    except Exception as e:
        logging.error(f"ë²¡í„° í´ëŸ¬ìŠ¤í„°ë§ ì‹¤íŒ¨: {e}", exc_info=True)
        return calculate_distribution(answers)