import os
import logging
import re 
from typing import List, Dict, Any, Tuple
from collections import Counter
from concurrent.futures import ThreadPoolExecutor, as_completed
from qdrant_client.models import Filter, FieldCondition, MatchValue

from utils import (
    extract_field_values,
    calculate_distribution,
    find_top_category,
    FIELD_NAME_MAP,
    WELCOME_OBJECTIVE_FIELDS,
    get_panels_data_from_db 
)
from mapping_rules import get_field_mapping, QPOLL_FIELD_TO_TEXT # get_field_mapping import
from db import get_db_connection_context, get_qdrant_client
from functools import lru_cache


@lru_cache(maxsize=64)
def get_field_distribution_from_db(field_name: str, limit: int = 10) -> Dict[str, float]:
    """
    PostgreSQLì—ì„œ ì§ì ‘ ì§‘ê³„í•˜ì—¬ í•„ë“œ ë¶„í¬ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤. (ì „ì²´ DB ëŒ€ìƒ)
    """
    try:
        with get_db_connection_context() as conn:
            if not conn:
                logging.error("DB ì§‘ê³„: ì—°ê²° ì‹¤íŒ¨")
                return {}
            
            cur = conn.cursor()
            
            if field_name == "birth_year":
                query = f"""
                    WITH age_groups AS (
                        SELECT 
                            CASE 
                                WHEN (date_part('year', CURRENT_DATE) - (structured_data->>'birth_year')::int) < 20 THEN '10ëŒ€'
                                WHEN (date_part('year', CURRENT_DATE) - (structured_data->>'birth_year')::int) < 30 THEN '20ëŒ€'
                                WHEN (date_part('year', CURRENT_DATE) - (structured_data->>'birth_year')::int) < 40 THEN '30ëŒ€'
                                WHEN (date_part('year', CURRENT_DATE) - (structured_data->>'birth_year')::int) < 50 THEN '40ëŒ€'
                                WHEN (date_part('year', CURRENT_DATE) - (structured_data->>'birth_year')::int) < 60 THEN '50ëŒ€'
                                ELSE '60ëŒ€ ì´ìƒ'
                            END as age_group
                        FROM welcome_meta2
                        WHERE structured_data->>'birth_year' IS NOT NULL
                            AND structured_data->>'birth_year' ~ '^[0-9]+$'
                    )
                    SELECT 
                        age_group,
                        COUNT(*) as count,
                        ROUND(COUNT(*) * 100.0 / SUM(COUNT(*)) OVER (), 1) as percentage
                    FROM age_groups
                    GROUP BY age_group
                    ORDER BY percentage DESC
                    LIMIT {limit}
                """
            else:
                query = f"""
                    SELECT 
                        structured_data->>'{field_name}' as value,
                        COUNT(*) as count,
                        ROUND(COUNT(*) * 100.0 / SUM(COUNT(*)) OVER (), 1) as percentage
                    FROM welcome_meta2
                    WHERE structured_data->>'{field_name}' IS NOT NULL
                        AND structured_data->>'{field_name}' != ''
                    GROUP BY structured_data->>'{field_name}'
                    ORDER BY percentage DESC
                    LIMIT {limit}
                """
            
            cur.execute(query)
            rows = cur.fetchall()
            
            distribution = {}
            for row in rows:
                value = row[0]
                percentage = float(row[2])
                if value and percentage > 0:
                    distribution[value] = percentage
            
            cur.close()
        
        logging.info(f"   ğŸ“Š DB ì§‘ê³„ ì™„ë£Œ: {field_name} ({len(distribution)}ê°œ ì¹´í…Œê³ ë¦¬)")
        return distribution
        
    except Exception as e:
        logging.error(f"   DB ì§‘ê³„ ì‹¤íŒ¨ ({field_name}): {e}", exc_info=True)
        return {}
    
@lru_cache(maxsize=64)
def get_qpoll_distribution_from_db(qpoll_field: str, limit: int = 10) -> Dict[str, float]:
    """
    Qdrantì—ì„œ Q-Poll ì§ˆë¬¸ì— ëŒ€í•œ ì‘ë‹µ ë¶„í¬ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.
    """
    question_text = QPOLL_FIELD_TO_TEXT.get(qpoll_field)
    if not question_text:
        logging.error(f"Q-Poll DB ì§‘ê³„: '{qpoll_field}'ì— í•´ë‹¹í•˜ëŠ” ì§ˆë¬¸ ì›ë¬¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return {}
    
    client = get_qdrant_client()
    if not client:
        logging.error("Q-Poll Qdrant ì§‘ê³„: Qdrant í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ì‹¤íŒ¨.")
        return {}
        
    try:
        COLLECTION_NAME = os.getenv("QDRANT_COLLECTION_QPOLL_NAME", "qpoll_vectors_v2")
        
        query_filter = Filter(
            must=[
                FieldCondition(key="question", match=MatchValue(value=question_text))
            ]
        )
        
        all_points = []
        next_offset = None
        
        while True:
            points, next_offset = client.scroll(
                collection_name=COLLECTION_NAME,
                scroll_filter=query_filter,
                limit=1000, 
                offset=next_offset,
                with_payload=True,
                with_vectors=False
            )
            all_points.extend(points)
            if next_offset is None:
                break
                
        total_count = len(all_points)
        
        if total_count == 0:
            return {}

        sentence_counts = Counter(p.payload.get("sentence") for p in all_points if p.payload and p.payload.get("sentence"))
        
        distribution = {
            sentence: round((count / total_count) * 100, 1)
            for sentence, count in sentence_counts.most_common(limit)
        }
        
        logging.info(f" Â  ğŸ“Š Q-Poll Qdrant ì§‘ê³„ ì™„ë£Œ: {qpoll_field} ({len(distribution)}ê°œ ì¹´í…Œê³ ë¦¬)")
        return distribution
        
    except Exception as e:
        logging.error(f" Â  Q-Poll Qdrant ì§‘ê³„ ì‹¤íŒ¨: {e}", exc_info=True)
        return {}

def create_chart_data_optimized(
    keyword: str,
    field_name: str,
    korean_name: str,
    panels_data: List[Dict],
    use_full_db: bool = False,
    max_categories: int = 10
) -> Dict:
    """
    ì°¨íŠ¸ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    """
    if use_full_db:
        logging.info(f"       â†’ DB ì§‘ê³„ë¡œ '{field_name}' ë¶„ì„ (ìµœì í™”)")
        distribution = get_field_distribution_from_db(field_name, max_categories)
        
        if not distribution:
            return {
                "topic": korean_name,
                "description": f"'{keyword}' ê´€ë ¨ ì „ì²´ ë°ì´í„°ë¥¼ ì¡°íšŒí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                "ratio": "0.0%",
                "chart_data": []
            }
        
        top_category, top_ratio = find_top_category(distribution)
        description_prefix = f"ì „ì²´ ë°ì´í„° ê¸°ì¤€ '{korean_name}' ë¶„ì„:"
        
        return {
            "topic": f"{korean_name} ë¶„í¬",
            "description": f"{description_prefix} {top_ratio}%ê°€ '{top_category}'ì…ë‹ˆë‹¤.",
            "ratio": f"{top_ratio}%",
            "chart_data": [{"label": korean_name, "values": distribution}]
        }
    
    else:
        values = extract_field_values(panels_data, field_name)
        
        if not values:
            return { "topic": korean_name, "description": "ë°ì´í„° ë¶€ì¡±", "ratio": "0.0%", "chart_data": [] }
        
        distribution = calculate_distribution(values)
        filtered_distribution = {k: v for k, v in distribution.items() if v > 0.0}
        
        if not filtered_distribution:
            return { "topic": korean_name, "description": "ë°ì´í„° ë¶€ì¡±", "ratio": "0.0%", "chart_data": [] }
        
        if len(filtered_distribution) > max_categories:
            sorted_items = sorted(filtered_distribution.items(), key=lambda x: x[1], reverse=True)
            top_items = dict(sorted_items[:max_categories - 1])
            other_sum = sum(v for k, v in sorted_items[max_categories - 1:])
            if other_sum > 0:
                top_items['ê¸°íƒ€'] = round(other_sum, 1)
            final_distribution = top_items
        else:
            final_distribution = filtered_distribution
        
        top_category, top_ratio = find_top_category(final_distribution)
        
        return {
            "topic": f"{korean_name} ë¶„í¬",
            "description": f"'{keyword}' ê²€ìƒ‰ ê²°ê³¼: {top_ratio}%ê°€ '{top_category}'ì…ë‹ˆë‹¤.",
            "ratio": f"{top_ratio}%",
            "chart_data": [{
                "label": korean_name,
                "values": final_distribution
            }]
        }

def create_qpoll_chart_data(
    qpoll_field: str,
    max_categories: int = 10
) -> Dict:
    """
    Q-Poll ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ ì°¨íŠ¸ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    """
    question_text = QPOLL_FIELD_TO_TEXT.get(qpoll_field, qpoll_field) 
    logging.info(f" Â  Â  Â  â†’ Q-Poll Qdrant ì§‘ê³„ë¡œ '{qpoll_field}' ë¶„ì„")
    
    distribution = get_qpoll_distribution_from_db(qpoll_field, max_categories)
    
    if not distribution:
        return {
            "topic": question_text,
            "description": f"'{question_text}' ê´€ë ¨ Q-Poll ë°ì´í„°ë¥¼ ì¡°íšŒí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
            "ratio": "0.0%",
            "chart_data": []
        }
    
    final_distribution = distribution
    
    top_category, top_ratio = find_top_category(final_distribution)
    
    is_array_type = "ëª¨ë‘ ì„ íƒí•´ì£¼ì„¸ìš”" in question_text

    if is_array_type:
        description = f"Q-Poll ì‘ë‹µì ê¸°ì¤€, ê°€ì¥ ë§ì€ ì‘ë‹µì€ '{top_category}'ë¡œ {top_ratio}%ì…ë‹ˆë‹¤. (ë³µìˆ˜ ì‘ë‹µ ê°€ëŠ¥)"
    else:
        description = f"Q-Poll ì‘ë‹µì ê¸°ì¤€, {top_ratio}%ê°€ '{top_category}'ì…ë‹ˆë‹¤."
        
    return {
        "topic": question_text, 
        "description": description,
        "ratio": f"{top_ratio}%",
        "chart_data": [{
            "label": question_text,
            "values": final_distribution
        }]
    }

def create_crosstab_chart(
    panels_data: List[Dict],
    field1: str,
    field2: str,
    field1_korean: str,
    field2_korean: str,
    max_categories: int = 5
) -> Dict:
    """
    êµì°¨ ë¶„ì„ ì°¨íŠ¸ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. (ì˜ˆ: ì—°ë ¹ëŒ€ë³„ ì„±ë³„ ë¶„í¬)
    """
    logging.info(f"       â†’ êµì°¨ ë¶„ì„ìœ¼ë¡œ '{field1}' vs '{field2}' ë¶„ì„")
    from utils import get_age_group

    crosstab_data = {}
    for item in panels_data:
        val1 = item.get(field1)
        val2 = item.get(field2)

        if val1 is None or val2 is None:
            continue

        key1 = get_age_group(val1) if field1 == 'birth_year' else str(val1)
        key2 = str(val2)

        if key1 not in crosstab_data:
            crosstab_data[key1] = []
        crosstab_data[key1].append(key2)

    if not crosstab_data:
        return {}

    chart_values = {}
    for key1, values2 in crosstab_data.items():
        distribution = calculate_distribution(values2)
        chart_values[key1] = distribution

    if len(chart_values) > max_categories:
        # ê° ì¹´í…Œê³ ë¦¬ì˜ ì „ì²´ ê°œìˆ˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
        sorted_keys = sorted(chart_values.keys(), key=lambda k: sum(crosstab_data[k].count(v) for v in set(crosstab_data[k])), reverse=True)
        chart_values = {k: chart_values[k] for k in sorted_keys[:max_categories]}

    if not chart_values:
        return {}

    return {
        "topic": f"{field1_korean}ë³„ {field2_korean} ë¶„í¬",
        "description": f"'{field1_korean}'ì— ë”°ë¥¸ '{field2_korean}'ì˜ ìƒëŒ€ì  ë¶„í¬ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.",
        "chart_type": "crosstab",
        "chart_data": [{"label": f"{field1_korean}ë³„ {field2_korean}", "values": chart_values}]
    }


def _analyze_fields_in_parallel(panels_data: List[Dict], candidate_fields: List[Tuple[str, str]]) -> List[Dict]:
    """
    panels_dataë¥¼ í•œ ë²ˆë§Œ ìˆœíšŒí•˜ì—¬ ëª¨ë“  í›„ë³´ í•„ë“œì˜ ê°’ì„ ì§‘ê³„í•˜ê³  ë¶„í¬ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    """
    field_values = {field_name: [] for field_name, _ in candidate_fields}
    field_map = dict(candidate_fields)

    for item in panels_data:
        for field_name in field_values.keys():
            value = item.get(field_name)
            if value is None:
                continue

            if field_name == "birth_year":
                from utils import get_age_group
                field_values[field_name].append(get_age_group(value))
            elif isinstance(value, list):
                field_values[field_name].extend(value)
            else:
                field_values[field_name].append(value)

    results = []
    for field_name, values in field_values.items():
        if not values:
            continue
        
        try:
            distribution = calculate_distribution(values)
            filtered_distribution = {k: v for k, v in distribution.items() if v > 0.0}
            if not filtered_distribution:
                continue

            results.append({
                "field": field_name,
                "korean_name": field_map[field_name],
                "distribution": filtered_distribution,
            })
        except Exception as e:
            logging.warning(f"   âš ï¸  {field_name} ë¶„í¬ ê³„ì‚° ì‹¤íŒ¨: {e}")

    return results


def find_high_ratio_fields_optimized(
    panels_data: List[Dict], 
    exclude_fields: List[str], 
    threshold: float = 50.0,
    max_charts: int = 3
) -> List[Dict]:
    """
    ê²€ìƒ‰ ê²°ê³¼(panels_data) ë‚´ì—ì„œ ë†’ì€ ë¹„ìœ¨ì„ ì°¨ì§€í•˜ëŠ” í•„ë“œë¥¼ ì°¾ìŠµë‹ˆë‹¤.
    """
    candidate_fields = []
    
    for field_name, korean_name in WELCOME_OBJECTIVE_FIELDS:
        if field_name not in exclude_fields:
            candidate_fields.append((field_name, korean_name))
    
    if not candidate_fields:
        return []
    
    logging.info(f"   ğŸ” {len(candidate_fields)}ê°œ í•„ë“œ ë³‘ë ¬ ë¶„ì„ ì¤‘... (ì œì™¸ í•„ë“œ: {exclude_fields})")
    
    analysis_results = _analyze_fields_in_parallel(panels_data, candidate_fields)
    
    high_ratio_results = []
    for result in analysis_results:
        distribution = result['distribution']
        
        top_category, top_ratio = find_top_category(distribution)
        
        if top_ratio >= threshold:
        
            final_distribution = distribution
            if len(distribution) > 10:
                sorted_items = sorted(distribution.items(), key=lambda x: x[1], reverse=True)
                top_items = dict(sorted_items[:9])
                other_sum = sum(v for k, v in sorted_items[9:])
                if other_sum > 0:
                    top_items['ê¸°íƒ€'] = round(other_sum, 1)
                final_distribution = top_items
            
            high_ratio_results.append({
                "field": result['field'],
                "korean_name": result['korean_name'],
                "distribution": final_distribution,
                "top_category": top_category,
                "top_ratio": top_ratio
            })
    
    high_ratio_results.sort(key=lambda x: x["top_ratio"], reverse=True)
    
    return high_ratio_results[:max_charts]

def _generate_no_results_tips(classified_keywords: dict) -> str:
    """
    ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ì„ ë•Œ ì‚¬ìš©ìì—ê²Œ ë³´ì—¬ì¤„ ë™ì  ë„ì›€ë§ì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    tips = []
    objective_kws = classified_keywords.get('objective_keywords', [])
    mandatory_kws = classified_keywords.get('mandatory_keywords', [])
    vector_kws = classified_keywords.get('vector_keywords', [])
    
    total_filter_kws = len(objective_kws) + len(mandatory_kws)

    if total_filter_kws > 3:
        combined_kws = objective_kws + mandatory_kws
        kws_str = ', '.join(f"'{k}'" for k in combined_kws[:3])
        tips.append(f"í•„í„° ì¡°ê±´({kws_str} ë“±)ì´ ë„ˆë¬´ ë§ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì¡°ê±´ì„ ì¤„ì—¬ë³´ì„¸ìš”.")

    if vector_kws:
        tips.append(f"'{', '.join(vector_kws)}'ì™€ ê°™ì€ í‚¤ì›Œë“œê°€ ë„ˆë¬´ êµ¬ì²´ì ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë” ì¼ë°˜ì ì¸ ë‹¨ì–´ë¡œ ë°”ê¿”ë³´ì„¸ìš”.")

    tips.append("ê²€ìƒ‰ì–´ì— ì˜¤íƒ€ê°€ ì—†ëŠ”ì§€ í™•ì¸í•˜ê±°ë‚˜, 'ì Šì€ì¸µ' ëŒ€ì‹  '20ëŒ€'ì²˜ëŸ¼ ë” ëª…í™•í•œ í‚¤ì›Œë“œë¥¼ ì‚¬ìš©í•´ ë³´ì„¸ìš”.")
    
    summary = "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë” ë‚˜ì€ ê²°ê³¼ë¥¼ ìœ„í•´ ë‹¤ìŒ íŒì„ í™•ì¸í•´ ë³´ì„¸ìš”:\n"
    for i, tip in enumerate(tips, 1):
        summary += f"\n{i}. {tip}"
        
    return summary

def analyze_search_results_optimized(
    query: str,
    classified_keywords: dict,
    panel_id_list: List[str]
) -> Tuple[Dict, int]:
    """
    ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ì—¬ ì°¨íŠ¸ì™€ ìš”ì•½ì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    logging.info(f"ğŸ“Š ë¶„ì„ ì‹œì‘ (ìµœì í™”) - panel_id ìˆ˜: {len(panel_id_list)}ê°œ")
    
    if not panel_id_list:
        summary = _generate_no_results_tips(classified_keywords)
        return {"main_summary": summary, "charts": []}, 200
    
    try:
        logging.info("   1ë‹¨ê³„: íŒ¨ë„ ë°ì´í„° ì¡°íšŒ (utils.py ì‚¬ìš©)")
        panels_data = get_panels_data_from_db(panel_id_list)
        
        if not panels_data:
            return {"main_summary": "íŒ¨ë„ ë°ì´í„°ë¥¼ ì¡°íšŒí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", "charts": []}, 200
        
        logging.info(f"   âœ… {len(panels_data)}ê°œ íŒ¨ë„ ë°ì´í„° ì¡°íšŒ ì™„ë£Œ")
        
        raw_keywords = classified_keywords.get('ranked_keywords_raw', [])
        ranked_keywords = []
        search_used_fields = set()
        
        if raw_keywords:
            logging.info(f"   2aë‹¨ê³„: (ê·œì¹™ ê¸°ë°˜) í‚¤ì›Œë“œ {raw_keywords} ë§¤í•‘ ì‹œì‘")
            for i, keyword in enumerate(raw_keywords):
                
                mapping = get_field_mapping(keyword) 
                kw_type = mapping.get("type", "unknown")
                
                ranked_keywords.append({
                    "keyword": keyword, 
                    "field": mapping["field"],
                    "description": mapping["description"], 
                    "type": kw_type,
                    "priority": i + 1
                })
                
                if kw_type == 'filter' and mapping["field"] != 'unknown':
                    search_used_fields.add(mapping["field"])
        
        if not ranked_keywords:
            logging.warning("   âš ï¸  'ranked_keywords_raw' ì—†ìŒ. (Fallback ë¡œì§ ì‹¤í–‰)")
            obj_keywords = classified_keywords.get('welcome_keywords', {}).get('objective', [])
            for i, kw in enumerate(obj_keywords[:5]):
                mapping = get_field_mapping(kw)
                ranked_keywords.append({
                    'keyword': kw, 
                    'field': mapping["field"],
                    'description': mapping["description"], 
                    'type': mapping.get("type", "unknown"),
                    'priority': i + 1
                })
                if mapping["type"] == 'filter' and mapping["field"] != 'unknown': # [ìˆ˜ì •] type ì²´í¬
                    search_used_fields.add(mapping["field"])
            
        if not ranked_keywords:
            return { "main_summary": f"ì´ {len(panels_data)}ëª… ì¡°íšŒ, ë¶„ì„í•  í‚¤ì›Œë“œ ì—†ìŒ.", "charts": [] }, 200
        
        ranked_keywords.sort(key=lambda x: x.get('priority', 999))
        logging.info(f"   âœ… ë¶„ì„ í‚¤ì›Œë“œ: {[k.get('keyword') for k in ranked_keywords]}")
        logging.info(f"   âœ… ê²€ìƒ‰ ì‚¬ìš© í•„ë“œ (ë»”í•œ ì¸ì‚¬ì´íŠ¸ ì œì™¸ìš©): {search_used_fields}")
        
        logging.info("   3ë‹¨ê³„: ì£¼ìš” í‚¤ì›Œë“œ ì°¨íŠ¸ ìƒì„± (DB ì§‘ê³„, ë³‘ë ¬)")
        charts = []
        used_fields = []
        objective_fields = set([f[0] for f in WELCOME_OBJECTIVE_FIELDS])
        
        chart_tasks = [] 
        chart_count = 0
        for kw_info in ranked_keywords:
            if chart_count >= 2: break
            
            field = kw_info.get('field', '')
            kw_type = kw_info.get('type', 'unknown')
            
            if field in used_fields:
                continue

            if kw_type == 'filter':
                if field in objective_fields and field != 'unknown':
                    if panels_data:
                        chart_tasks.append({"type": "filter", "kw_info": kw_info})
                        used_fields.append(field)
                        chart_count += 1
            
            elif kw_type == 'qpoll': # Q-Poll ë¶„ì„ì€ ì „ì²´ DB ëŒ€ìƒ
                chart_tasks.append({"type": "qpoll", "kw_info": kw_info})
                used_fields.append(field)
                chart_count += 1
        if chart_tasks:
            with ThreadPoolExecutor(max_workers=len(chart_tasks) or 1) as executor:
                
                def run_chart_creation(task):
                    kw_info = task["kw_info"]
                    field = kw_info.get('field', '')
                    korean_name = kw_info.get('description', field)
                    logging.info(f" Â  âš¡ [{korean_name}] ì°¨íŠ¸ DB ì§‘ê³„ ìŠ¤ë ˆë“œ ì‹œì‘ ({task['type']})...")
                    
                    if task["type"] == "filter":
                        return create_chart_data_optimized(
                            kw_info.get('keyword', ''), 
                            field, 
                            korean_name,
                            panels_data,
                            use_full_db=False
                        )
                    elif task["type"] == "qpoll":
                        return create_qpoll_chart_data( 
                            field
                        )
                    
                    return None

                futures = {executor.submit(run_chart_creation, task): task for task in chart_tasks}
                
                for future in as_completed(futures):
                    kw_info_original = futures[future]["kw_info"]
                    field_name = kw_info_original.get('field', 'unknown')
                    try:
                        chart = future.result() 
                        if chart.get('chart_data') and chart.get('ratio') != '0.0%':
                            chart['priority'] = kw_info_original.get('priority', 99)
                            charts.append(chart)
                            logging.info(f"   âœ… [{field_name}] ì°¨íŠ¸ ìƒì„± ì™„ë£Œ (DB ì§‘ê³„)")
                        else:
                            logging.warning(f"   âš ï¸  [{field_name}] ì°¨íŠ¸ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŒ (DB ì§‘ê³„)")
                    except Exception as e:
                        logging.error(f"   âŒ [{field_name}] ì°¨íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}", exc_info=True)
            
            charts.sort(key=lambda x: x.get('priority', 99))
            
            for chart in charts:
                if 'priority' in chart:
                    del chart['priority']

        logging.info("   3.5ë‹¨ê³„: êµì°¨ ë¶„ì„ ì°¨íŠ¸ ìƒì„±")
        if len(charts) < 5 and len(ranked_keywords) > 0:
            
            DEFAULT_CROSSTAB_AXES = [
                ('birth_year', 'ì—°ë ¹ëŒ€'),
                ('gender', 'ì„±ë³„'),
            ]

            if not search_used_fields:
                topic_kw = ranked_keywords[0]
                topic_field = topic_kw.get('field')
                topic_korean_name = topic_kw.get('description')

                if topic_field and topic_field != 'unknown':
                    # ê¸°ë³¸ ì¶•(ì—°ë ¹ëŒ€, ì„±ë³„)ìœ¼ë¡œ êµì°¨ ë¶„ì„ ì‹¤í–‰
                    for axis_field, axis_korean_name in DEFAULT_CROSSTAB_AXES:
                        if len(charts) >= 5: break
                        
                        if topic_field == axis_field: continue

                        crosstab_chart = create_crosstab_chart(
                            panels_data, axis_field, topic_field, axis_korean_name, topic_korean_name)
                        if crosstab_chart and crosstab_chart.get("chart_data"):
                            charts.append(crosstab_chart)
                            logging.info(f"   âœ… [{len(charts)}] êµì°¨ ë¶„ì„ ì°¨íŠ¸ ìƒì„± ({axis_korean_name} vs {topic_korean_name})")

            else:
                CROSSTAB_CANDIDATES = [
                    ('gender', 'ì„±ë³„'), ('birth_year', 'ì—°ë ¹ëŒ€'), ('marital_status', 'ê²°í˜¼ ì—¬ë¶€'),
                    ('income_personal_monthly', 'ì†Œë“ ìˆ˜ì¤€'), ('job_duty_raw', 'ì§ë¬´'), ('job_title_raw', 'ì§ì—…'),
                ]

                primary_kw = next((kw for kw in ranked_keywords if kw.get("type") == "filter"), None)

                if primary_kw:
                    primary_field = primary_kw.get('field')
                    primary_korean_name = primary_kw.get('description')

                    secondary_field_info = next((
                        (field, korean) for field, korean in CROSSTAB_CANDIDATES 
                        if field != primary_field and field not in search_used_fields
                    ), None)

                    if secondary_field_info:
                        secondary_field, secondary_korean_name = secondary_field_info
                        if primary_field in search_used_fields and secondary_field in search_used_fields:
                            logging.warning(f"   âš ï¸  êµì°¨ ë¶„ì„ ìŠ¤í‚µ: ì£¼ì¶•({primary_korean_name})ê³¼ ë³´ì¡°ì¶•({secondary_korean_name})ì´ ëª¨ë‘ ê²€ìƒ‰ ì¡°ê±´ì— í¬í•¨ë¨")
                            pass

                        logging.info(f"   âœ¨ ìƒˆ êµì°¨ë¶„ì„ ì¶• ë°œê²¬: '{primary_korean_name}' vs '{secondary_korean_name}'")
                        
                        crosstab_chart = create_crosstab_chart(
                            panels_data,
                            primary_field, secondary_field,
                            primary_korean_name, secondary_korean_name
                        )
                        if crosstab_chart and crosstab_chart.get("chart_data"):
                            charts.append(crosstab_chart)
                            if primary_field not in used_fields: used_fields.append(primary_field)
                            if secondary_field not in used_fields: used_fields.append(secondary_field)
                            logging.info(f"   âœ… [{len(charts)}] êµì°¨ ë¶„ì„ ì°¨íŠ¸ ìƒì„± ({primary_korean_name} vs {secondary_korean_name})")
                    else:
                        logging.warning("   âš ï¸  êµì°¨ ë¶„ì„ ìŠ¤í‚µ: ì ì ˆí•œ ë³´ì¡°ì¶• í›„ë³´ê°€ ì—†ìŒ (ëª¨ë‘ ê²€ìƒ‰ì–´ì— í¬í•¨ë¨)")
                else:
                    logging.warning("   âš ï¸  êµì°¨ ë¶„ì„ ìŠ¤í‚µ: 1ìˆœìœ„ í•„í„° í‚¤ì›Œë“œê°€ ì—†ìŒ")
                
        logging.info("   4ë‹¨ê³„: ë†’ì€ ë¹„ìœ¨ í•„ë“œ ì°¨íŠ¸ ìƒì„± (ê²€ìƒ‰ ê²°ê³¼ ê¸°ë°˜)")
        needed_charts = 5 - len(charts)
        exclude_fields_for_step4 = list(set(used_fields) | search_used_fields)
        
        if needed_charts > 0:
            high_ratio_fields = find_high_ratio_fields_optimized(
                panels_data, 
                exclude_fields=exclude_fields_for_step4,
                threshold=50.0,
                max_charts=needed_charts
            )
            
            for field_info in high_ratio_fields:
                if len(charts) >= 5: break
                
                chart = {
                    "topic": f"{field_info['korean_name']} ë¶„í¬",
                    "description": f"{field_info['top_ratio']:.1f}%ê°€ '{field_info['top_category']}'ë¡œ ëšœë ·í•œ íŒ¨í„´ì„ ë³´ì…ë‹ˆë‹¤.",
                    "ratio": f"{field_info['top_ratio']:.1f}%",
                    "chart_data": [{"label": field_info['korean_name'], "values": field_info['distribution']}]
                }
                charts.append(chart)
                logging.info(f"   âœ… [{len(charts)}] {field_info['korean_name']} ({field_info['top_ratio']:.1f}%) ì°¨íŠ¸ ìƒì„±")
        
        main_summary = f"ì´ {len(panels_data)}ëª…ì˜ ì‘ë‹µì ë°ì´í„°ë¥¼ ë¶„ì„í–ˆìŠµë‹ˆë‹¤. "
        if charts:
            top_chart = charts[0]
            summary_desc = top_chart.get('description', '')
            if 'ì „ì²´ ë°ì´í„° ê¸°ì¤€' in summary_desc:
                summary_desc = summary_desc.split(':', 1)[-1].strip()
            elif ':' in summary_desc:
                 summary_desc = summary_desc.split(':', 1)[-1].strip()
            
            main_summary += f"ì£¼ìš” ë¶„ì„ ê²°ê³¼: {top_chart.get('topic', '')}ì—ì„œ {top_chart.get('ratio', '0%')}ì˜ ë¹„ìœ¨ì„ ë³´ì…ë‹ˆë‹¤."
        
        result = {
            "query": query,
            "total_count": len(panels_data),
            "main_summary": main_summary,
            "charts": charts
        }
        
        logging.info(f"âœ… ë¶„ì„ ì™„ë£Œ: {len(charts)}ê°œ ì°¨íŠ¸ ìƒì„± (ìµœì í™”)")
        return result, 200
        
    except Exception as e:
        logging.error(f"âŒ ë¶„ì„ ì‹¤íŒ¨: {e}", exc_info=True)
        return {"main_summary": f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", "charts": []}, 500