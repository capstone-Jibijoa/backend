import os
import logging
import re 
from typing import List, Dict, Any, Tuple
from collections import Counter, defaultdict
from concurrent.futures import ThreadPoolExecutor, as_completed
from qdrant_client.http.models import Filter, FieldCondition, MatchValue
import numpy as np
from sklearn.cluster import DBSCAN
from search_helpers import initialize_embeddings 

from utils import (
    extract_field_values,
    calculate_distribution,
    find_top_category,
    FIELD_NAME_MAP,
    WELCOME_OBJECTIVE_FIELDS,
    get_panels_data_from_db,
    get_age_group
)
# [í•„ìˆ˜] í…œí”Œë¦¿ import
from mapping_rules import get_field_mapping, QPOLL_FIELD_TO_TEXT, QPOLL_ANSWER_TEMPLATES
from db import get_db_connection_context, get_qdrant_client


def _clean_label(text: Any, max_length: int = 12) -> str:
    """ê¸°ë³¸ ë¼ë²¨ ì •ì œ í•¨ìˆ˜"""
    if not text: return ""
    text_str = str(text)
    cleaned = re.sub(r'\([^)]*\)', '', text_str).strip()
    cleaned = " ".join(cleaned.split())
    if len(cleaned) > max_length:
        return cleaned[:max_length] + ".."
    return cleaned

def _extract_core_value(field_name: str, sentence: str) -> str:
    """
    [ì§€ëŠ¥í˜• ìˆ˜ì •] í…œí”Œë¦¿ì„ ì—­ì„¤ê³„í•˜ì—¬ í•µì‹¬ ë‹µë³€ë§Œ ìë™ ì¶”ì¶œí•©ë‹ˆë‹¤.
    """
    if not sentence: return ""
    
    # 1. ìˆ«ì ë°ì´í„° ë“± íŠ¹ìˆ˜ ì²˜ë¦¬ê°€ í•„ìš”í•œ í•„ë“œëŠ” ê¸°ì¡´ ë¡œì§ ìœ ì§€ (ì •í™•ë„ ìµœìš°ì„ )
    if field_name == "ott_count":
        match = re.search(r'(\d+ê°œ|ì´ìš© ì•ˆ í•¨|ì—†ìŒ)', sentence)
        if match: return match.group(1)
    elif field_name == "skincare_spending":
        match = re.search(r'(\d+ë§Œ\s*ì›|\d+~\d+ë§Œ\s*ì›|\d+ì›)', sentence)
        if match: return match.group(1)

    # 2. QPOLL_ANSWER_TEMPLATESë¥¼ ì´ìš©í•œ ë™ì  ì¶”ì¶œ
    template = QPOLL_ANSWER_TEMPLATES.get(field_name)
    if template:
        try:
            # 2-1. í…œí”Œë¦¿ì„ ì •ê·œì‹ íŒ¨í„´ìœ¼ë¡œ ë³€í™˜í•˜ê¸° ìœ„í•´ íŠ¹ìˆ˜ë¬¸ì ì´ìŠ¤ì¼€ì´í”„
            # ì˜ˆ: "ì´ì‚¬í•  ë•Œ {answer_str}(ìœ¼)ë¡œ..." -> "ì´ì‚¬í• \ ë•Œ\ \{answer_str\}\(ìœ¼\)ë¡œ\.\.\."
            pattern_str = re.escape(template)

            # 2-2. {answer_str} ë¶€ë¶„ì„ ìº¡ì²˜ ê·¸ë£¹ (.*?) ìœ¼ë¡œ ë³€ê²½
            # re.escapeë¡œ ì¸í•´ \{answer_str\} í˜•íƒœê°€ ë˜ì—ˆì„ ê²ƒì„
            pattern_str = pattern_str.replace(re.escape("{answer_str}"), r"(.*?)")

            # 2-3. í•œêµ­ì–´ ì¡°ì‚¬ ìœ ì—°ì„± ì²˜ë¦¬
            # í…œí”Œë¦¿ì˜ (ì´)ë‹¤ -> (?:ì´)?ë‹¤ ( 'ì´'ëŠ” ìˆì–´ë„ ë˜ê³  ì—†ì–´ë„ ë¨)
            pattern_str = pattern_str.replace(r"\(ì´\)ë‹¤", r"(?:ì´)?ë‹¤")
            pattern_str = pattern_str.replace(r"\(ìœ¼\)ë¡œ", r"(?:ìœ¼)?ë¡œ")
            pattern_str = pattern_str.replace(r"\(ê°€\)", r"(?:ê°€)?")
            
            # 2-4. ê³µë°± ìœ ì—°ì„± (í…œí”Œë¦¿ê³¼ ì‹¤ì œ ë°ì´í„°ì˜ ë„ì–´ì“°ê¸°ê°€ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ)
            pattern_str = pattern_str.replace(r"\ ", r"\s*")

            # 2-5. ë§¤ì¹­ ì‹œë„
            match = re.search(pattern_str, sentence)
            if match:
                # ìº¡ì²˜ëœ ë‚´ìš©(í•µì‹¬ ë‹µë³€) ë°˜í™˜
                extracted = match.group(1)
                return _clean_label(extracted)
        except Exception as e:
            logging.warning(f"í…œí”Œë¦¿ ì¶”ì¶œ ì‹¤íŒ¨ ({field_name}): {e}")

    # 3. í…œí”Œë¦¿ ë§¤ì¹­ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ì •ì œ ë°˜í™˜
    return _clean_label(sentence)


def _limit_distribution_top_k(distribution: Dict[str, float], k: int = 7) -> Dict[str, float]:
    """ìƒìœ„ Kê°œ + ê¸°íƒ€ë¡œ ì œí•œ"""
    if not distribution or len(distribution) <= k:
        return distribution
    
    sorted_items = sorted(distribution.items(), key=lambda x: x[1], reverse=True)
    top_items = dict(sorted_items[:k])
    
    other_sum = sum(v for _, v in sorted_items[k:])
    if other_sum > 0:
        top_items['ê¸°íƒ€'] = round(other_sum, 1)
            
    return top_items


def get_field_distribution_from_db(field_name: str, limit: int = 10) -> Dict[str, float]:
    """PostgreSQL ì§ì ‘ ì§‘ê³„"""
    try:
        with get_db_connection_context() as conn:
            if not conn: return {}
            cur = conn.cursor()
            
            if field_name == "birth_year":
                query = f"""
                    WITH age_groups AS (
                        SELECT 
                            CASE 
                                WHEN (date_part('year', CURRENT_DATE) - (structured_data->>'birth_year')::int) < 20 THEN '10ëŒ€'
                                WHEN (date_part('year', CURRENT_DATE) - (structured_data->>'birth_year')::int) < 30 THEN '20ëŒ€'
                                WHEN (date_part('year', CURRENT_DATE) - (structured_data->>'birth_year')::int) < 40 THEN '30ëŒ€'
                                WHEN (date_part('year', CURRENT_DATE) - (structured_data->>'birth_year')::int) < 50 THEN '40ëŒ€'
                                WHEN (date_part('year', CURRENT_DATE) - (structured_data->>'birth_year')::int) < 60 THEN '50ëŒ€'
                                ELSE '60ëŒ€ ì´ìƒ'
                            END as age_group
                        FROM welcome_meta2
                        WHERE structured_data->>'birth_year' IS NOT NULL
                    )
                    SELECT age_group, COUNT(*), ROUND(COUNT(*) * 100.0 / SUM(COUNT(*)) OVER (), 1)
                    FROM age_groups GROUP BY age_group ORDER BY 3 DESC LIMIT {limit}
                """
            else:
                query = f"""
                    SELECT structured_data->>'{field_name}', COUNT(*), ROUND(COUNT(*) * 100.0 / SUM(COUNT(*)) OVER (), 1)
                    FROM welcome_meta2
                    WHERE structured_data->>'{field_name}' IS NOT NULL
                    GROUP BY 1 ORDER BY 3 DESC LIMIT {limit}
                """
            
            cur.execute(query)
            rows = cur.fetchall()
            cur.close()
            return {row[0]: float(row[2]) for row in rows if row[0]}
            
    except Exception as e:
        logging.error(f"DB ì§‘ê³„ ì‹¤íŒ¨ ({field_name}): {e}")
        return {}
    
def get_qpoll_distribution_from_db(qpoll_field: str, limit: int = 10) -> Dict[str, float]:
    """Qdrant ì§‘ê³„ (ìë™ ì¶”ì¶œ ì ìš©)"""
    question_text = QPOLL_FIELD_TO_TEXT.get(qpoll_field)
    if not question_text: return {}
    
    client = get_qdrant_client()
    if not client: return {}
        
    try:
        COLLECTION_NAME = os.getenv("QDRANT_COLLECTION_QPOLL_NAME", "qpoll_vectors_v2")
        query_filter = Filter(must=[FieldCondition(key="question", match=MatchValue(value=question_text))])
        
        all_points = []
        next_offset = None
        while True:
            points, next_offset = client.scroll(
                collection_name=COLLECTION_NAME, scroll_filter=query_filter, limit=1000, offset=next_offset, with_payload=True, with_vectors=False
            )
            all_points.extend(points)
            if next_offset is None: break
        
        if not all_points: return {}

        extracted_values = []
        for p in all_points:
            if p.payload and p.payload.get("sentence"):
                raw_sentence = p.payload.get("sentence")
                # [í•µì‹¬] í…œí”Œë¦¿ ê¸°ë°˜ ìë™ ì¶”ì¶œ ì‹¤í–‰
                core_val = _extract_core_value(qpoll_field, raw_sentence)
                if core_val:
                    extracted_values.append(core_val)
        
        total_count = len(extracted_values)
        if total_count == 0: return {}

        val_counts = Counter(extracted_values)
        
        return {
            k: round((v / total_count) * 100, 1)
            for k, v in val_counts.most_common(limit)
        }
        
    except Exception as e:
        logging.error(f"Q-Poll ì§‘ê³„ ì‹¤íŒ¨: {e}")
        return {}

def create_chart_data_optimized(
    keyword: str,
    field_name: str,
    korean_name: str,
    panels_data: List[Dict],
    use_full_db: bool = False,
    max_categories: int = 7
) -> Dict:
    """ì°¨íŠ¸ ë°ì´í„° ìƒì„±"""
    if use_full_db:
        logging.info(f"       â†’ DB ì§‘ê³„ë¡œ '{field_name}' ë¶„ì„ (ìµœì í™”)")
        distribution = get_field_distribution_from_db(field_name, max_categories)
        
        if not distribution:
            return {"topic": korean_name, "ratio": "0.0%", "chart_data": [], "description": "ë°ì´í„° ì—†ìŒ"}
        
        cleaned_distribution = defaultdict(float)
        for k, v in distribution.items():
            cleaned_distribution[_clean_label(k)] += v
            
        final_distribution = _limit_distribution_top_k(dict(cleaned_distribution), max_categories)
        top_category, top_ratio = find_top_category(final_distribution)
        
        return {
            "topic": f"{korean_name} ë¶„í¬",
            "description": f"ì „ì²´ ê¸°ì¤€: {top_ratio}%ê°€ '{top_category}'ì…ë‹ˆë‹¤.",
            "ratio": f"{top_ratio}%",
            "chart_data": [{"label": korean_name, "values": final_distribution}],
            "field": field_name 
        }
    
    else:
        values = []
        raw_values = [item.get(field_name) for item in panels_data if item.get(field_name)]
        
        for val in raw_values:
            if isinstance(val, list):
                for v in val:
                    cleaned = _clean_label(v)
                    if cleaned: values.append(cleaned)
            elif val is not None:
                cleaned = _clean_label(val)
                if cleaned: values.append(cleaned)
        
        if not values:
            return { "topic": korean_name, "description": "ë°ì´í„° ë¶€ì¡±", "ratio": "0.0%", "chart_data": [], "field": field_name }
        
        distribution = calculate_distribution(values)
        final_distribution = _limit_distribution_top_k(distribution, max_categories)
        top_category, top_ratio = find_top_category(final_distribution)
        
        return {
            "topic": f"{korean_name} ë¶„í¬",
            "description": f"ê²€ìƒ‰ ê²°ê³¼: {top_ratio}%ê°€ '{top_category}'ì…ë‹ˆë‹¤.",
            "ratio": f"{top_ratio}%",
            "chart_data": [{"label": korean_name, "values": final_distribution}],
            "field": field_name
        }

def create_qpoll_chart_data(qpoll_field: str, max_categories: int = 7) -> Dict:
    """Q-Poll ì°¨íŠ¸ ë°ì´í„° ìƒì„±"""
    question_text = QPOLL_FIELD_TO_TEXT.get(qpoll_field, qpoll_field) 
    
    distribution = get_qpoll_distribution_from_db(qpoll_field, max_categories)
    
    if not distribution:
        return {"topic": question_text, "ratio": "0.0%", "chart_data": [], "description": "ë°ì´í„° ì—†ìŒ", "field": qpoll_field}
    
    top_category, top_ratio = find_top_category(distribution)
    
    # ì„¤ëª…(Description)ì€ í…œí”Œë¦¿ì„ ì‚¬ìš©í•´ ìì—°ìŠ¤ëŸ½ê²Œ
    template = QPOLL_ANSWER_TEMPLATES.get(qpoll_field)
    if template and top_category != "ê¸°íƒ€":
        try:
            formatted_answer = template.format(answer_str=f"'{top_category}'")
            description = f"ê°€ì¥ ë§ì€ ì‘ë‹µìëŠ” {formatted_answer} ({top_ratio}%)"
        except:
            description = f"ê°€ì¥ ë§ì€ ì‘ë‹µì€ '{top_category}'({top_ratio}%)ì…ë‹ˆë‹¤."
    else:
        description = f"ê°€ì¥ ë§ì€ ì‘ë‹µì€ '{top_category}'({top_ratio}%)ì…ë‹ˆë‹¤."

    return {
        "topic": question_text, 
        "description": description,
        "ratio": f"{top_ratio}%",
        "chart_data": [{"label": question_text, "values": distribution}],
        "field": qpoll_field
    }

def create_crosstab_chart(
    panels_data: List[Dict],
    field1: str,
    field2: str,
    field1_korean: str,
    field2_korean: str,
    max_categories: int = 5
) -> Dict:
    """êµì°¨ ë¶„ì„ ì°¨íŠ¸ ìƒì„±"""
    logging.info(f"       â†’ êµì°¨ ë¶„ì„: '{field1}' vs '{field2}'")
    
    all_values_field2 = []
    for item in panels_data:
        val2 = item.get(field2)
        if not val2: continue
        
        if isinstance(val2, list):
            for v in val2:
                cleaned = _clean_label(v)
                if cleaned: all_values_field2.append(cleaned)
        else:
            cleaned = _clean_label(val2)
            if cleaned: all_values_field2.append(cleaned)
            
    if not all_values_field2:
        return {}

    global_counter = Counter(all_values_field2)
    top_7_keys = [k for k, v in global_counter.most_common(7)]
    top_7_set = set(top_7_keys)

    crosstab_data = {} 

    for item in panels_data:
        val1 = item.get(field1)
        val2 = item.get(field2)
        
        if val1 is None or val2 is None: continue

        raw_key1 = get_age_group(val1) if field1 == 'birth_year' else str(val1)
        key1 = _clean_label(raw_key1)
        
        if key1 not in crosstab_data:
            crosstab_data[key1] = []
            
        values_to_process = val2 if isinstance(val2, list) else [val2]
        
        for v in values_to_process:
            cleaned_v = _clean_label(v)
            if not cleaned_v: continue
            
            if cleaned_v in top_7_set:
                crosstab_data[key1].append(cleaned_v)
            else:
                crosstab_data[key1].append("ê¸°íƒ€")

    if not crosstab_data:
        return {}

    if len(crosstab_data) <= 1:
        only_group = list(crosstab_data.keys())[0]
        distribution = calculate_distribution(crosstab_data[only_group])
        final_distribution = _limit_distribution_top_k(distribution, k=7)
        
        return {
            "topic": f"{field1_korean}ë³„ {field2_korean} ë¶„í¬ ({only_group})",
            "description": f"'{only_group}' ì§‘ë‹¨ì˜ '{field2_korean}' ë¶„í¬ì…ë‹ˆë‹¤.",
            "chart_type": "pie", 
            "chart_data": [{"label": field2_korean, "values": final_distribution}],
            "fields": [field1, field2]
        }

    chart_values = {}
    sorted_groups = sorted(crosstab_data.keys(), key=lambda k: len(crosstab_data[k]), reverse=True)
    target_groups = sorted_groups[:max_categories]

    for group in target_groups:
        items = crosstab_data[group]
        distribution = calculate_distribution(items)
        chart_values[group] = _limit_distribution_top_k(distribution, k=7)

    return {
        "topic": f"{field1_korean}ë³„ {field2_korean} ë¶„í¬",
        "description": f"'{field1_korean}'ì— ë”°ë¥¸ ì£¼ìš” '{field2_korean}' ë¶„í¬ì…ë‹ˆë‹¤.",
        "chart_type": "crosstab",
        "chart_data": [{"label": f"{field1_korean}ë³„ {field2_korean}", "values": chart_values}],
        "fields": [field1, field2] 
    }

def _analyze_fields_in_parallel(panels_data: List[Dict], candidate_fields: List[Tuple[str, str]]) -> List[Dict]:
    """ë³‘ë ¬ í•„ë“œ ë¶„ì„"""
    field_values = {fname: [] for fname, _ in candidate_fields}
    field_map = dict(candidate_fields)

    for item in panels_data:
        for fname in field_values.keys():
            val = item.get(fname)
            if val is None: continue

            if fname == "birth_year":
                field_values[fname].append(get_age_group(val))
            elif isinstance(val, list):
                for v in val:
                    cleaned = _clean_label(v)
                    if cleaned: field_values[fname].append(cleaned)
            else:
                cleaned = _clean_label(val)
                if cleaned: field_values[fname].append(cleaned)

    results = []
    for fname, vals in field_values.items():
        if not vals: continue
        try:
            dist = calculate_distribution(vals)
            final_dist = _limit_distribution_top_k(dist, k=7)
            if not final_dist: continue
            
            results.append({
                "field": fname,
                "korean_name": field_map[fname],
                "distribution": final_dist,
            })
        except: pass
    return results


def find_high_ratio_fields_optimized(
    panels_data: List[Dict], 
    exclude_fields: List[str], 
    threshold: float = 50.0,
    max_charts: int = 3
) -> List[Dict]:
    """ë†’ì€ ë¹„ìœ¨ í•„ë“œ ì°¾ê¸°"""
    candidate_fields = []
    for fname, kname in WELCOME_OBJECTIVE_FIELDS:
        if fname not in exclude_fields:
            candidate_fields.append((fname, kname))
    
    if not candidate_fields: return []
    
    analysis_results = _analyze_fields_in_parallel(panels_data, candidate_fields)
    
    high_ratio_results = []
    for result in analysis_results:
        distribution = result['distribution']
        top_category, top_ratio = find_top_category(distribution)
        
        if top_ratio >= threshold:
            if top_ratio >= 98.0:
                continue

            high_ratio_results.append({
                "field": result['field'],
                "korean_name": result['korean_name'],
                "distribution": distribution,
                "top_category": top_category,
                "top_ratio": top_ratio
            })
    
    high_ratio_results.sort(key=lambda x: x["top_ratio"], reverse=True)
    return high_ratio_results[:max_charts]

def _generate_no_results_tips(classified_keywords: dict) -> str:
    tips = []
    if len(classified_keywords.get('objective_keywords', [])) > 3:
        tips.append("í•„í„° ì¡°ê±´ì´ ë„ˆë¬´ ë§ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    tips.append("ë” ì¼ë°˜ì ì¸ í‚¤ì›Œë“œë¥¼ ì‚¬ìš©í•´ ë³´ì„¸ìš”.")
    return "\n".join(tips)

def analyze_search_results_optimized(
    query: str,
    classified_keywords: dict,
    panel_id_list: List[str]
) -> Tuple[Dict, int]:
    """
    ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ì—¬ ì°¨íŠ¸ì™€ ìš”ì•½ì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    logging.info(f"ğŸ“Š ë¶„ì„ ì‹œì‘ (ìµœì í™”) - panel_id ìˆ˜: {len(panel_id_list)}ê°œ")
    
    if not panel_id_list:
        summary = _generate_no_results_tips(classified_keywords)
        return {"main_summary": summary, "charts": []}, 200
    
    try:
        logging.info("   1ë‹¨ê³„: íŒ¨ë„ ë°ì´í„° ì¡°íšŒ (utils.py ì‚¬ìš©)")
        panels_data = get_panels_data_from_db(panel_id_list)
        
        if not panels_data:
            return {"main_summary": "íŒ¨ë„ ë°ì´í„°ë¥¼ ì¡°íšŒí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", "charts": []}, 200
        
        logging.info(f"   âœ… {len(panels_data)}ê°œ íŒ¨ë„ ë°ì´í„° ì¡°íšŒ ì™„ë£Œ")
        
        raw_keywords = classified_keywords.get('ranked_keywords_raw', [])
        ranked_keywords = []
        search_used_fields = set()

        # [ê¸°ì¡´ ë¡œì§] ê²€ìƒ‰ì— ì‚¬ìš©ëœ í•„ë“œ ì¶”ì¶œ
        demographic_filters = classified_keywords.get('demographic_filters', {})
        if demographic_filters:
            logging.debug(f"   âœ… demographic_filtersì—ì„œ ê²€ìƒ‰ í•„í„° ì¶”ì¶œ: {demographic_filters}")
            if 'age_range' in demographic_filters:
                search_used_fields.add('birth_year')  
            for key in demographic_filters.keys():
                if key != 'age_range':
                    search_used_fields.add(key)

        structured_filters = classified_keywords.get('structured_filters', [])
        if structured_filters:
            for filter_item in structured_filters:
                field = filter_item.get('field')
                if field and field != 'age':
                    search_used_fields.add(field)
                elif field == 'age':
                    search_used_fields.add('birth_year')

        if raw_keywords:
            logging.debug(f"   2aë‹¨ê³„: (ê·œì¹™ ê¸°ë°˜) í‚¤ì›Œë“œ {raw_keywords} ë§¤í•‘ ì‹œì‘")
            for i, keyword in enumerate(raw_keywords):
                mapping = get_field_mapping(keyword)
                kw_type = mapping.get("type", "unknown")

                ranked_keywords.append({
                    "keyword": keyword,
                    "field": mapping["field"],
                    "description": mapping["description"],
                    "type": kw_type,
                    "priority": i + 1
                })

                if kw_type == 'filter' and mapping["field"] != 'unknown':
                    search_used_fields.add(mapping["field"])

        if not ranked_keywords:
            # Fallback ë¡œì§ (ê¸°ì¡´ ì½”ë“œ ìœ ì§€)
            logging.warning("   âš ï¸  'ranked_keywords_raw' ì—†ìŒ. (Fallback ë¡œì§ ì‹¤í–‰)")
            obj_keywords = classified_keywords.get('welcome_keywords', {}).get('objective', [])
            for i, kw in enumerate(obj_keywords[:5]):
                mapping = get_field_mapping(kw)
                ranked_keywords.append({
                    'keyword': kw,
                    'field': mapping["field"],
                    'description': mapping["description"],
                    'type': mapping.get("type", "unknown"),
                    'priority': i + 1
                })
                if mapping["type"] == 'filter' and mapping["field"] != 'unknown':
                    search_used_fields.add(mapping["field"])
            
        ranked_keywords.sort(key=lambda x: x.get('priority', 999))
        
        logging.info("   3ë‹¨ê³„: ì£¼ìš” í‚¤ì›Œë“œ ì°¨íŠ¸ ìƒì„± (DB ì§‘ê³„, ë³‘ë ¬)")
        charts = []
        used_fields = []
        objective_fields = set([f[0] for f in WELCOME_OBJECTIVE_FIELDS])

        is_single_household = False
        
        # 1. demographic_filters í™•ì¸
        fam_val = demographic_filters.get('family_size') or demographic_filters.get('household_size')
        if fam_val:
            if isinstance(fam_val, list):
                if any(str(v).startswith('1') for v in fam_val): is_single_household = True
            elif str(fam_val).startswith('1'):
                is_single_household = True
                
        # 2. structured_filters í™•ì¸
        if not is_single_household:
            for f in structured_filters:
                if f.get('field') in ['family_size', 'household_size']:
                    val = f.get('value')
                    if isinstance(val, list):
                        if any(str(v).startswith('1') for v in val): is_single_household = True
                    elif str(val).startswith('1'):
                        is_single_household = True
                        
        if is_single_household:
            logging.info("   â„¹ï¸ 1ì¸ ê°€êµ¬ ê°ì§€: 'ê°€êµ¬ ì†Œë“', 'í˜¼ì¸ ì—¬ë¶€' í•„ë“œë¥¼ ì¸ì‚¬ì´íŠ¸ì—ì„œ ì œì™¸í•©ë‹ˆë‹¤.")
            # used_fieldsì— ë¯¸ë¦¬ ì¶”ê°€í•´ë‘ë©´, ì´í›„ ë‹¨ê³„(4ë‹¨ê³„)ì—ì„œ ì¤‘ë³µ í•„ë“œë¡œ ê°„ì£¼ë˜ì–´ ìƒì„±ë˜ì§€ ì•ŠìŒ
            used_fields.append('income_household_monthly')
            used_fields.append('marital_status')
        # ----------------------------------------------------------------------

        chart_tasks = []
        for kw_info in ranked_keywords:
            if len(chart_tasks) >= 3: break 

            field = kw_info.get('field', '')
            kw_type = kw_info.get('type', 'unknown')

            if field in used_fields:
                continue

            if kw_type == 'qpoll': 
                chart_tasks.append({"type": "qpoll", "kw_info": kw_info})
                used_fields.append(field)
            elif kw_type == 'filter' and field not in search_used_fields:
                if field in objective_fields and field != 'unknown':
                    if panels_data:
                        chart_tasks.append({"type": "filter", "kw_info": kw_info})
                        used_fields.append(field)
                        
        if chart_tasks:
            with ThreadPoolExecutor(max_workers=len(chart_tasks) or 1) as executor:
                
                def run_chart_creation(task):
                    kw_info = task["kw_info"]
                    field = kw_info.get('field', '')
                    korean_name = kw_info.get('description', field)
                    
                    if task["type"] == "filter":
                        return create_chart_data_optimized(
                            kw_info.get('keyword', ''), field, korean_name, panels_data, use_full_db=False
                        )
                    elif task["type"] == "qpoll":
                        return create_qpoll_chart_data(field)
                    return None

                futures = {executor.submit(run_chart_creation, task): task for task in chart_tasks}
                
                for future in as_completed(futures):
                    kw_info_original = futures[future]["kw_info"]
                    try:
                        chart = future.result() 
                        if chart.get('chart_data') and chart.get('ratio') != '0.0%':
                            chart['priority'] = kw_info_original.get('priority', 99)
                            charts.append(chart)
                    except Exception as e:
                        logging.error(f"ì°¨íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}", exc_info=True)
            
            charts.sort(key=lambda x: x.get('priority', 99))
            for chart in charts:
                if 'priority' in chart: del chart['priority']

        logging.debug("   3.2ë‹¨ê³„: ì—°ê´€ í•„ë“œ ì‹¬ì¸µ ë¶„ì„")
        needed_charts_after_main = 5 - len(charts)
        if needed_charts_after_main > 0:
            if 'region_major' in search_used_fields and 'region_minor' not in used_fields:
                region_minor_chart = create_chart_data_optimized(
                    "ì„¸ë¶€ ì§€ì—­", "region_minor", "ì„¸ë¶€ ì§€ì—­(êµ¬/êµ°)", panels_data, use_full_db=False, max_categories=15 
                )
                if region_minor_chart and region_minor_chart.get('chart_data'):
                    charts.append(region_minor_chart)
                    used_fields.append('region_minor')

            if 'birth_year' in search_used_fields and 'marital_status' not in used_fields:
                marital_chart = create_chart_data_optimized(
                    "í˜¼ì¸ ìƒíƒœ", "marital_status", "í˜¼ì¸ ìƒíƒœ", panels_data, use_full_db=False, max_categories=10
                )
                if marital_chart and marital_chart.get('chart_data') and len(charts) < 5:
                    charts.append(marital_chart)
                    used_fields.append('marital_status')

        logging.debug("   3.5ë‹¨ê³„: êµì°¨ ë¶„ì„ ì°¨íŠ¸ ìƒì„±")
        if len(charts) < 5:
            topic_field_info = next((kw for kw in ranked_keywords if kw.get('type') == 'qpoll'), None)
            if not topic_field_info:
                topic_field_info = next((kw for kw in ranked_keywords if kw.get('type') == 'filter'), None)

            if topic_field_info:
                topic_field = topic_field_info.get('field')
                topic_korean_name = topic_field_info.get('description')

                priority_axes = []
                for field in search_used_fields:
                    if field != topic_field:
                        korean_name = FIELD_NAME_MAP.get(field, field)
                        priority_axes.append((field, korean_name, 'priority'))

                standard_axes = [
                    ('birth_year', 'ì—°ë ¹ëŒ€', 'standard'),
                    ('gender', 'ì„±ë³„', 'standard'),
                    ('region_major', 'ì§€ì—­', 'standard'),
                    ('job_title_raw', 'ì§ì—…', 'standard'),
                    ('marital_status', 'í˜¼ì¸ ìƒíƒœ', 'standard'),
                ]

                all_axes = priority_axes + [ax for ax in standard_axes if ax[0] not in search_used_fields]

                for axis_field, axis_korean_name, axis_type in all_axes:
                    if len(charts) >= 5: break
                    if topic_field == axis_field: continue

                    crosstab_chart = create_crosstab_chart(
                        panels_data, axis_field, topic_field, axis_korean_name, topic_korean_name
                    )

                    if crosstab_chart and crosstab_chart.get("chart_data"):
                        charts.append(crosstab_chart)
                        used_fields.append(axis_field)
                        used_fields.append(topic_field)
                
        logging.info("   4ë‹¨ê³„: ë†’ì€ ë¹„ìœ¨ í•„ë“œ ì°¨íŠ¸ ìƒì„± (ê²€ìƒ‰ ê²°ê³¼ ê¸°ë°˜)")
        needed_charts = 5 - len(charts)
        exclude_fields_for_step4 = list(set(used_fields) | search_used_fields)
        
        if needed_charts > 0:
            high_ratio_fields = find_high_ratio_fields_optimized(
                panels_data, 
                exclude_fields=exclude_fields_for_step4,
                threshold=50.0,
                max_charts=needed_charts
            )
            
            for field_info in high_ratio_fields:
                if len(charts) >= 5: break
                
                chart = {
                    "topic": f"{field_info['korean_name']} ë¶„í¬",
                    "description": f"{field_info['top_ratio']:.1f}%ê°€ '{field_info['top_category']}'ì…ë‹ˆë‹¤.",
                    "ratio": f"{field_info['top_ratio']:.1f}%",
                    "chart_data": [{"label": field_info['korean_name'], "values": field_info['distribution']}]
                }
                charts.append(chart)
        
        main_summary = f"ì´ {len(panels_data)}ëª…ì˜ ì‘ë‹µì ë°ì´í„°ë¥¼ ë¶„ì„í–ˆìŠµë‹ˆë‹¤. "
        if charts:
            top_chart = charts[0]
            summary_desc = top_chart.get('description', '')
            if ':' in summary_desc: summary_desc = summary_desc.split(':', 1)[-1].strip()
            main_summary += f"ì£¼ìš” ë¶„ì„ ê²°ê³¼: {top_chart.get('topic', '')}ì—ì„œ {top_chart.get('ratio', '0%')}ì˜ ë¹„ìœ¨ì„ ë³´ì…ë‹ˆë‹¤."
        
        result = {
            "query": query,
            "total_count": len(panels_data),
            "main_summary": main_summary,
            "charts": charts
        }
        
        logging.info(f"âœ… ë¶„ì„ ì™„ë£Œ: {len(charts)}ê°œ ì°¨íŠ¸ ìƒì„±")
        return result, 200
        
    except Exception as e:
        logging.error(f"âŒ ë¶„ì„ ì‹¤íŒ¨: {e}", exc_info=True)
        return {"main_summary": f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", "charts": []}, 500

async def generate_dynamic_insight(panel_ids: List[str], target_field: str, field_desc: str) -> Dict:
    if not panel_ids or not target_field: return {}
    logging.info(f"ğŸ“Š ë™ì  ì¸ì‚¬ì´íŠ¸ ìƒì„± ì¤‘... (Field: {target_field})")
    panels_data = get_panels_data_from_db(panel_ids)
    
    cleaned_answers = []
    for p in panels_data:
        val = p.get(target_field)
        if val:
            if isinstance(val, list):
                for v in val:
                    cleaned = _clean_label(v)
                    if cleaned: cleaned_answers.append(cleaned)
            else:
                cleaned = _clean_label(val)
                if cleaned: cleaned_answers.append(cleaned)
    
    if not cleaned_answers: return {"error": "ë°ì´í„° ë¶€ì¡±"}

    unique_answers = list(set(cleaned_answers))
    chart_data = {}
    
    if len(unique_answers) <= 15:
        chart_data = calculate_distribution(cleaned_answers)
    else:
        chart_data = _group_answers_with_vectors(cleaned_answers, threshold=0.82)

    final_chart_data = _limit_distribution_top_k(chart_data, k=7)
    if not final_chart_data: return {}

    top_category, top_ratio = find_top_category(final_chart_data)
    
    return {
        "topic": f"{field_desc} ë¶„ì„",
        "description": f"'{field_desc}'ì— ëŒ€í•´ '{top_category}'({top_ratio}%) ì‘ë‹µì´ ê°€ì¥ ë§ì•˜ìŠµë‹ˆë‹¤.",
        "ratio": f"{top_ratio}%",
        "chart_data": [{"label": field_desc, "values": final_chart_data}]
    }

def _group_answers_with_vectors(answers: List[str], threshold: float = 0.75) -> Dict[str, float]:
    if not answers: return {}
    embeddings_model = initialize_embeddings()
    unique_answers = list(set(answers))
    if len(unique_answers) < 2: return calculate_distribution(answers)

    try:
        vectors = embeddings_model.embed_documents(unique_answers)
        vectors = np.array(vectors)
        clustering = DBSCAN(eps=1-threshold, min_samples=1, metric='cosine').fit(vectors)
        labels = clustering.labels_
        
        cluster_map = {}
        for i, label in enumerate(labels):
            if label not in cluster_map: cluster_map[label] = []
            cluster_map[label].append(unique_answers[i])
            
        total_counts = Counter(answers)
        cluster_to_repr = {}
        for label, group_members in cluster_map.items():
            repr_word = max(group_members, key=lambda x: (total_counts[x], -len(x)))
            cluster_to_repr[label] = repr_word
            
        ans_to_label = {ans: labels[i] for i, ans in enumerate(unique_answers)}
        mapped_answers = [cluster_to_repr[ans_to_label[ans]] for ans in answers]
            
        return calculate_distribution(mapped_answers)
    except Exception as e:
        logging.error(f"ë²¡í„° í´ëŸ¬ìŠ¤í„°ë§ ì‹¤íŒ¨: {e}", exc_info=True)
        return calculate_distribution(answers)
        logging.error(f"ë²¡í„° í´ëŸ¬ìŠ¤í„°ë§ ì‹¤íŒ¨: {e}", exc_info=True)
        return calculate_distribution(answers)