import logging
import re
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from typing import Dict, Optional, List, Set

from qdrant_client.http.models import Filter, FieldCondition, MatchValue, MatchAny, MatchText
from utils import WELCOME_OBJECTIVE_FIELDS
from llm import parse_query_intelligent
from semantic_router import router
from search_helpers import (
    search_welcome_objective, 
    initialize_embeddings, 
    filter_negative_conditions, 
    embed_keywords
)
from mapping_rules import (
    QPOLL_FIELD_TO_TEXT, 
    get_negative_patterns,
    VALUE_TRANSLATION_MAP
)
from db import get_qdrant_client

def normalize_text(text: str) -> str:
    """[New] í…ìŠ¤íŠ¸ ì •ê·œí™”: ê³µë°±, íŠ¹ìˆ˜ë¬¸ì ì œê±° í›„ ë¹„êµìš© ë¬¸ìì—´ ìƒì„±"""
    if not text: return ""
    # ì•ŒíŒŒë²³, í•œê¸€, ìˆ«ìë§Œ ë‚¨ê¸°ê³  ëª¨ë‘ ì œê±° (íŠ¹ìˆ˜ë¬¸ì, ê³µë°± ë¬´ì‹œ)
    return re.sub(r'[^a-zA-Z0-9ê°€-í£]', '', text)

def rerank_candidates(
    candidate_ids: list,
    query_vector: list,
    qdrant_client,
    collection_name: str,
    id_key_path: str,
    negative_patterns: list,
    target_question: str = None  
) -> list:
    """
    [í•µì‹¬ ë¡œì§] In-Memory Reranking (Hybrid Fetching & Fuzzy Matching)
    - ëŒ€ìƒì´ ì ì„ ë•Œ(2000ëª… ì´í•˜): ì§ˆë¬¸ í•„í„° ì—†ì´ ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ Pythonì—ì„œ ì •ë°€/ìœ ì—°í•˜ê²Œ ë§¤ì¹­ (ëˆ„ë½ ë°©ì§€)
    - ëŒ€ìƒì´ ë§ì„ ë•Œ: DB í•„í„° ì‚¬ìš© (ì†ë„ ìµœì í™”)
    """
    # [Safety Cap] ëŒ€ìƒì´ ë„ˆë¬´ ë§ìœ¼ë©´ ìƒìœ„ 5000ëª…ìœ¼ë¡œ ì œí•œ
    if len(candidate_ids) > 10000:
        logging.warning(f"âš ï¸ Reranking ëŒ€ìƒì´ ë„ˆë¬´ ë§ìŒ ({len(candidate_ids)}ëª…). ìƒìœ„ 5000ëª…ë§Œ ìˆ˜í–‰í•©ë‹ˆë‹¤.")
        candidate_ids = candidate_ids[:5000]

    # [ì „ëµ ê²°ì •] ëŒ€ìƒì´ ì ê³  íƒ€ê²Ÿ ì§ˆë¬¸ì´ ìˆìœ¼ë©´ -> Python ìœ ì—° í•„í„°ë§ ì‚¬ìš© (DB í•„í„° ë¯¸ì‚¬ìš©)
    # ì´ìœ : DBì˜ MatchTextëŠ” íŠ¹ìˆ˜ë¬¸ì(Â·, ()) ì²˜ë¦¬ê°€ ì—„ê²©í•˜ì—¬ ë°ì´í„°ë¥¼ ë†“ì¹  ìˆ˜ ìˆìŒ
    use_python_filter = (len(candidate_ids) <= 2000) and (target_question is not None)

    must_conditions = [
        FieldCondition(
            key=id_key_path, 
            match=MatchAny(any=[str(pid) for pid in candidate_ids])
        )
    ]
    
    # DB ë ˆë²¨ ì§ˆë¬¸ í•„í„°ëŠ” 'ëŒ€ëŸ‰ì´ê±°ë‚˜ ì§ˆë¬¸ì´ ì—†ì„ ë•Œ'ë§Œ ì‚¬ìš©
    if target_question and not use_python_filter:
        must_conditions.append(
            FieldCondition(key="question", match=MatchText(text=target_question))
        )

    search_filter = Filter(must=must_conditions)

    # 1. ë°ì´í„° ì¡°íšŒ (Batch Scroll)
    batch_size = 2000 
    all_points = []
    offset = None
    
    while True:
        points, next_offset = qdrant_client.scroll(
            collection_name=collection_name,
            scroll_filter=search_filter,
            limit=batch_size,
            with_vectors=True,
            with_payload=True,
            offset=offset
        )
        all_points.extend(points)
        offset = next_offset
        if offset is None:
            break
            
    if not all_points:
        return []

    # 2. [ì •ë°€ ë¡œì§] Python ë ˆë²¨ì—ì„œ ì§ˆë¬¸ ë§¤ì¹­ (use_python_filter ëª¨ë“œ)
    target_points = []
    if use_python_filter:
        norm_target = normalize_text(target_question)
        
        for p in all_points:
            p_question = p.payload.get("question", "")
            # ì •ê·œí™”ëœ ë¬¸ìì—´ë¡œ í¬í•¨ ì—¬ë¶€ í™•ì¸ (ë„ì–´ì“°ê¸°, íŠ¹ìˆ˜ë¬¸ì ë¬´ì‹œí•˜ê³  ë¹„êµ)
            if norm_target in normalize_text(p_question):
                target_points.append(p)
        
        # ë§Œì•½ ë§¤ì¹­ëœ ê²Œ í•˜ë‚˜ë„ ì—†ë‹¤ë©´(ë°ì´í„° ì˜¤ë¥˜ ë“±), í•„í„° ì—†ì´ ì „ì²´ ì‚¬ìš© (Fallback)
        if not target_points and all_points:
            logging.warning(f"âš ï¸ ì§ˆë¬¸ ë§¤ì¹­ ì‹¤íŒ¨ (Target: {target_question[:10]}...). ì „ì²´ ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            target_points = all_points
    else:
        target_points = all_points

    if not target_points:
        return []

    # 3. ìœ ì‚¬ë„ ê³„ì‚° ë° ë¶€ì •ì–´ í•„í„°ë§
    vectors = [p.vector for p in target_points]
    query_vec_np = np.array([query_vector])
    
    # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
    scores = cosine_similarity(query_vec_np, vectors)[0]

    scored_results = []
    for i, point in enumerate(target_points):
        score = scores[i]
        payload = point.payload
        
        # ë‹µë³€ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        answer_text = payload.get('page_content') or payload.get('sentence') or ""
        
        # ë¶€ì •ì–´ í•„í„°ë§ (ì •ê·œì‹ ê²€ì‚¬)
        is_negative = False
        for pattern in negative_patterns:
            if re.search(pattern, answer_text):
                is_negative = True
                break
        
        if is_negative:
            continue  # ë¶€ì • ë‹µë³€ì€ ê²°ê³¼ì—ì„œ ì œì™¸
            
        # ID ì¶”ì¶œ
        pid = payload.get('panel_id') or payload.get('metadata', {}).get('panel_id')
        
        if pid:
            scored_results.append((pid, score))

    # 4. ì ìˆ˜ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
    scored_results.sort(key=lambda x: x[1], reverse=True)
    
    # ì¤‘ë³µ ì œê±° (í•œ ì‚¬ëŒì´ ì—¬ëŸ¬ ë‹µë³€ì„ í–ˆì„ ê²½ìš° ìµœê³  ì ìˆ˜ë§Œ ìœ ì§€)
    seen_pids = set()
    unique_results = []
    for pid, score in scored_results:
        if pid not in seen_pids:
            unique_results.append(pid)
            seen_pids.add(pid)

    return unique_results

def hybrid_search(query: str, limit: Optional[int] = None) -> Dict:
    """
    Semantic Search V3 (Refactored): 
    SQL í•„í„° ê²°ê³¼ ìœ ë¬´ì— ë”°ë¼ Reranking(ì „ìˆ˜ì¡°ì‚¬)ê³¼ ì¼ë°˜ ê²€ìƒ‰ì„ ë¶„ê¸°í•˜ì—¬ ìˆ˜í–‰
    """
    try:
        logging.info(f"ğŸš€ Semantic Search V3 (Optimized): {query}")
        
        # 1. LLM íŒŒì‹±
        parsed_query = parse_query_intelligent(query) 
        
        all_conditions = parsed_query.get("semantic_conditions", [])
        positive_conditions = [c for c in all_conditions if not c.get('is_negative', False)]
        negative_conditions = [c for c in all_conditions if c.get('is_negative', False)]

        structured_filters = parsed_query.get("demographic_filters", {})
        user_limit = limit or parsed_query.get("limit", 100)

        intent = ""
        if positive_conditions:
            intent = positive_conditions[0].get("original_keyword", "")
        
        # 2. ë¼ìš°íŒ…
        target_field_info = router.find_closest_field(intent)
        target_field = None
        target_desc = None
        if target_field_info:
            target_field = target_field_info['field']
            target_desc = target_field_info['description']

        objective_field_names = [f[0] for f in WELCOME_OBJECTIVE_FIELDS]
        
        # ë¼ìš°íŒ… ë³´ì •
        if target_field in objective_field_names:
            for cond in all_conditions:
                kw = cond.get('original_keyword', '')
                if kw == intent: continue 
                
                alt_info = router.find_closest_field(kw)
                if alt_info and alt_info['field'] in QPOLL_FIELD_TO_TEXT:
                    logging.info(f"ğŸ”„ íƒ€ê²Ÿ ì¬ì„¤ì •: {target_field}(ì¸êµ¬í†µê³„) -> {alt_info['field']}(ì„¤ë¬¸)ë¡œ ë³€ê²½")
                    target_field = alt_info['field']
                    target_desc = alt_info['description']
                    intent = kw 
                    break

        # 3. 1ì°¨ í•„í„°ë§ (SQL - ì¸êµ¬í†µê³„)
        filtered_panel_ids = set()
        
        if structured_filters or target_field:
            filters_for_sql = []
            
            # Structured Filters ì²˜ë¦¬
            for key, value in structured_filters.items():
                if key == "age_range":
                    filters_for_sql.append({"field": "age", "operator": "between", "value": value})
                # ì†Œë“ ë“± ë²”ìœ„ í•„í„° ì²˜ë¦¬
                elif isinstance(value, dict) and ("min" in value or "max" in value or "gte" in value or "lte" in value):
                    min_val = value.get("min") or value.get("gte")
                    max_val = value.get("max") or value.get("lte")

                    if min_val is not None and max_val is not None:
                        filters_for_sql.append({"field": key, "operator": "between", "value": [min_val, max_val]})
                    elif min_val is not None:
                        filters_for_sql.append({"field": key, "operator": "gte", "value": min_val})
                    elif max_val is not None:
                        filters_for_sql.append({"field": key, "operator": "lte", "value": max_val})
                else:
                    filters_for_sql.append({"field": key, "operator": "in", "value": value})

            # Target Field ì²˜ë¦¬
            if target_field and target_field not in QPOLL_FIELD_TO_TEXT:
                is_specific_value_filter = False
                if target_field in VALUE_TRANSLATION_MAP:
                    for key in VALUE_TRANSLATION_MAP[target_field].keys():
                        if key == intent or (len(intent) < 10 and key in intent):
                            logging.info(f"ğŸ¯ íƒ€ê²Ÿ í•„ë“œ '{target_field}'ë¥¼ ê°’ í•„í„° '{key}'ë¡œ ë³€í™˜ (Intent: {intent})")
                            filters_for_sql.append({"field": target_field, "operator": "eq", "value": key})
                            is_specific_value_filter = True
                            break
                
                if not is_specific_value_filter:
                    filters_for_sql.append({"field": target_field, "operator": "not_null", "value": "check"})
            
            if filters_for_sql:
                panel_ids, _ = search_welcome_objective(filters_for_sql, attempt_name="V3_Filter_Optimized")
                filtered_panel_ids = panel_ids
        
        # ê²€ìƒ‰ ë²”ìœ„ ì„¤ì •
        if filtered_panel_ids:
            vector_search_k = max(len(filtered_panel_ids), user_limit * 5)
            vector_search_k = min(vector_search_k, 3000) 
        else:
            vector_search_k = max(user_limit * 5, 500)

        final_panel_ids = filtered_panel_ids
        vector_matched_ids = set() 

        is_structured_target = target_field and target_field not in QPOLL_FIELD_TO_TEXT
        
        # [Case A] ì •í˜• ë°ì´í„° íƒ€ê²Ÿ + SQL í•„í„° ì¡´ì¬
        if is_structured_target and filtered_panel_ids:
            logging.info(f"ğŸ¯ ì •í˜• ë°ì´í„° íƒ€ê²Ÿ({target_field}) ê°ì§€ -> ë²¡í„° ê²€ìƒ‰ ì—†ì´ SQL ê²°ê³¼({len(filtered_panel_ids)}ëª…) ì‚¬ìš©")
            final_panel_ids = filtered_panel_ids
            
        # [Case B] ë²¡í„° ê²€ìƒ‰ í•„ìš”
        elif intent and target_field:
            qdrant_client = get_qdrant_client()
            embeddings = initialize_embeddings()
            query_vector = embeddings.embed_query(intent)
            
            is_welcome_collection = False
            target_question_text = None 

            if target_field in QPOLL_FIELD_TO_TEXT:
                collection_name = "qpoll_vectors_v2"
                id_key_path = "panel_id"
                target_question_text = QPOLL_FIELD_TO_TEXT[target_field]
            else:
                collection_name = "welcome_subjective_vectors"
                id_key_path = "metadata.panel_id"
                is_welcome_collection = True

            negative_patterns = get_negative_patterns(target_field)

            # ------------------------------------------------------------------
            # [ë¶„ê¸° 1] SQL í•„í„° ê²°ê³¼ê°€ ìˆìŒ -> Reranking (ì „ìˆ˜ ì¡°ì‚¬)
            # ------------------------------------------------------------------
            if filtered_panel_ids:
                logging.info(f"ğŸš€ Reranking ëª¨ë“œ ì§„ì…: {len(filtered_panel_ids)}ëª… ëŒ€ìƒ ì •ë°€ ê²€ì‚¬")
                
                reranked_ids = rerank_candidates(
                    candidate_ids=list(filtered_panel_ids),
                    query_vector=query_vector,
                    qdrant_client=qdrant_client,
                    collection_name=collection_name,
                    id_key_path=id_key_path,
                    negative_patterns=negative_patterns,
                    target_question=target_question_text 
                )
                
                vector_matched_ids = set(reranked_ids)
                logging.info(f"âœ… Reranking ì™„ë£Œ: {len(filtered_panel_ids)}ëª… -> {len(vector_matched_ids)}ëª… (ë¶€ì • ë‹µë³€ ì œì™¸ë¨)")

            # ------------------------------------------------------------------
            # [ë¶„ê¸° 2] SQL í•„í„° ê²°ê³¼ê°€ ì—†ìŒ -> ì¼ë°˜ ë²¡í„° ê²€ìƒ‰ (ê¸°ì¡´ ë¡œì§)
            # ------------------------------------------------------------------
            else:
                logging.info("ğŸ” ì¼ë°˜ ë²¡í„° ê²€ìƒ‰ ëª¨ë“œ ì§„ì… (SQL í•„í„° ì—†ìŒ)")
                must_conditions = []
                
                # ì¼ë°˜ ê²€ìƒ‰ì—ì„œë„ íŠ¹ìˆ˜ë¬¸ì ì´ìŠˆê°€ ìˆì„ ìˆ˜ ìˆìœ¼ë‚˜, 
                # ëŒ€ëŸ‰ ê²€ìƒ‰ì´ë¯€ë¡œ ì†ë„ë¥¼ ìœ„í•´ DB í•„í„°ë¥¼ ìœ ì§€í•˜ë˜, ê²€ìƒ‰ì´ ì•ˆ ë˜ë©´ í•„í„° ì—†ì´ ì‹œë„í•˜ëŠ” ë¡œì§ ì¶”ê°€ ê°€ëŠ¥
                # (ì—¬ê¸°ì„œëŠ” ê¸°ì¡´ ë¡œì§ ìœ ì§€)
                if target_question_text:
                     must_conditions.append(FieldCondition(key="question", match=MatchText(text=target_question_text)))

                qdrant_filter = Filter(must=must_conditions)

                search_results = []
                try:
                    search_results = qdrant_client.search(
                        collection_name=collection_name, 
                        query_vector=query_vector,
                        query_filter=qdrant_filter,
                        limit=vector_search_k,
                        with_payload=True 
                    )
                except Exception as e:
                    logging.error(f"âŒ Qdrant ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
                    search_results = []

                valid_hits_count = 0
                
                for hit in search_results:
                    if not hit.payload: continue
                    
                    answer_text = hit.payload.get('page_content') or hit.payload.get('sentence') or ""

                    is_negative = False
                    for pattern in negative_patterns:
                        if re.search(pattern, answer_text):
                            is_negative = True
                            break 
                    
                    if is_negative: continue

                    pid = None
                    if is_welcome_collection:
                        meta = hit.payload.get('metadata', {})
                        pid = meta.get('panel_id')
                    else:
                        pid = hit.payload.get('panel_id')
                    
                    if pid:
                        vector_matched_ids.add(pid)
                        valid_hits_count += 1
                
                logging.info(f"   âœ‚ï¸ í…ìŠ¤íŠ¸ í•„í„°ë§ ê²°ê³¼: ê²€ìƒ‰ {len(search_results)}ëª… -> ìœ íš¨ {valid_hits_count}ëª…")
                
                # [ê²€ì¦ 2] ë²¡í„° ê¸°ë°˜ ë¶€ì • ì¡°ê±´ í•„í„°ë§
                if negative_conditions and vector_matched_ids:
                     neg_keywords = []
                     for nc in negative_conditions:
                         neg_keywords.extend(nc.get('expanded_queries', []))
                     
                     if neg_keywords:
                         logging.info(f"ğŸš« ë¶€ì • ì¡°ê±´ í•„í„°ë§ ì ìš© (ë²¡í„°): {neg_keywords}")
                         neg_vectors = embed_keywords(neg_keywords)
                         vector_matched_ids = filter_negative_conditions(
                             panel_ids=vector_matched_ids,
                             negative_keywords=neg_keywords,
                             query_vectors=neg_vectors,
                             qdrant_client=qdrant_client,
                             collection_name=collection_name,
                             threshold=0.55 
                         )
                         logging.info(f"   âœ‚ï¸ ë²¡í„° ë¶€ì • í•„í„°ë§ í›„ ë‚¨ì€ ì¸ì›: {len(vector_matched_ids)}ëª…")

            final_panel_ids = vector_matched_ids

        else:
            logging.debug("  - ì˜ë„/íƒ€ê²Ÿ ì—†ìŒ. 1ì°¨ í•„í„° ê²°ê³¼ ì‚¬ìš©.")
            final_panel_ids = filtered_panel_ids

        final_panel_ids_list = list(final_panel_ids)
        logging.info(f"âœ… ê²€ìƒ‰ ì™„ë£Œ: {len(final_panel_ids_list)}ëª…")

        return {
            "final_panel_ids": final_panel_ids_list,
            "total_count": len(final_panel_ids_list),
            "search_intent": intent,
            "target_field": target_field,
            "target_field_desc": target_desc
        }

    except Exception as e:
        logging.error(f"âŒ hybrid_search ì˜¤ë¥˜: {e}", exc_info=True)
        return {
            "final_panel_ids": [],
            "total_count": 0,
            "search_intent": "",
            "target_field": None,
            "target_field_desc": None
        }