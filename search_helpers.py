import os
import re
import logging
import threading
from typing import List, Set, Optional, Dict, Tuple
from datetime import datetime
from collections import defaultdict
from functools import lru_cache
from dotenv import load_dotenv

from qdrant_client import QdrantClient
from qdrant_client.http.models import Filter, FieldCondition, MatchAny, SearchParams
from langchain_huggingface import HuggingFaceEmbeddings

from db import get_db_connection_context
from mapping_rules import (
    CATEGORY_MAPPING, 
    get_field_mapping,
    FIELD_ALIAS_MAP, 
    VALUE_TRANSLATION_MAP,
    FUZZY_MATCH_FIELDS, 
    ARRAY_FIELDS
)

def build_sql_from_structured_filters(filters: List[Dict]) -> Tuple[str, List]:
    """
    JSONB ë°ì´í„° íƒ€ìž…ì— ë§žì¶° ì •í™•í•œ SQL WHERE ì ˆì„ ìƒì„±í•©ë‹ˆë‹¤.
    (ì†Œë“ ë²”ìœ„ ìŠ¤ë§ˆíŠ¸ ë§¤í•‘ í¬í•¨)
    """
    if not filters:
        return "", []

    conditions = []
    params = []
    CURRENT_YEAR = datetime.now().year

    # ì†Œë“ ì¹´í…Œê³ ë¦¬ ì •ì˜
    INCOME_RANGES = [
        (0, 999999, "ì›” 100ë§Œì› ë¯¸ë§Œ"),
        (1000000, 1999999, "ì›” 100~199ë§Œì›"),
        (2000000, 2999999, "ì›” 200~299ë§Œì›"),
        (3000000, 3999999, "ì›” 300~399ë§Œì›"),
        (4000000, 4999999, "ì›” 400~499ë§Œì›"),
        (5000000, 5999999, "ì›” 500~599ë§Œì›"),
        (6000000, 6999999, "ì›” 600~699ë§Œì›"),
        (7000000, 999999999, "ì›” 700ë§Œì› ì´ìƒ")
    ]

    for f in filters:
        raw_field = f.get("field")
        operator = f.get("operator")
        value = f.get("value")

        if not raw_field or not operator:
            continue

        field = FIELD_ALIAS_MAP.get(raw_field, raw_field)

        # 1. not_null ì²˜ë¦¬
        if operator == "not_null":
            base_condition = f"(structured_data->>'{field}' IS NOT NULL AND structured_data->>'{field}' != 'NaN')"
            exclude_pattern = ""
            
            if field == "children_count":
                conditions.append(f"({base_condition} AND structured_data->>'{field}' NOT IN ('0', '0ëª…') AND structured_data->>'{field}' !~ 'ì—†ìŒ')")
                continue
            
            if field == "drinking_experience":
                exclude_pattern = "ë§ˆì‹œì§€|ì•ŠìŒ|ì—†ìŒ|ë¹„ìŒì£¼|ê¸ˆì£¼|ì•ˆ\\s*ë§ˆì‹¬|ì „í˜€"
            elif field == "smoking_experience":
                exclude_pattern = "í”¼ìš°ì§€|ì•ŠìŒ|ì—†ìŒ|ë¹„í¡ì—°|ê¸ˆì—°|ì•ˆ\\s*í”¼ì›€"
            elif field == "ott_count":
                exclude_pattern = "0ê°œ|ì•ˆ\\s*í•¨|ì—†ìŒ|ì´ìš©\\s*ì•ˆ|ë³´ì§€\\s*ì•ŠìŒ"
            elif field == "fast_delivery_usage":
                exclude_pattern = "ì•ˆ\\s*í•¨|ì´ìš©\\s*ì•ˆ|ì—†ìŒ|ì§ì ‘\\s*êµ¬ë§¤"
            else:
                exclude_pattern = "ì—†ìŒ|ë¹„í¡ì—°|í•´ë‹¹ì‚¬í•­|í”¼ìš°ì§€|ê¸ˆì—°"

            refined_condition = f"({base_condition} AND structured_data->>'{field}' !~ '{exclude_pattern}')"
            conditions.append(refined_condition)
            continue 

        # 2. ë‚˜ì´ ê³„ì‚°
        if field == "birth_year" or raw_field == "age":
            if operator == "between" and isinstance(value, list) and len(value) == 2:
                age_start, age_end = value
                birth_year_end = CURRENT_YEAR - age_start
                birth_year_start = CURRENT_YEAR - age_end
                conditions.append(f"(structured_data->>'birth_year')::int BETWEEN %s AND %s")
                params.extend([birth_year_start, birth_year_end])
            continue
        
        # 3. ê°’ í™•ìž¥ (ë§¤í•‘) - ì˜ì–´/í•œê¸€ ë³€í™˜ ë° ì¹´í…Œê³ ë¦¬ í™•ìž¥
        final_value = value
        if field in VALUE_TRANSLATION_MAP:
            mapping = VALUE_TRANSLATION_MAP[field]
            if isinstance(value, list):
                converted_list = []
                for v in value:
                    mapped_v = mapping.get(v, v)
                    if isinstance(mapped_v, list):
                        converted_list.extend(mapped_v)
                    else:
                        converted_list.append(mapped_v)
                final_value = converted_list
            else:
                mapped_v = mapping.get(value, value)
                final_value = mapped_v

        if isinstance(final_value, list):
            expanded_list = []
            for v in final_value:
                if str(v) in CATEGORY_MAPPING:
                    expanded_list.extend(CATEGORY_MAPPING[str(v)])
                else:
                    expanded_list.append(v)
            final_value = expanded_list
        elif str(final_value) in CATEGORY_MAPPING:
            final_value = CATEGORY_MAPPING[str(final_value)]

        # 4. FUZZY_MATCH (ILIKE)
        if field in FUZZY_MATCH_FIELDS or field in ARRAY_FIELDS:
            if not isinstance(final_value, list):
                final_value = [final_value]
            
            or_conditions = []
            for v in final_value:
                or_conditions.append(f"structured_data->>'{field}' ILIKE %s")
                params.append(f"%{v}%")
            
            if or_conditions:
                exclude_sql = ""
                if field == "drinking_experience":
                    exclude_patterns = "ë§ˆì‹œì§€|ì•ŠìŒ|ì—†ìŒ|ë¹„ìŒì£¼|ê¸ˆì£¼|ì•ˆ\\s*ë§ˆì‹¬|ì „í˜€"
                    exclude_sql = f" AND structured_data->>'{field}' !~ '{exclude_patterns}'"
                elif field == "smoking_experience":
                    exclude_patterns = "í”¼ìš°ì§€|ì•ŠìŒ|ì—†ìŒ|ë¹„í¡ì—°|ê¸ˆì—°|ì•ˆ\\s*í”¼ì›€"
                    exclude_sql = f" AND structured_data->>'{field}' !~ '{exclude_patterns}'"
                elif field == "ott_count":
                    exclude_pattern = "0ê°œ|ì•ˆ\\s*í•¨|ì—†ìŒ|ì´ìš©\\s*ì•ˆ|ë³´ì§€\\s*ì•ŠìŒ"
                    conditions.append(f"({base_condition} AND structured_data->>'{field}' !~ '{exclude_pattern}')")

                conditions.append(f"({' OR '.join(or_conditions)}){exclude_sql}")

        # 5. ì†Œë“ í•„ë“œ ìŠ¤ë§ˆíŠ¸ ì²˜ë¦¬ (ìˆ«ìž ë²”ìœ„ -> ë¬¸ìžì—´ ì¹´í…Œê³ ë¦¬ ë³€í™˜)
        elif field in ["income_household_monthly", "income_personal_monthly"] and operator in ["gte", "lte", "between"]:
            target_categories = []
            min_val = 0
            max_val = 999999999
            
            if operator == "gte": min_val = int(final_value)
            elif operator == "lte": max_val = int(final_value)
            elif operator == "between":
                min_val = int(final_value[0])
                max_val = int(final_value[1])
            
            for r_min, r_max, label in INCOME_RANGES:
                if max_val >= r_min and min_val <= r_max:
                    target_categories.append(label)
            
            if target_categories:
                str_values = [str(v) for v in target_categories]
                placeholders = ','.join(['%s'] * len(str_values))
                conditions.append(f"structured_data->>'{field}' IN ({placeholders})")
                params.extend(str_values)
            else:
                conditions.append("1=0")

        # 6. ìˆ«ìží˜• í•„ë“œ (children_count ë“±)
        elif field in ["children_count"]:
            field_sql = f"(structured_data->>'{field}')::numeric"
            if operator == "between" and isinstance(final_value, list) and len(final_value) == 2:
                conditions.append(f"{field_sql} BETWEEN %s AND %s")
                params.extend(final_value)
            elif operator == "gte":
                conditions.append(f"{field_sql} >= %s")
                params.append(final_value)
            elif operator == "lte":
                conditions.append(f"{field_sql} <= %s")
                params.append(final_value)
            elif operator == "eq":
                conditions.append(f"{field_sql} = %s")
                params.append(final_value)

        # 7. ì¼ë°˜ ë¬¸ìžì—´ í•„ë“œ
        else:
            field_sql = f"structured_data->>'{field}'"

            if field == "family_size":
                if isinstance(final_value, list):
                    or_conditions = []
                    for v in final_value:
                        or_conditions.append(f"{field_sql} ~ %s")
                        params.append(f"^{v}([^0-9]|$)") 
                    conditions.append(f"({' OR '.join(or_conditions)})")
                else:
                    conditions.append(f"{field_sql} ~ %s")
                    params.append(f"^{final_value}([^0-9]|$)")

            elif operator == "eq":
                conditions.append(f"{field_sql} = %s")
                params.append(str(final_value))

            elif operator == "in" and isinstance(final_value, list) and final_value:
                str_values = [str(v) for v in final_value]
                placeholders = ','.join(['%s'] * len(str_values))
                conditions.append(f"{field_sql} IN ({placeholders})")
                params.extend(str_values)
                
            elif operator == "like":
                conditions.append(f"{field_sql} ILIKE %s")
                params.append(f"%{final_value}%")

    if not conditions:
        return "", []

    where_clause = " WHERE " + " AND ".join(conditions)
    return where_clause, params


def search_welcome_objective(
    filters: List[Dict],
    attempt_name: str = "êµ¬ì¡°í™”"
) -> Tuple[Set[str], Set[str]]:
    if not filters:
        logging.info(f"   Welcome {attempt_name}: í•„í„° ì—†ìŒ")
        return set(), set()

    try:
        with get_db_connection_context() as conn:
            if not conn:
                return set(), set()

            cur = conn.cursor()
            where_clause, params = build_sql_from_structured_filters(filters)

            if not where_clause:
                return set(), set()

            query = f"SELECT panel_id FROM welcome_meta2 {where_clause}"
            
            logging.info(f"  (SQL) ì‹¤í–‰: {query}")
            logging.info(f"  (SQL) íŒŒë¼ë¯¸í„°: {params}")

            cur.execute(query, tuple(params))
            
            results = {str(row[0]) for row in cur.fetchall()}
            cur.close()

            logging.info(f"  (SQL) ðŸ“ˆ 1ë‹¨ê³„ í•„í„°ë§ ê²°ê³¼: {len(results)}ëª…")

        return results, set()

    except Exception as e:
        logging.error(f"   Welcome {attempt_name} ê²€ìƒ‰ ì‹¤íŒ¨: {e}", exc_info=True)
        return set(), set()

def search_preference_conditions(
    preference_keywords: List[str],
    query_vectors: List[List[float]],
    qdrant_client: QdrantClient,
    collection_name: str,
    candidate_panel_ids: Set[str],
    threshold: float = 0.45,
    top_k_per_keyword: int = 500
) -> Tuple[List[tuple], List[str]]:
    if not preference_keywords or not query_vectors or not candidate_panel_ids:
        return ([(pid, 0.0) for pid in candidate_panel_ids], [])
    try:
        candidate_list = list(candidate_panel_ids)
        qdrant_filter = Filter(must=[FieldCondition(key="panel_id", match=MatchAny(any=candidate_list))])
        panel_scores: Dict[str, float] = {pid: 0.0 for pid in candidate_panel_ids}
        found_categories: List[str] = []
        for i, (keyword, vector) in enumerate(zip(preference_keywords, query_vectors)):
            search_results = qdrant_client.search(
                collection_name=collection_name, query_vector=vector, query_filter=qdrant_filter,
                limit=top_k_per_keyword, with_payload=True, score_threshold=threshold
            )
            for result in search_results:
                pid = result.payload.get('panel_id')
                category = result.payload.get('category', None)
                if not pid and 'metadata' in result.payload:
                    pid = result.payload['metadata'].get('panel_id')
                    if not category: category = result.payload['metadata'].get('category', None)
                if pid and str(pid) in panel_scores:
                    panel_scores[str(pid)] = max(panel_scores[str(pid)], result.score)
                    if category: found_categories.append(category)
        sorted_results = sorted(panel_scores.items(), key=lambda x: x[1], reverse=True)
        return sorted_results, list(set(found_categories))
    except Exception as e:
        logging.error(f"Preference ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        return ([(pid, 0.0) for pid in candidate_panel_ids], [])

def filter_negative_conditions(
    panel_ids: Set[str],
    negative_keywords: List[str],
    query_vectors: List[List[float]],
    qdrant_client: QdrantClient,
    collection_name: str,
    threshold: float = 0.50
) -> Set[str]:
    if not negative_keywords or not query_vectors or not panel_ids: return panel_ids
    try:
        panel_ids_to_exclude = set()
        for vector in query_vectors:
            search_results = qdrant_client.search(
                collection_name=collection_name, query_vector=vector, limit=5000,
                with_payload=True, score_threshold=threshold
            )
            for result in search_results:
                pid = result.payload.get('panel_id')
                if not pid and 'metadata' in result.payload: pid = result.payload['metadata'].get('panel_id')
                if pid: panel_ids_to_exclude.add(str(pid))
        return panel_ids - panel_ids_to_exclude
    except Exception as e:
        logging.error(f"Negative í•„í„°ë§ ì‹¤íŒ¨: {e}")
        return panel_ids

@lru_cache(maxsize=None)
def initialize_embeddings():
    try:
        return HuggingFaceEmbeddings(model_name="nlpai-lab/KURE-v1", model_kwargs={'device': 'cpu'})
    except Exception as e:
        logging.error(f"ìž„ë² ë”© ë¡œë“œ ì‹¤íŒ¨: {e}")
        raise

def embed_keywords(keywords: List[str]) -> List[List[float]]:
    if not keywords: return []
    try:
        return initialize_embeddings().embed_documents(keywords)
    except Exception as e:
        logging.error(f"ìž„ë² ë”© ì‹¤íŒ¨: {e}")
        return []