import json
import logging
import re 
from typing import List, Dict, Any, Tuple
from collections import Counter
from concurrent.futures import ThreadPoolExecutor, as_completed

from utils import (
    extract_field_values,
    calculate_distribution,
    find_top_category,
    FIELD_NAME_MAP,
    WELCOME_OBJECTIVE_FIELDS,
    get_panels_data_from_db 
)
from db import get_db_connection_context

# 1. ì •ì  ë§¤í•‘ ê·œì¹™ (Python ì½”ë“œë¡œ ê´€ë¦¬)
FIELD_MAPPING_RULES = [
    # ì •ê·œì‹ ê¸°ë°˜ (ìˆœì„œ ì¤‘ìš” - êµ¬ì²´ì ì¸ ê²ƒë¶€í„°)
    (re.compile(r'^\d{2}ëŒ€$'), {"field": "birth_year", "description": "ì—°ë ¹ëŒ€"}),
    (re.compile(r'^\d{2}~\d{2}ëŒ€$'), {"field": "birth_year", "description": "ì—°ë ¹ëŒ€"}),
    (re.compile(r'ì Šì€ì¸µ|ì²­ë…„|MZì„¸ëŒ€'), {"field": "birth_year", "description": "ì—°ë ¹ëŒ€"}),
    (re.compile(r'.*(ì‹œ|êµ¬|êµ°)$'), {"field": "region_minor", "description": "ì„¸ë¶€ ê±°ì£¼ ì§€ì—­"}),

    ("ì„œìš¸", {"field": "region_major", "description": "ê±°ì£¼ ì§€ì—­"}),
    ("ê²½ê¸°", {"field": "region_major", "description": "ê±°ì£¼ ì§€ì—­"}),
    ("ë¶€ì‚°", {"field": "region_major", "description": "ê±°ì£¼ ì§€ì—­"}),
    ("ì¸ì²œ", {"field": "region_major", "description": "ê±°ì£¼ ì§€ì—­"}),
    ("ëŒ€êµ¬", {"field": "region_major", "description": "ê±°ì£¼ ì§€ì—­"}),
    ("ê´‘ì£¼", {"field": "region_major", "description": "ê±°ì£¼ ì§€ì—­"}),
    ("ëŒ€ì „", {"field": "region_major", "description": "ê±°ì£¼ ì§€ì—­"}),
    ("ìš¸ì‚°", {"field": "region_major", "description": "ê±°ì£¼ ì§€ì—­"}),
    ("ì„¸ì¢…", {"field": "region_major", "description": "ê±°ì£¼ ì§€ì—­"}),
    
    ("ë‚¨ì", {"field": "gender", "description": "ì„±ë³„"}),
    ("ì—¬ì„±", {"field": "gender", "description": "ì„±ë³„"}),
    ("ë‚¨ì„±", {"field": "gender", "description": "ì„±ë³„"}),
    ("ì—¬ì", {"field": "gender", "description": "ì„±ë³„"}),
    
    ("ì§ì¥ì¸", {"field": "job_title_raw", "description": "ì§ì—…"}),
    ("í•™ìƒ", {"field": "job_title_raw", "description": "ì§ì—…"}),
    ("ì£¼ë¶€", {"field": "job_title_raw", "description": "ì§ì—…"}),
    
    ("ê³ ì†Œë“", {"field": "income_personal_monthly", "description": "ì†Œë“"}),
    ("ì €ì†Œë“", {"field": "income_personal_monthly", "description": "ì†Œë“"}),
    
    ("ë¯¸í˜¼", {"field": "marital_status", "description": "ê²°í˜¼ ì—¬ë¶€"}),
    ("ê¸°í˜¼", {"field": "marital_status", "description": "ê²°í˜¼ ì—¬ë¶€"}),
    
    ("í¡ì—°", {"field": "smoking_experience", "description": "í¡ì—° ê²½í—˜"}),
    ("ë¹„í¡ì—°", {"field": "smoking_experience", "description": "í¡ì—° ê²½í—˜"}),
    
    ("ìŒì£¼", {"field": "drinking_experience", "description": "ìŒì£¼ ê²½í—˜"}),
    ("ê¸ˆì£¼", {"field": "drinking_experience", "description": "ìŒì£¼ ê²½í—˜"}),
    
    ("ì°¨ëŸ‰ë³´ìœ ", {"field": "car_ownership", "description": "ì°¨ëŸ‰ ë³´ìœ "}),
    ("ì°¨ì—†ìŒ", {"field": "car_ownership", "description": "ì°¨ëŸ‰ ë³´ìœ "}),

    ("it", {"field": "job_duty_raw", "description": "ì§ë¬´"}),
    ("ë§ˆì¼€íŒ…", {"field": "job_duty_raw", "description": "ì§ë¬´"}),

    ("ì‚¼ì„±", {"field": "phone_brand_raw", "description": "íœ´ëŒ€í° ë¸Œëœë“œ"}),
    ("ê°¤ëŸ­ì‹œ", {"field": "phone_brand_raw", "description": "íœ´ëŒ€í° ë¸Œëœë“œ"}),
    ("ì•„ì´í°", {"field": "phone_brand_raw", "description": "íœ´ëŒ€í° ë¸Œëœë“œ"}),
    ("ì• í”Œ", {"field": "phone_brand_raw", "description": "íœ´ëŒ€í° ë¸Œëœë“œ"}),
    
    ("í˜„ëŒ€ì°¨", {"field": "car_manufacturer_raw", "description": "ì°¨ëŸ‰ ì œì¡°ì‚¬"}),
    ("ê¸°ì•„", {"field": "car_manufacturer_raw", "description": "ì°¨ëŸ‰ ì œì¡°ì‚¬"}),
]

def get_field_mapping(keyword: str) -> Dict[str, str]:
    """[ëˆ„ë½ëœ í•¨ìˆ˜] í‚¤ì›Œë“œë¥¼ ë°›ì•„ ë§¤í•‘ë˜ëŠ” í•„ë“œ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    keyword_lower = keyword.lower()
    
    for pattern, mapping_info in FIELD_MAPPING_RULES:
        if isinstance(pattern, re.Pattern): # ì •ê·œì‹ ë§¤ì¹­
            if pattern.match(keyword):
                field = mapping_info["field"]
                description = FIELD_NAME_MAP.get(field, mapping_info["description"])
                return {"field": field, "description": description}
        elif isinstance(pattern, str): # ë¬¸ìì—´ ì¼ì¹˜
            if pattern == keyword_lower:
                field = mapping_info["field"]
                description = FIELD_NAME_MAP.get(field, mapping_info["description"])
                return {"field": field, "description": description}

    logging.warning(f" âš ï¸  '{keyword}'ì— ëŒ€í•œ ë§¤í•‘ ê·œì¹™ ì—†ìŒ. 'unknown'ìœ¼ë¡œ ì²˜ë¦¬.")
    return {"field": "unknown", "description": keyword}

def get_field_distribution_from_db(field_name: str, limit: int = 10) -> Dict[str, float]:
    """
    PostgreSQLì—ì„œ ì§ì ‘ ì§‘ê³„í•˜ì—¬ í•„ë“œ ë¶„í¬ ì¡°íšŒ (ì „ì²´ DB ëŒ€ìƒ)
    """
    try:
        with get_db_connection_context() as conn:
            if not conn:
                logging.error("DB ì§‘ê³„: ì—°ê²° ì‹¤íŒ¨")
                return {}
            
            cur = conn.cursor()
            
            if field_name == "birth_year":
                query = f"""
                    WITH age_groups AS (
                        SELECT 
                            CASE 
                                WHEN (2025 - (structured_data->>'birth_year')::int) < 20 THEN '10ëŒ€'
                                WHEN (2025 - (structured_data->>'birth_year')::int) < 30 THEN '20ëŒ€'
                                WHEN (2025 - (structured_data->>'birth_year')::int) < 40 THEN '30ëŒ€'
                                WHEN (2025 - (structured_data->>'birth_year')::int) < 50 THEN '40ëŒ€'
                                WHEN (2025 - (structured_data->>'birth_year')::int) < 60 THEN '50ëŒ€'
                                ELSE '60ëŒ€ ì´ìƒ'
                            END as age_group
                        FROM welcome_meta2
                        WHERE structured_data->>'birth_year' IS NOT NULL
                            AND structured_data->>'birth_year' ~ '^[0-9]+$'
                    )
                    SELECT 
                        age_group,
                        COUNT(*) as count,
                        ROUND(COUNT(*) * 100.0 / SUM(COUNT(*)) OVER (), 1) as percentage
                    FROM age_groups
                    GROUP BY age_group
                    ORDER BY percentage DESC
                    LIMIT {limit}
                """
            else:
                query = f"""
                    SELECT 
                        structured_data->>'{field_name}' as value,
                        COUNT(*) as count,
                        ROUND(COUNT(*) * 100.0 / SUM(COUNT(*)) OVER (), 1) as percentage
                    FROM welcome_meta2
                    WHERE structured_data->>'{field_name}' IS NOT NULL
                        AND structured_data->>'{field_name}' != ''
                    GROUP BY structured_data->>'{field_name}'
                    ORDER BY percentage DESC
                    LIMIT {limit}
                """
            
            cur.execute(query)
            rows = cur.fetchall()
            
            distribution = {}
            for row in rows:
                value = row[0]
                percentage = float(row[2])
                if value and percentage > 0:
                    distribution[value] = percentage
            
            cur.close()
        
        logging.info(f"   ğŸ“Š DB ì§‘ê³„ ì™„ë£Œ: {field_name} ({len(distribution)}ê°œ ì¹´í…Œê³ ë¦¬)")
        return distribution
        
    except Exception as e:
        logging.error(f"   DB ì§‘ê³„ ì‹¤íŒ¨ ({field_name}): {e}", exc_info=True)
        return {}

def create_chart_data_optimized(
    keyword: str,
    field_name: str,
    korean_name: str,
    panels_data: List[Dict],
    use_full_db: bool = False,
    max_categories: int = 10
) -> Dict:
    """
    ì°¨íŠ¸ ë°ì´í„° ìƒì„± (ìµœì í™” ë²„ì „)
    """
    # ì „ì²´ DB ê¸°ë°˜ ë¶„ì„
    if use_full_db:
        logging.info(f"       â†’ DB ì§‘ê³„ë¡œ '{field_name}' ë¶„ì„ (ìµœì í™”)")
        distribution = get_field_distribution_from_db(field_name, max_categories)
        
        if not distribution:
            return {
                "topic": korean_name,
                "description": f"'{keyword}' ê´€ë ¨ ì „ì²´ ë°ì´í„°ë¥¼ ì¡°íšŒí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                "ratio": "0.0%",
                "chart_data": []
            }
        
        top_category, top_ratio = find_top_category(distribution)
        description_prefix = f"ì „ì²´ ë°ì´í„° ê¸°ì¤€ '{korean_name}' ë¶„ì„:"
        
        return {
            "topic": f"{korean_name} ë¶„í¬",
            "description": f"{description_prefix} {top_ratio}%ê°€ '{top_category}'ì…ë‹ˆë‹¤.",
            "ratio": f"{top_ratio}%",
            "chart_data": [{"label": korean_name, "values": distribution}]
        }
    
    # ê²€ìƒ‰ ê²°ê³¼ ê¸°ë°˜ ë¶„ì„
    else:
        values = extract_field_values(panels_data, field_name)
        
        if not values:
            return { "topic": korean_name, "description": "ë°ì´í„° ë¶€ì¡±", "ratio": "0.0%", "chart_data": [] }
        
        distribution = calculate_distribution(values)
        filtered_distribution = {k: v for k, v in distribution.items() if v > 0.0}
        
        if not filtered_distribution:
            return { "topic": korean_name, "description": "ë°ì´í„° ë¶€ì¡±", "ratio": "0.0%", "chart_data": [] }
        
        # ìƒìœ„ Nê°œë§Œ + ê¸°íƒ€
        if len(filtered_distribution) > max_categories:
            sorted_items = sorted(filtered_distribution.items(), key=lambda x: x[1], reverse=True)
            top_items = dict(sorted_items[:max_categories - 1])
            other_sum = sum(v for k, v in sorted_items[max_categories - 1:])
            if other_sum > 0:
                top_items['ê¸°íƒ€'] = round(other_sum, 1)
            final_distribution = top_items
        else:
            final_distribution = filtered_distribution
        
        top_category, top_ratio = find_top_category(final_distribution)
        
        return {
            "topic": f"{korean_name} ë¶„í¬",
            "description": f"'{keyword}' ê²€ìƒ‰ ê²°ê³¼: {top_ratio}%ê°€ '{top_category}'ì…ë‹ˆë‹¤.",
            "ratio": f"{top_ratio}%",
            "chart_data": [{
                "label": korean_name,
                "values": final_distribution
            }]
        }


def create_crosstab_chart(
    panels_data: List[Dict],
    field1: str,  # ì£¼ì¶• (e.g., 'birth_year')
    field2: str,  # ì„¸ê·¸ë¨¼íŠ¸ (e.g., 'gender')
    field1_korean: str,
    field2_korean: str,
    max_categories: int = 5
) -> Dict:
    """
    êµì°¨ ë¶„ì„ ì°¨íŠ¸ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. (ì˜ˆ: ì—°ë ¹ëŒ€ë³„ ì„±ë³„ ë¶„í¬)
    """
    logging.info(f"       â†’ êµì°¨ ë¶„ì„ìœ¼ë¡œ '{field1}' vs '{field2}' ë¶„ì„")
    from utils import get_age_group

    # 1. ë‘ í•„ë“œì— ëŒ€í•œ ë°ì´í„° ì¶”ì¶œ
    crosstab_data = {}
    for item in panels_data:
        val1 = item.get(field1)
        val2 = item.get(field2)

        if val1 is None or val2 is None:
            continue

        # ê°’ ì²˜ë¦¬ (ì—°ë ¹ëŒ€ ë³€í™˜ ë“±)
        key1 = get_age_group(val1) if field1 == 'birth_year' else str(val1)
        key2 = str(val2)

        if key1 not in crosstab_data:
            crosstab_data[key1] = []
        crosstab_data[key1].append(key2)

    if not crosstab_data:
        return {}

    # 2. ê° ì£¼ì¶• ì¹´í…Œê³ ë¦¬ë³„ë¡œ ì„¸ê·¸ë¨¼íŠ¸ ë¶„í¬ ê³„ì‚°
    chart_values = {}
    for key1, values2 in crosstab_data.items():
        distribution = calculate_distribution(values2)
        chart_values[key1] = distribution

    # 3. ì£¼ì¶• ì¹´í…Œê³ ë¦¬ê°€ ë„ˆë¬´ ë§ìœ¼ë©´ ìƒìœ„ Nê°œë§Œ ì„ íƒ
    if len(chart_values) > max_categories:
        # ê° ì¹´í…Œê³ ë¦¬ì˜ ì „ì²´ ê°œìˆ˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
        sorted_keys = sorted(chart_values.keys(), key=lambda k: sum(crosstab_data[k].count(v) for v in set(crosstab_data[k])), reverse=True)
        chart_values = {k: chart_values[k] for k in sorted_keys[:max_categories]}

    if not chart_values:
        return {}

    return {
        "topic": f"{field1_korean}ë³„ {field2_korean} ë¶„í¬",
        "description": f"'{field1_korean}'ì— ë”°ë¥¸ '{field2_korean}'ì˜ ìƒëŒ€ì  ë¶„í¬ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.",
        "chart_type": "crosstab",
        "chart_data": [{"label": f"{field1_korean}ë³„ {field2_korean}", "values": chart_values}]
    }


def _analyze_fields_in_parallel(panels_data: List[Dict], candidate_fields: List[Tuple[str, str]]) -> List[Dict]:
    """
    [ë¦¬íŒ©í† ë§] panels_dataë¥¼ í•œ ë²ˆë§Œ ìˆœíšŒí•˜ì—¬ ëª¨ë“  í›„ë³´ í•„ë“œì˜ ê°’ì„ ì§‘ê³„í•˜ê³  ë¶„í¬ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    """
    field_values = {field_name: [] for field_name, _ in candidate_fields}
    field_map = dict(candidate_fields)

    # ë°ì´í„°ë¥¼ í•œ ë²ˆë§Œ ìˆœíšŒí•˜ì—¬ ëª¨ë“  í•„ë“œì˜ ê°’ì„ ì¶”ì¶œ
    for item in panels_data:
        for field_name in field_values.keys():
            value = item.get(field_name)
            if value is None:
                continue

            if field_name == "birth_year":
                from utils import get_age_group
                field_values[field_name].append(get_age_group(value))
            elif isinstance(value, list):
                field_values[field_name].extend(value)
            else:
                field_values[field_name].append(value)

    results = []
    for field_name, values in field_values.items():
        if not values:
            continue
        
        try:
            distribution = calculate_distribution(values)
            filtered_distribution = {k: v for k, v in distribution.items() if v > 0.0}
            if not filtered_distribution:
                continue

            results.append({
                "field": field_name,
                "korean_name": field_map[field_name],
                "distribution": filtered_distribution,
            })
        except Exception as e:
            logging.warning(f"   âš ï¸  {field_name} ë¶„í¬ ê³„ì‚° ì‹¤íŒ¨: {e}")

    return results


def find_high_ratio_fields_optimized(
    panels_data: List[Dict], 
    exclude_fields: List[str], 
    threshold: float = 50.0,
    max_charts: int = 3
) -> List[Dict]:
    """
    ê²€ìƒ‰ ê²°ê³¼(panels_data) ë‚´ì—ì„œ ë†’ì€ ë¹„ìœ¨ì„ ì°¨ì§€í•˜ëŠ” í•„ë“œ ì°¾ê¸° (ë³‘ë ¬ ì²˜ë¦¬)
    """
    candidate_fields = []
    
    for field_name, korean_name in WELCOME_OBJECTIVE_FIELDS:
        if field_name in exclude_fields:
            continue
        candidate_fields.append((field_name, korean_name))
    
    if not candidate_fields:
        return []
    
    logging.info(f"   ğŸ” {len(candidate_fields)}ê°œ í•„ë“œ ë³‘ë ¬ ë¶„ì„ ì¤‘...")
    
    analysis_results = _analyze_fields_in_parallel(panels_data, candidate_fields)
    
    high_ratio_results = []
    for result in analysis_results:
        distribution = result['distribution']
        top_category, top_ratio = find_top_category(distribution)
        
        if top_ratio >= threshold:
            final_distribution = distribution
            if len(distribution) > 10:
                sorted_items = sorted(distribution.items(), key=lambda x: x[1], reverse=True)
                top_items = dict(sorted_items[:9])
                other_sum = sum(v for k, v in sorted_items[9:])
                if other_sum > 0:
                    top_items['ê¸°íƒ€'] = round(other_sum, 1)
                final_distribution = top_items
            
            high_ratio_results.append({
                "field": result['field'],
                "korean_name": result['korean_name'],
                "distribution": final_distribution,
                "top_category": top_category,
                "top_ratio": top_ratio
            })
    
    high_ratio_results.sort(key=lambda x: x["top_ratio"], reverse=True)
    
    return high_ratio_results[:max_charts]


def analyze_search_results_optimized(
    query: str,
    classified_keywords: dict,
    panel_id_list: List[str]
) -> Tuple[Dict, int]:
    """
    ê²€ìƒ‰ ê²°ê³¼ ë¶„ì„ (ìµœì í™” ë²„ì „)
    """
    logging.info(f"ğŸ“Š ë¶„ì„ ì‹œì‘ (ìµœì í™”) - panel_id ìˆ˜: {len(panel_id_list)}ê°œ")
    
    if not panel_id_list:
        return {"main_summary": "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.", "charts": []}, 200
    
    try:
        # 1ë‹¨ê³„: íŒ¨ë„ ë°ì´í„° ì¡°íšŒ
        logging.info("   1ë‹¨ê³„: íŒ¨ë„ ë°ì´í„° ì¡°íšŒ (utils.py ì‚¬ìš©)")
        panels_data = get_panels_data_from_db(panel_id_list)
        
        if not panels_data:
            return {"main_summary": "íŒ¨ë„ ë°ì´í„°ë¥¼ ì¡°íšŒí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", "charts": []}, 200
        
        logging.info(f"   âœ… {len(panels_data)}ê°œ íŒ¨ë„ ë°ì´í„° ì¡°íšŒ ì™„ë£Œ")
        
        # 2ë‹¨ê³„: ranked_keywords ì¶”ì¶œ ë° ë§¤í•‘
        raw_keywords = classified_keywords.get('ranked_keywords_raw', [])
        ranked_keywords = []
        search_used_fields = set()
        
        if raw_keywords:
            logging.info(f"   2aë‹¨ê³„: LLM ì›ë³¸ í‚¤ì›Œë“œ {raw_keywords} ë§¤í•‘ ì‹œì‘")
            for i, keyword in enumerate(raw_keywords):
                mapping = get_field_mapping(keyword) 
                ranked_keywords.append({
                    "keyword": keyword, "field": mapping["field"],
                    "description": mapping["description"], "priority": i + 1
                })
                if mapping["field"] != 'unknown':
                    search_used_fields.add(mapping["field"])
        
        if not ranked_keywords:
            logging.warning("   âš ï¸  'ranked_keywords_raw' ì—†ìŒ. objective í‚¤ì›Œë“œë¡œ fallback.")
            obj_keywords = classified_keywords.get('welcome_keywords', {}).get('objective', [])
            for i, kw in enumerate(obj_keywords[:5]):
                mapping = get_field_mapping(kw)
                ranked_keywords.append({
                    'keyword': kw, 'field': mapping["field"],
                    'description': mapping["description"], 'priority': i + 1
                })
                if mapping["field"] != 'unknown':
                    search_used_fields.add(mapping["field"])
            
        if not ranked_keywords:
            return { "main_summary": f"ì´ {len(panels_data)}ëª… ì¡°íšŒ, ë¶„ì„í•  í‚¤ì›Œë“œ ì—†ìŒ.", "charts": [] }, 200
        
        ranked_keywords.sort(key=lambda x: x.get('priority', 999))
        logging.info(f"   âœ… ë¶„ì„ í‚¤ì›Œë“œ: {[k.get('keyword') for k in ranked_keywords]}")
        
        # 3ë‹¨ê³„: ranked_keywords ê¸°ë°˜ ì°¨íŠ¸ ìƒì„±
        logging.info("   3ë‹¨ê³„: ì£¼ìš” í‚¤ì›Œë“œ ì°¨íŠ¸ ìƒì„± (DB ì§‘ê³„, ë³‘ë ¬)")
        charts = []
        used_fields = []
        objective_fields = set([f[0] for f in WELCOME_OBJECTIVE_FIELDS])
        
        # 1. ìƒì„±í•  ì°¨íŠ¸ ì‘ì—… ëª©ë¡ ì •ì˜
        chart_tasks = [] 
        chart_count = 0
        for kw_info in ranked_keywords:
            if chart_count >= 2: break
            
            field = kw_info.get('field', '')
            if not field or field == 'unknown' or field not in objective_fields or field in used_fields:
                continue
            
            chart_tasks.append(kw_info)
            used_fields.append(field) 
            chart_count += 1

        # 2. ThreadPoolExecutorë¡œ ì°¨íŠ¸ ìƒì„± ë³‘ë ¬ ì‹¤í–‰
        if chart_tasks:
            with ThreadPoolExecutor(max_workers=len(chart_tasks) or 1) as executor:
                
                def create_chart_task(kw_info):
                    field = kw_info.get('field', '')
                    logging.info(f"   âš¡ [{field}] ì°¨íŠ¸ DB ì§‘ê³„ ìŠ¤ë ˆë“œ ì‹œì‘...")
                    return create_chart_data_optimized(
                        kw_info.get('keyword', ''), 
                        field, 
                        kw_info.get('description', FIELD_NAME_MAP.get(field, field)),
                        panels_data, 
                        use_full_db=True
                    )

                futures = {executor.submit(create_chart_task, kw_info): kw_info for kw_info in chart_tasks}
                
                for future in as_completed(futures):
                    kw_info_original = futures[future] 
                    field_name = kw_info_original.get('field', 'unknown')
                    try:
                        chart = future.result() 
                        if chart.get('chart_data') and chart.get('ratio') != '0.0%':
                            chart['priority'] = kw_info_original.get('priority', 99)
                            charts.append(chart)
                            logging.info(f"   âœ… [{field_name}] ì°¨íŠ¸ ìƒì„± ì™„ë£Œ (DB ì§‘ê³„)")
                        else:
                            logging.warning(f"   âš ï¸  [{field_name}] ì°¨íŠ¸ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŒ (DB ì§‘ê³„)")
                    except Exception as e:
                        logging.error(f"   âŒ [{field_name}] ì°¨íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}", exc_info=True)
            
            charts.sort(key=lambda x: x.get('priority', 99))
            
            for chart in charts:
                if 'priority' in chart:
                    del chart['priority']

        # 3.5ë‹¨ê³„: êµì°¨ ë¶„ì„ ì°¨íŠ¸ ìƒì„±
        logging.info("   3.5ë‹¨ê³„: êµì°¨ ë¶„ì„ ì°¨íŠ¸ ìƒì„±")
        if len(charts) < 5 and len(ranked_keywords) > 0:
            primary_kw = ranked_keywords[0]
            primary_field = primary_kw.get('field')
            primary_korean_name = primary_kw.get('description')
            secondary_field, secondary_korean_name = "gender", "ì„±ë³„"

            if primary_field and primary_field != secondary_field and primary_field in objective_fields:
                crosstab_chart = create_crosstab_chart(
                    panels_data,
                    primary_field, secondary_field,
                    primary_korean_name, secondary_korean_name
                )
                if crosstab_chart:
                    charts.append(crosstab_chart)
                    used_fields.append(primary_field) 
                    logging.info(f"   âœ… [{len(charts)}] êµì°¨ ë¶„ì„ ì°¨íŠ¸ ìƒì„± ({primary_korean_name} vs {secondary_korean_name})")

        # 4ë‹¨ê³„: ë†’ì€ ë¹„ìœ¨ í•„ë“œ ì°¾ê¸°
        logging.info("   4ë‹¨ê³„: ë†’ì€ ë¹„ìœ¨ í•„ë“œ ì°¨íŠ¸ ìƒì„± (ê²€ìƒ‰ ê²°ê³¼ ê¸°ë°˜)")
        needed_charts = 5 - len(charts)
        exclude_fields_for_step4 = list(set(used_fields) | search_used_fields)
        
        if needed_charts > 0:
            high_ratio_fields = find_high_ratio_fields_optimized(
                panels_data, 
                exclude_fields=exclude_fields_for_step4,
                threshold=50.0,
                max_charts=needed_charts
            )
            
            for field_info in high_ratio_fields:
                if len(charts) >= 5: break
                
                chart = {
                    "topic": f"{field_info['korean_name']} ë¶„í¬",
                    "description": f"{field_info['top_ratio']:.1f}%ê°€ '{field_info['top_category']}'ë¡œ ëšœë ·í•œ íŒ¨í„´ì„ ë³´ì…ë‹ˆë‹¤.",
                    "ratio": f"{field_info['top_ratio']:.1f}%",
                    "chart_data": [{"label": field_info['korean_name'], "values": field_info['distribution']}]
                }
                charts.append(chart)
                logging.info(f"   âœ… [{len(charts)}] {field_info['korean_name']} ({field_info['top_ratio']:.1f}%) ì°¨íŠ¸ ìƒì„±")
        
        # 5ë‹¨ê³„: ìš”ì•½ ìƒì„±
        main_summary = f"ì´ {len(panels_data)}ëª…ì˜ ì‘ë‹µì ë°ì´í„°ë¥¼ ë¶„ì„í–ˆìŠµë‹ˆë‹¤. "
        if charts:
            top_chart = charts[0]
            summary_desc = top_chart.get('description', '')
            if 'ì „ì²´ ë°ì´í„° ê¸°ì¤€' in summary_desc:
                summary_desc = summary_desc.split(':', 1)[-1].strip()
            elif ':' in summary_desc:
                 summary_desc = summary_desc.split(':', 1)[-1].strip()
            
            # â€¼ï¸ [ìˆ˜ì •] ìš”ì•½ ë¬¸êµ¬ ìˆ˜ì •
            main_summary += f"ì£¼ìš” ë¶„ì„ ê²°ê³¼: {top_chart.get('topic', '')}ì—ì„œ {top_chart.get('ratio', '0%')}ì˜ ë¹„ìœ¨ì„ ë³´ì…ë‹ˆë‹¤."
        
        result = {
            "query": query,
            "total_count": len(panels_data),
            "main_summary": main_summary,
            "charts": charts
        }
        
        logging.info(f"âœ… ë¶„ì„ ì™„ë£Œ: {len(charts)}ê°œ ì°¨íŠ¸ ìƒì„± (ìµœì í™”)")
        return result, 200
        
    except Exception as e:
        logging.error(f"âŒ ë¶„ì„ ì‹¤íŒ¨: {e}", exc_info=True)
        return {"main_summary": f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", "charts": []}, 500

