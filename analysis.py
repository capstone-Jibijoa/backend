import json
import logging
import re 
from typing import List, Dict, Any, Tuple
from collections import Counter
from concurrent.futures import ThreadPoolExecutor, as_completed

from utils import (
    extract_field_values,
    calculate_distribution,
    find_top_category,
    FIELD_NAME_MAP,
    WELCOME_OBJECTIVE_FIELDS,
    get_panels_data_from_db 
)
from db import get_db_connection_context

# 1. ì •ì  ë§¤í•‘ ê·œì¹™ (Python ì½”ë“œë¡œ ê´€ë¦¬)
FIELD_MAPPING_RULES = [
    # --- type: "filter" (ê°ê´€ì‹ í•„í„°ìš©) ---
    (re.compile(r'^\d{2}ëŒ€$'), 
     {"field": "birth_year", "description": "ì—°ë ¹ëŒ€", "type": "filter"}),
    (re.compile(r'^\d{2}~\d{2}ëŒ€$'), 
     {"field": "birth_year", "description": "ì—°ë ¹ëŒ€", "type": "filter"}),
    (re.compile(r'ì Šì€ì¸µ|ì²­ë…„|MZì„¸ëŒ€'), 
     {"field": "birth_year", "description": "ì—°ë ¹ëŒ€", "type": "filter"}),
    
    (re.compile(r'^(ì„œìš¸|ê²½ê¸°|ë¶€ì‚°|ì¸ì²œ|ëŒ€êµ¬|ê´‘ì£¼|ëŒ€ì „|ìš¸ì‚°|ì„¸ì¢…|ê°•ì›|ì¶©ë¶|ì¶©ë‚¨|ì „ë¶|ì „ë‚¨|ê²½ë¶|ê²½ë‚¨|ì œì£¼)(íŠ¹ë³„)?(ì?ì¹˜)?(ì‹œ|ë„|ê´‘ì—­)?$', re.IGNORECASE), 
     {"field": "region_major", "description": "ê±°ì£¼ ì§€ì—­", "type": "filter"}),
    
    (re.compile(r'.*(ì‹œ|êµ¬|êµ°)$'), 
     {"field": "region_minor", "description": "ì„¸ë¶€ ê±°ì£¼ ì§€ì—­", "type": "filter"}),

    (re.compile(r'^(ë‚¨|ë‚¨ì|ë‚¨ì„±)$', re.IGNORECASE), 
     {"field": "gender", "description": "ì„±ë³„", "type": "filter"}),
    (re.compile(r'^(ì—¬|ì—¬ì|ì—¬ì„±)$', re.IGNORECASE), 
     {"field": "gender", "description": "ì„±ë³„", "type": "filter"}),
    
    ("ë¯¸í˜¼", {"field": "marital_status", "description": "ê²°í˜¼ ì—¬ë¶€", "type": "filter"}),
    ("ê¸°í˜¼", {"field": "marital_status", "description": "ê²°í˜¼ ì—¬ë¶€", "type": "filter"}),
    
    ("í¡ì—°", {"field": "smoking_experience", "description": "í¡ì—° ê²½í—˜", "type": "filter"}),
    ("ë¹„í¡ì—°", {"field": "smoking_experience", "description": "í¡ì—° ê²½í—˜", "type": "filter"}),
    
    ("ìŒì£¼", {"field": "drinking_experience", "description": "ìŒì£¼ ê²½í—˜", "type": "filter"}),
    ("ê¸ˆì£¼", {"field": "drinking_experience", "description": "ìŒì£¼ ê²½í—˜", "type": "filter"}),
    
    ("ì°¨ëŸ‰ë³´ìœ ", {"field": "car_ownership", "description": "ì°¨ëŸ‰ ë³´ìœ ", "type": "filter"}),
    ("ì°¨ì—†ìŒ", {"field": "car_ownership", "description": "ì°¨ëŸ‰ ë³´ìœ ", "type": "filter"}),
    # ê°œë…/ì£¼ê´€ì‹ í‚¤ì›Œë“œëŠ” ëª¨ë‘ ì œê±° -> 'unknown' ì²˜ë¦¬ë˜ì–´ ë²¡í„° ê²€ìƒ‰ìœ¼ë¡œ ìœ ë„
]

def get_field_mapping(keyword: str) -> Dict[str, str]:
    """
    [ìˆ˜ì •ë¨] í‚¤ì›Œë“œë¥¼ ë°›ì•„ ë§¤í•‘ë˜ëŠ” í•„ë“œ ì •ë³´ì™€ "íƒ€ì…"ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    í•„í„° ê·œì¹™ì— ì—†ìœ¼ë©´ 'unknown'ìœ¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    keyword_for_string_match = keyword.lower() 
    
    for pattern, mapping_info in FIELD_MAPPING_RULES:
        
        # [ìˆ˜ì •] 'type'ì„ ëª…ì‹œì ìœ¼ë¡œ í™•ì¸ (ê¸°ë³¸ê°’ 'filter')
        rule_type = mapping_info.get("type", "filter")
        if rule_type != "filter": # (í˜¹ì‹œ ëª¨ë¥¼ ì‹¤ìˆ˜ë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•´)
            continue
            
        field = mapping_info["field"]
        description = FIELD_NAME_MAP.get(field, mapping_info["description"])

        if isinstance(pattern, re.Pattern):
            if pattern.match(keyword): 
                return {"field": field, 
                        "description": description, 
                        "type": "filter"}
        elif isinstance(pattern, str):
            if pattern == keyword_for_string_match:
                return {"field": field, 
                        "description": description, 
                        "type": "filter"}
            
    # 'ê°„í˜¸ì§', 'OTT', 'it' ë“± í•„í„° ê·œì¹™ì— ì—†ëŠ” ëª¨ë“  í‚¤ì›Œë“œëŠ” 'unknown'ìœ¼ë¡œ ì²˜ë¦¬
    # (ì£¼ì˜: search.pyì˜ íŒŒì„œê°€ 'unknown' íƒ€ì…ì„ 'vector'ë¡œ í•´ì„í•´ì•¼ í•¨)
    logging.warning(f" âš ï¸  '{keyword}'ì— ëŒ€í•œ ë§¤í•‘ ê·œì¹™ ì—†ìŒ. 'unknown'(ë²¡í„°)ìœ¼ë¡œ ì²˜ë¦¬.")
    return {"field": "unknown", "description": keyword, "type": "unknown"}


def get_field_distribution_from_db(field_name: str, limit: int = 10) -> Dict[str, float]:
    """
    PostgreSQLì—ì„œ ì§ì ‘ ì§‘ê³„í•˜ì—¬ í•„ë“œ ë¶„í¬ ì¡°íšŒ (ì „ì²´ DB ëŒ€ìƒ)
    (ìºì‹œ ë¡¤ë°± ë²„ì „)
    """
    try:
        with get_db_connection_context() as conn:
            if not conn:
                logging.error("DB ì§‘ê³„: ì—°ê²° ì‹¤íŒ¨")
                return {}
            
            cur = conn.cursor()
            
            if field_name == "birth_year":
                query = f"""
                    WITH age_groups AS (
                        SELECT 
                            CASE 
                                WHEN (date_part('year', CURRENT_DATE) - (structured_data->>'birth_year')::int) < 20 THEN '10ëŒ€'
                                WHEN (date_part('year', CURRENT_DATE) - (structured_data->>'birth_year')::int) < 30 THEN '20ëŒ€'
                                WHEN (date_part('year', CURRENT_DATE) - (structured_data->>'birth_year')::int) < 40 THEN '30ëŒ€'
                                WHEN (date_part('year', CURRENT_DATE) - (structured_data->>'birth_year')::int) < 50 THEN '40ëŒ€'
                                WHEN (date_part('year', CURRENT_DATE) - (structured_data->>'birth_year')::int) < 60 THEN '50ëŒ€'
                                ELSE '60ëŒ€ ì´ìƒ'
                            END as age_group
                        FROM welcome_meta2
                        WHERE structured_data->>'birth_year' IS NOT NULL
                            AND structured_data->>'birth_year' ~ '^[0-9]+$'
                    )
                    SELECT 
                        age_group,
                        COUNT(*) as count,
                        ROUND(COUNT(*) * 100.0 / SUM(COUNT(*)) OVER (), 1) as percentage
                    FROM age_groups
                    GROUP BY age_group
                    ORDER BY percentage DESC
                    LIMIT {limit}
                """
            else:
                query = f"""
                    SELECT 
                        structured_data->>'{field_name}' as value,
                        COUNT(*) as count,
                        ROUND(COUNT(*) * 100.0 / SUM(COUNT(*)) OVER (), 1) as percentage
                    FROM welcome_meta2
                    WHERE structured_data->>'{field_name}' IS NOT NULL
                        AND structured_data->>'{field_name}' != ''
                    GROUP BY structured_data->>'{field_name}'
                    ORDER BY percentage DESC
                    LIMIT {limit}
                """
            
            cur.execute(query)
            rows = cur.fetchall()
            
            distribution = {}
            for row in rows:
                value = row[0]
                percentage = float(row[2])
                if value and percentage > 0:
                    distribution[value] = percentage
            
            cur.close()
        
        logging.info(f"   ğŸ“Š DB ì§‘ê³„ ì™„ë£Œ: {field_name} ({len(distribution)}ê°œ ì¹´í…Œê³ ë¦¬)")
        return distribution
        
    except Exception as e:
        logging.error(f"   DB ì§‘ê³„ ì‹¤íŒ¨ ({field_name}): {e}", exc_info=True)
        return {}

def create_chart_data_optimized(
    keyword: str,
    field_name: str,
    korean_name: str,
    panels_data: List[Dict],
    use_full_db: bool = False,
    max_categories: int = 10
) -> Dict:
    """
    ì°¨íŠ¸ ë°ì´í„° ìƒì„± (ìµœì í™” ë²„ì „)
    """
    # ì „ì²´ DB ê¸°ë°˜ ë¶„ì„
    if use_full_db:
        logging.info(f"       â†’ DB ì§‘ê³„ë¡œ '{field_name}' ë¶„ì„ (ìµœì í™”)")
        distribution = get_field_distribution_from_db(field_name, max_categories)
        
        if not distribution:
            return {
                "topic": korean_name,
                "description": f"'{keyword}' ê´€ë ¨ ì „ì²´ ë°ì´í„°ë¥¼ ì¡°íšŒí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                "ratio": "0.0%",
                "chart_data": []
            }
        
        top_category, top_ratio = find_top_category(distribution)
        description_prefix = f"ì „ì²´ ë°ì´í„° ê¸°ì¤€ '{korean_name}' ë¶„ì„:"
        
        return {
            "topic": f"{korean_name} ë¶„í¬",
            "description": f"{description_prefix} {top_ratio}%ê°€ '{top_category}'ì…ë‹ˆë‹¤.",
            "ratio": f"{top_ratio}%",
            "chart_data": [{"label": korean_name, "values": distribution}]
        }
    
    # ê²€ìƒ‰ ê²°ê³¼ ê¸°ë°˜ ë¶„ì„
    else:
        values = extract_field_values(panels_data, field_name)
        
        if not values:
            return { "topic": korean_name, "description": "ë°ì´í„° ë¶€ì¡±", "ratio": "0.0%", "chart_data": [] }
        
        distribution = calculate_distribution(values)
        filtered_distribution = {k: v for k, v in distribution.items() if v > 0.0}
        
        if not filtered_distribution:
            return { "topic": korean_name, "description": "ë°ì´í„° ë¶€ì¡±", "ratio": "0.0%", "chart_data": [] }
        
        # ìƒìœ„ Nê°œë§Œ + ê¸°íƒ€
        if len(filtered_distribution) > max_categories:
            sorted_items = sorted(filtered_distribution.items(), key=lambda x: x[1], reverse=True)
            top_items = dict(sorted_items[:max_categories - 1])
            other_sum = sum(v for k, v in sorted_items[max_categories - 1:])
            if other_sum > 0:
                top_items['ê¸°íƒ€'] = round(other_sum, 1)
            final_distribution = top_items
        else:
            final_distribution = filtered_distribution
        
        top_category, top_ratio = find_top_category(final_distribution)
        
        return {
            "topic": f"{korean_name} ë¶„í¬",
            "description": f"'{keyword}' ê²€ìƒ‰ ê²°ê³¼: {top_ratio}%ê°€ '{top_category}'ì…ë‹ˆë‹¤.",
            "ratio": f"{top_ratio}%",
            "chart_data": [{
                "label": korean_name,
                "values": final_distribution
            }]
        }

def create_crosstab_chart(
    panels_data: List[Dict],
    field1: str,  # ì£¼ì¶• (e.g., 'birth_year')
    field2: str,  # ì„¸ê·¸ë¨¼íŠ¸ (e.g., 'gender')
    field1_korean: str,
    field2_korean: str,
    max_categories: int = 5
) -> Dict:
    """
    êµì°¨ ë¶„ì„ ì°¨íŠ¸ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. (ì˜ˆ: ì—°ë ¹ëŒ€ë³„ ì„±ë³„ ë¶„í¬)
    """
    logging.info(f"       â†’ êµì°¨ ë¶„ì„ìœ¼ë¡œ '{field1}' vs '{field2}' ë¶„ì„")
    from utils import get_age_group

    # 1. ë‘ í•„ë“œì— ëŒ€í•œ ë°ì´í„° ì¶”ì¶œ
    crosstab_data = {}
    for item in panels_data:
        val1 = item.get(field1)
        val2 = item.get(field2)

        if val1 is None or val2 is None:
            continue

        # ê°’ ì²˜ë¦¬ (ì—°ë ¹ëŒ€ ë³€í™˜ ë“±)
        key1 = get_age_group(val1) if field1 == 'birth_year' else str(val1)
        key2 = str(val2)

        if key1 not in crosstab_data:
            crosstab_data[key1] = []
        crosstab_data[key1].append(key2)

    if not crosstab_data:
        return {}

    # 2. ê° ì£¼ì¶• ì¹´í…Œê³ ë¦¬ë³„ë¡œ ì„¸ê·¸ë¨¼íŠ¸ ë¶„í¬ ê³„ì‚°
    chart_values = {}
    for key1, values2 in crosstab_data.items():
        distribution = calculate_distribution(values2)
        chart_values[key1] = distribution

    # 3. ì£¼ì¶• ì¹´í…Œê³ ë¦¬ê°€ ë„ˆë¬´ ë§ìœ¼ë©´ ìƒìœ„ Nê°œë§Œ ì„ íƒ
    if len(chart_values) > max_categories:
        # ê° ì¹´í…Œê³ ë¦¬ì˜ ì „ì²´ ê°œìˆ˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
        sorted_keys = sorted(chart_values.keys(), key=lambda k: sum(crosstab_data[k].count(v) for v in set(crosstab_data[k])), reverse=True)
        chart_values = {k: chart_values[k] for k in sorted_keys[:max_categories]}

    if not chart_values:
        return {}

    return {
        "topic": f"{field1_korean}ë³„ {field2_korean} ë¶„í¬",
        "description": f"'{field1_korean}'ì— ë”°ë¥¸ '{field2_korean}'ì˜ ìƒëŒ€ì  ë¶„í¬ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.",
        "chart_type": "crosstab",
        "chart_data": [{"label": f"{field1_korean}ë³„ {field2_korean}", "values": chart_values}]
    }


def _analyze_fields_in_parallel(panels_data: List[Dict], candidate_fields: List[Tuple[str, str]]) -> List[Dict]:
    """
    [ë¦¬íŒ©í† ë§] panels_dataë¥¼ í•œ ë²ˆë§Œ ìˆœíšŒí•˜ì—¬ ëª¨ë“  í›„ë³´ í•„ë“œì˜ ê°’ì„ ì§‘ê³„í•˜ê³  ë¶„í¬ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    """
    field_values = {field_name: [] for field_name, _ in candidate_fields}
    field_map = dict(candidate_fields)

    # ë°ì´í„°ë¥¼ í•œ ë²ˆë§Œ ìˆœíšŒí•˜ì—¬ ëª¨ë“  í•„ë“œì˜ ê°’ì„ ì¶”ì¶œ
    for item in panels_data:
        for field_name in field_values.keys():
            value = item.get(field_name)
            if value is None:
                continue

            if field_name == "birth_year":
                from utils import get_age_group
                field_values[field_name].append(get_age_group(value))
            elif isinstance(value, list):
                field_values[field_name].extend(value)
            else:
                field_values[field_name].append(value)

    results = []
    for field_name, values in field_values.items():
        if not values:
            continue
        
        try:
            distribution = calculate_distribution(values)
            filtered_distribution = {k: v for k, v in distribution.items() if v > 0.0}
            if not filtered_distribution:
                continue

            results.append({
                "field": field_name,
                "korean_name": field_map[field_name],
                "distribution": filtered_distribution,
            })
        except Exception as e:
            logging.warning(f"   âš ï¸  {field_name} ë¶„í¬ ê³„ì‚° ì‹¤íŒ¨: {e}")

    return results


def find_high_ratio_fields_optimized(
    panels_data: List[Dict], 
    exclude_fields: List[str], 
    threshold: float = 50.0,
    max_charts: int = 3
) -> List[Dict]:
    """
    ê²€ìƒ‰ ê²°ê³¼(panels_data) ë‚´ì—ì„œ ë†’ì€ ë¹„ìœ¨ì„ ì°¨ì§€í•˜ëŠ” í•„ë“œ ì°¾ê¸° (ë³‘ë ¬ ì²˜ë¦¬)
    """
    candidate_fields = []
    
    for field_name, korean_name in WELCOME_OBJECTIVE_FIELDS:
        if field_name not in exclude_fields:
            candidate_fields.append((field_name, korean_name))
    
    if not candidate_fields:
        return []
    
    logging.info(f"   ğŸ” {len(candidate_fields)}ê°œ í•„ë“œ ë³‘ë ¬ ë¶„ì„ ì¤‘... (ì œì™¸ í•„ë“œ: {exclude_fields})")
    
    analysis_results = _analyze_fields_in_parallel(panels_data, candidate_fields)
    
    high_ratio_results = []
    for result in analysis_results:
        distribution = result['distribution']
        
        # 100% ë‹¨ì¼ ì¹´í…Œê³ ë¦¬ ìŠ¤í‚µ
        if len(distribution) == 1:
            top_category, top_ratio = find_top_category(distribution) 
            logging.info(f"   âš ï¸  [{result['korean_name']}] ìŠ¤í‚µ: {top_category} {top_ratio}% (ë‹¨ì¼ ì¹´í…Œê³ ë¦¬ 100%)")
            continue
        
        top_category, top_ratio = find_top_category(distribution)
        
        # 50% ì´ìƒì´ë¼ëŠ” 1ì°¨ ì„ê³„ê°’ í†µê³¼ ì‹œ
        if top_ratio >= threshold:
        
            final_distribution = distribution
            if len(distribution) > 10:
                sorted_items = sorted(distribution.items(), key=lambda x: x[1], reverse=True)
                top_items = dict(sorted_items[:9])
                other_sum = sum(v for k, v in sorted_items[9:])
                if other_sum > 0:
                    top_items['ê¸°íƒ€'] = round(other_sum, 1)
                final_distribution = top_items
            
            high_ratio_results.append({
                "field": result['field'],
                "korean_name": result['korean_name'],
                "distribution": final_distribution,
                "top_category": top_category,
                "top_ratio": top_ratio
            })
    
    high_ratio_results.sort(key=lambda x: x["top_ratio"], reverse=True)
    
    return high_ratio_results[:max_charts]

def analyze_search_results_optimized(
    query: str,
    classified_keywords: dict,
    panel_id_list: List[str]
) -> Tuple[Dict, int]:
    """
    ê²€ìƒ‰ ê²°ê³¼ ë¶„ì„ (ìµœì í™” ë²„ì „)
    """
    logging.info(f"ğŸ“Š ë¶„ì„ ì‹œì‘ (ìµœì í™”) - panel_id ìˆ˜: {len(panel_id_list)}ê°œ")
    
    if not panel_id_list:
        return {"main_summary": "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.", "charts": []}, 200
    
    try:
        # 1ë‹¨ê³„: íŒ¨ë„ ë°ì´í„° ì¡°íšŒ
        logging.info("   1ë‹¨ê³„: íŒ¨ë„ ë°ì´í„° ì¡°íšŒ (utils.py ì‚¬ìš©)")
        panels_data = get_panels_data_from_db(panel_id_list)
        
        if not panels_data:
            return {"main_summary": "íŒ¨ë„ ë°ì´í„°ë¥¼ ì¡°íšŒí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", "charts": []}, 200
        
        logging.info(f"   âœ… {len(panels_data)}ê°œ íŒ¨ë„ ë°ì´í„° ì¡°íšŒ ì™„ë£Œ")
        
        # 2ë‹¨ê³„: ranked_keywords ì¶”ì¶œ ë° ë§¤í•‘
        # (ì£¼ì˜: search.pyì—ì„œ LLM ëŒ€ì‹  ê·œì¹™ ê¸°ë°˜ íŒŒì„œë¡œ ëŒ€ì²´ë˜ì—ˆë‹¤ë©´
        #       classified_keywords['ranked_keywords_raw']ê°€ ì˜¬ë°”ë¥´ê²Œ ì „ë‹¬ë˜ì–´ì•¼ í•¨)
        raw_keywords = classified_keywords.get('ranked_keywords_raw', [])
        ranked_keywords = []
        search_used_fields = set()
        
        if raw_keywords:
            logging.info(f"   2aë‹¨ê³„: (ê·œì¹™ ê¸°ë°˜) í‚¤ì›Œë“œ {raw_keywords} ë§¤í•‘ ì‹œì‘")
            for i, keyword in enumerate(raw_keywords):
                
                mapping = get_field_mapping(keyword) 
                kw_type = mapping.get("type", "unknown")
                
                ranked_keywords.append({
                    "keyword": keyword, 
                    "field": mapping["field"],
                    "description": mapping["description"], 
                    "type": kw_type, # [ìˆ˜ì •] type ì •ë³´ ì €ì¥
                    "priority": i + 1
                })
                
                # [ìˆ˜ì •] 'filter' íƒ€ì…ì´ê³  'unknown'ì´ ì•„ë‹Œ ê²½ìš°ì—ë§Œ 'ë»”í•œ í•„ë“œ'ë¡œ ì¶”ê°€
                if kw_type == 'filter' and mapping["field"] != 'unknown':
                    search_used_fields.add(mapping["field"])
        
        if not ranked_keywords:
            logging.warning("   âš ï¸  'ranked_keywords_raw' ì—†ìŒ. (Fallback ë¡œì§ ì‹¤í–‰)")
            # (Fallback ë¡œì§ì€ LLMì„ ì‚¬ìš©í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ìˆ˜ì •ì´ í•„ìš”í•  ìˆ˜ ìˆìŒ)
            obj_keywords = classified_keywords.get('welcome_keywords', {}).get('objective', [])
            for i, kw in enumerate(obj_keywords[:5]):
                mapping = get_field_mapping(kw) # [ìˆ˜ì •] ìˆ˜ì •ëœ í•¨ìˆ˜ í˜¸ì¶œ
                ranked_keywords.append({
                    'keyword': kw, 
                    'field': mapping["field"],
                    'description': mapping["description"], 
                    'type': mapping.get("type", "unknown"), # [ìˆ˜ì •] type ì •ë³´ ì €ì¥
                    'priority': i + 1
                })
                if mapping["type"] == 'filter' and mapping["field"] != 'unknown': # [ìˆ˜ì •] type ì²´í¬
                    search_used_fields.add(mapping["field"])
            
        if not ranked_keywords:
            return { "main_summary": f"ì´ {len(panels_data)}ëª… ì¡°íšŒ, ë¶„ì„í•  í‚¤ì›Œë“œ ì—†ìŒ.", "charts": [] }, 200
        
        ranked_keywords.sort(key=lambda x: x.get('priority', 999))
        logging.info(f"   âœ… ë¶„ì„ í‚¤ì›Œë“œ: {[k.get('keyword') for k in ranked_keywords]}")
        logging.info(f"   âœ… ê²€ìƒ‰ ì‚¬ìš© í•„ë“œ (ë»”í•œ ì¸ì‚¬ì´íŠ¸ ì œì™¸ìš©): {search_used_fields}")
        
        # 3ë‹¨ê³„: ranked_keywords ê¸°ë°˜ ì°¨íŠ¸ ìƒì„±
        logging.info("   3ë‹¨ê³„: ì£¼ìš” í‚¤ì›Œë“œ ì°¨íŠ¸ ìƒì„± (DB ì§‘ê³„, ë³‘ë ¬)")
        charts = []
        used_fields = []
        objective_fields = set([f[0] for f in WELCOME_OBJECTIVE_FIELDS])
        
        # 1. ìƒì„±í•  ì°¨íŠ¸ ì‘ì—… ëª©ë¡ ì •ì˜
        chart_tasks = [] 
        chart_count = 0
        for kw_info in ranked_keywords:
            if chart_count >= 2: break
            
            field = kw_info.get('field', '')
            kw_type = kw_info.get('type', 'unknown') # [ìˆ˜ì •] type ê°€ì ¸ì˜¤ê¸°
            
            # [ìˆ˜ì •] 'filter' íƒ€ì…ì¸ í‚¤ì›Œë“œë§Œ 3ë‹¨ê³„ ì°¨íŠ¸ ìƒì„±
            if kw_type != 'filter' or not field or field == 'unknown' or field not in objective_fields or field in used_fields:
                # ('it', 'ê°„í˜¸ì§' ë“± ë²¡í„°/unknown í‚¤ì›Œë“œëŠ” ì—¬ê¸°ì„œ ì°¨íŠ¸ ìƒì„± ì•ˆ í•¨)
                continue
            
            chart_tasks.append(kw_info)
            used_fields.append(field) 
            chart_count += 1

        # 2. ThreadPoolExecutorë¡œ ì°¨íŠ¸ ìƒì„± ë³‘ë ¬ ì‹¤í–‰
        if chart_tasks:
            with ThreadPoolExecutor(max_workers=len(chart_tasks) or 1) as executor:
                
                def create_chart_task(kw_info):
                    field = kw_info.get('field', '')
                    logging.info(f"   âš¡ [{field}] ì°¨íŠ¸ DB ì§‘ê³„ ìŠ¤ë ˆë“œ ì‹œì‘...")
                    return create_chart_data_optimized(
                        kw_info.get('keyword', ''), 
                        field, 
                        kw_info.get('description', FIELD_NAME_MAP.get(field, field)),
                        panels_data, 
                        use_full_db=True
                    )

                futures = {executor.submit(create_chart_task, kw_info): kw_info for kw_info in chart_tasks}
                
                for future in as_completed(futures):
                    kw_info_original = futures[future] 
                    field_name = kw_info_original.get('field', 'unknown')
                    try:
                        chart = future.result() 
                        if chart.get('chart_data') and chart.get('ratio') != '0.0%':
                            chart['priority'] = kw_info_original.get('priority', 99)
                            charts.append(chart)
                            logging.info(f"   âœ… [{field_name}] ì°¨íŠ¸ ìƒì„± ì™„ë£Œ (DB ì§‘ê³„)")
                        else:
                            logging.warning(f"   âš ï¸  [{field_name}] ì°¨íŠ¸ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŒ (DB ì§‘ê³„)")
                    except Exception as e:
                        logging.error(f"   âŒ [{field_name}] ì°¨íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}", exc_info=True)
            
            charts.sort(key=lambda x: x.get('priority', 99))
            
            for chart in charts:
                if 'priority' in chart:
                    del chart['priority']

        # 3.5ë‹¨ê³„: êµì°¨ ë¶„ì„ ì°¨íŠ¸ ìƒì„±
        logging.info("   3.5ë‹¨ê³„: êµì°¨ ë¶„ì„ ì°¨íŠ¸ ìƒì„±")
        if len(charts) < 5 and len(ranked_keywords) > 0:
            
            CROSSTAB_CANDIDATES = [
                ('gender', 'ì„±ë³„'),
                ('birth_year', 'ì—°ë ¹ëŒ€'),
                ('marital_status', 'ê²°í˜¼ ì—¬ë¶€'),
                ('income_personal_monthly', 'ì†Œë“ ìˆ˜ì¤€'),
                ('job_duty_raw', 'ì§ë¬´'), 
                ('job_title_raw', 'ì§ì—…'),
            ]
            
            primary_kw = None
            for kw in ranked_keywords:
                if kw.get("type") == "filter":
                    primary_kw = kw
                    break 
            
            primary_field = None
            primary_korean_name = None
            
            if primary_kw:
                primary_field = primary_kw.get('field')
                primary_korean_name = primary_kw.get('description')
            
            secondary_field = None
            secondary_korean_name = None
            
            if primary_field and primary_field != 'unknown' and primary_field in objective_fields:
                for field, korean in CROSSTAB_CANDIDATES:
                    if field == primary_field or field in search_used_fields:
                        continue
                    
                    secondary_field = field
                    secondary_korean_name = korean
                    logging.info(f"   âœ¨ ìƒˆ êµì°¨ë¶„ì„ ì¶• ë°œê²¬: '{primary_korean_name}' vs '{secondary_korean_name}'")
                    break
            
            if secondary_field:
                crosstab_chart = create_crosstab_chart(
                    panels_data,
                    primary_field, secondary_field,
                    primary_korean_name, secondary_korean_name
                )
                if crosstab_chart:
                    charts.append(crosstab_chart)
                    if primary_field not in used_fields:
                         used_fields.append(primary_field) 
                    # [ìˆ˜ì •] êµì°¨ë¶„ì„ ë³´ì¡°ì¶•ë„ ì œì™¸ ëª©ë¡ì— ì¶”ê°€
                    if secondary_field not in used_fields:
                        used_fields.append(secondary_field)
                    logging.info(f"   âœ… [{len(charts)}] êµì°¨ ë¶„ì„ ì°¨íŠ¸ ìƒì„± ({primary_korean_name} vs {secondary_korean_name})")
            else:
                logging.warning("   âš ï¸  êµì°¨ ë¶„ì„ ìŠ¤í‚µ: 1ìˆœìœ„ í•„í„° í‚¤ì›Œë“œê°€ ì—†ê±°ë‚˜, ì ì ˆí•œ ë³´ì¡°ì¶• í›„ë³´ê°€ ì—†ìŒ (ëª¨ë‘ ê²€ìƒ‰ì–´ì— í¬í•¨ë¨)")
                
        # 4ë‹¨ê³„: ë†’ì€ ë¹„ìœ¨ í•„ë“œ ì°¾ê¸°
        logging.info("   4ë‹¨ê³„: ë†’ì€ ë¹„ìœ¨ í•„ë“œ ì°¨íŠ¸ ìƒì„± (ê²€ìƒ‰ ê²°ê³¼ ê¸°ë°˜)")
        needed_charts = 5 - len(charts)
        # 3.5ë‹¨ê³„ì—ì„œ ë³´ì¡°ì¶•ê¹Œì§€ ì œì™¸ë¨
        exclude_fields_for_step4 = list(set(used_fields) | search_used_fields)
        
        if needed_charts > 0:
            high_ratio_fields = find_high_ratio_fields_optimized(
                panels_data, 
                # [ë¡¤ë°±] ê²€ìƒ‰ì— ì‚¬ìš©ëœ í•„ë“œì™€ ì´ë¯¸ ì°¨íŠ¸ë¡œ ë§Œë“¤ì–´ì§„ í•„ë“œë¥¼ ì œì™¸
                exclude_fields=exclude_fields_for_step4,
                threshold=50.0,
                max_charts=needed_charts
            )
            
            for field_info in high_ratio_fields:
                if len(charts) >= 5: break
                
                chart = {
                    "topic": f"{field_info['korean_name']} ë¶„í¬",
                    "description": f"{field_info['top_ratio']:.1f}%ê°€ '{field_info['top_category']}'ë¡œ ëšœë ·í•œ íŒ¨í„´ì„ ë³´ì…ë‹ˆë‹¤.",
                    "ratio": f"{field_info['top_ratio']:.1f}%",
                    "chart_data": [{"label": field_info['korean_name'], "values": field_info['distribution']}]
                }
                charts.append(chart)
                logging.info(f"   âœ… [{len(charts)}] {field_info['korean_name']} ({field_info['top_ratio']:.1f}%) ì°¨íŠ¸ ìƒì„±")
        
        # 5ë‹¨ê³„: ìš”ì•½ ìƒì„±
        main_summary = f"ì´ {len(panels_data)}ëª…ì˜ ì‘ë‹µì ë°ì´í„°ë¥¼ ë¶„ì„í–ˆìŠµë‹ˆë‹¤. "
        if charts:
            top_chart = charts[0]
            summary_desc = top_chart.get('description', '')
            if 'ì „ì²´ ë°ì´í„° ê¸°ì¤€' in summary_desc:
                summary_desc = summary_desc.split(':', 1)[-1].strip()
            elif ':' in summary_desc:
                 summary_desc = summary_desc.split(':', 1)[-1].strip()
            
            main_summary += f"ì£¼ìš” ë¶„ì„ ê²°ê³¼: {top_chart.get('topic', '')}ì—ì„œ {top_chart.get('ratio', '0%')}ì˜ ë¹„ìœ¨ì„ ë³´ì…ë‹ˆë‹¤."
        
        result = {
            "query": query,
            "total_count": len(panels_data),
            "main_summary": main_summary,
            "charts": charts
        }
        
        logging.info(f"âœ… ë¶„ì„ ì™„ë£Œ: {len(charts)}ê°œ ì°¨íŠ¸ ìƒì„± (ìµœì í™”)")
        return result, 200
        
    except Exception as e:
        logging.error(f"âŒ ë¶„ì„ ì‹¤íŒ¨: {e}", exc_info=True)
        return {"main_summary": f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", "charts": []}, 500