import json
import re
import os
import logging
from typing import Dict, List, Optional, Any
from functools import lru_cache
from langchain_anthropic import ChatAnthropic
from langchain_core.messages import SystemMessage, HumanMessage
from dotenv import load_dotenv

load_dotenv()

# 1. Claude í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
try:
    # API KeyëŠ” í™˜ê²½ë³€ìˆ˜(.env)ì—ì„œ ìë™ìœ¼ë¡œ ë¡œë“œë©ë‹ˆë‹¤.
    CLAUDE_CLIENT = ChatAnthropic(model="claude-sonnet-4-5", temperature=0.1)
except Exception as e:
    CLAUDE_CLIENT = None
    logging.error(f"Anthropic í´ë¼ì´ì–¸íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")


# 2. DB ìŠ¤í‚¤ë§ˆ ì •ë³´
DB_SCHEMA_INFO = """
## PostgreSQL (ì¸êµ¬í†µê³„): gender, birth_year, region_major, marital_status, education_level, job_title_raw, income_household_monthly, car_ownership, smoking_experience, drinking_experience

## Qdrant (ë²¡í„° ê²€ìƒ‰):
- welcome_subjective_vectors: ì£¼ê´€ì‹ ë‹µë³€ ì „ì²´
- qpoll_vectors_v2: ë¼ì´í”„ìŠ¤íƒ€ì¼ ì„¤ë¬¸ (ott_count, physical_activity, skincare_spending, ai_chatbot_used, stress_relief_method, travel_planning_style ë“± 40+ ì¹´í…Œê³ ë¦¬)
"""

# 3. ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (ìˆ˜ì •ë¨: {{QUERY}} ìœ„ì¹˜ ëª…ì‹œ ë° JSON í¬ë§· ìµœì í™”)
SYSTEM_PROMPT_V2 = """
ë‹¹ì‹ ì€ ìì—°ì–´ ì¿¼ë¦¬ë¥¼ ë¶„ì„í•˜ì—¬ **"ì •í˜• í•„í„°(SQL)"**ì™€ **"ì˜ë¯¸ ê²€ìƒ‰ ì¡°ê±´(Vector Search)"**ìœ¼ë¡œ ì™„ë²½í•˜ê²Œ ë¶„ë¦¬í•˜ëŠ” **Search Query Analyzer**ì…ë‹ˆë‹¤.

## âš ï¸ ì ˆëŒ€ ì£¼ì˜ì‚¬í•­
1. ìœ„ ì˜ˆì‹œ(Examples)ì˜ ë°ì´í„°(ë‚˜ì´, ì„±ë³„, í‚¤ì›Œë“œ)ë¥¼ ê·¸ëŒ€ë¡œ ë² ë¼ì§€ ë§ˆì‹­ì‹œì˜¤.
2. ë°˜ë“œì‹œ ì•„ë˜ ì œê³µë˜ëŠ” **[ì‚¬ìš©ì ì¿¼ë¦¬]**ì˜ ë‚´ìš©ë§Œ ë¶„ì„í•˜ì‹­ì‹œì˜¤.
3. ì¿¼ë¦¬ì— ì–¸ê¸‰ë˜ì§€ ì•Šì€ ì¡°ê±´(ì„±ë³„, ë‚˜ì´ ë“±)ì„ ì„ì˜ë¡œ ìƒì„±í•˜ì§€ ë§ˆì‹­ì‹œì˜¤.

## ğŸ¯ ëª©í‘œ
ì‚¬ìš©ìì˜ ì§ˆë¬¸ì—ì„œ **'ëˆ„êµ¬(Who)'**ì— í•´ë‹¹í•˜ëŠ” ì¸êµ¬í†µê³„í•™ì  ì¡°ê±´ê³¼ **'ë¬´ì—‡(What)'**ì— í•´ë‹¹í•˜ëŠ” í–‰ë™/ì„±í–¥/ê²½í—˜ ì¡°ê±´ì„ ëª…í™•íˆ ë¶„ë¦¬í•˜ì—¬ êµ¬ì¡°í™”ëœ JSONìœ¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.

## ğŸ› ï¸ ìˆ˜í–‰ ì‘ì—… ì •ì˜

### 1. Demographic Filters (SQL í•„í„°)
- **ëŒ€ìƒ**: ë‚˜ì´, ì„±ë³„, ê±°ì£¼ì§€ì—­, ê²°í˜¼ì—¬ë¶€, ìë…€ìˆ˜, ì§ì—…, ì†Œë“, íœ´ëŒ€í° ê¸°ì¢…, ì°¨ëŸ‰ ë³´ìœ  ì—¬ë¶€ ë“± **ê°ê´€ì ì´ê³  ëª…í™•í•œ í”„ë¡œí•„ ì •ë³´**.
- **ê·œì¹™**: ì¿¼ë¦¬ì— ëª…ì‹œëœ ë‚´ìš©ë§Œ ì¶”ì¶œí•©ë‹ˆë‹¤. (ì¶”ë¡  ê¸ˆì§€)
- **ì˜ˆì‹œ**: "20ëŒ€", "ì„œìš¸ ê±°ì£¼", "ì•„ì´í° ìœ ì €", "ë¯¸í˜¼"

### 2. Semantic Conditions (ì˜ë¯¸ ê²€ìƒ‰ - í•µì‹¬!)
- **ëŒ€ìƒ**: ì·¨ë¯¸, ìŠµê´€, ì„ í˜¸ë„, ë¼ì´í”„ìŠ¤íƒ€ì¼, ê²½í—˜, ê°€ì¹˜ê´€, ê³ ë¯¼ ë“± **ì£¼ê´€ì ì´ê±°ë‚˜ í–‰ë™ì— ê´€ë ¨ëœ ëª¨ë“  í‘œí˜„**.
- **ê·œì¹™**: ì¸êµ¬í†µê³„ê°€ ì•„ë‹Œ ëª¨ë“  ëª…ì‚¬/ë™ì‚¬ êµ¬ë¬¸ì€ ì´ê³³ìœ¼ë¡œ ë¶„ë¥˜í•´ì•¼ í•©ë‹ˆë‹¤.
- **ì¤‘ìš”**: "OTTë¥¼ ë³´ëŠ”", "ìš´ë™ì„ ì¦ê¸°ëŠ”", "ì•¼ì‹ì„ ë¨¹ëŠ”", "ìŠ¤íŠ¸ë ˆìŠ¤ ë°›ëŠ”" ë“±ì€ ì ˆëŒ€ í•„í„°ê°€ ì•„ë‹Œ **Semantic Condition**ì…ë‹ˆë‹¤.
- **ì†ì„± ì •ì˜**:
  - `original_keyword`: ì‚¬ìš©ì ì¿¼ë¦¬ ê·¸ëŒ€ë¡œì˜ í‘œí˜„ (ì˜ˆ: "OTT ì´ìš©")
  - `expanded_queries`: ë¼ìš°í„° ë§¤ì¹­ì„ ë•ê¸° ìœ„í•œ 3~4ê°œì˜ êµ¬ì²´ì ì¸ ë¬¸ì¥í˜• ë™ì˜ì–´. (ì˜ˆ: "ë„·í”Œë¦­ìŠ¤ë‚˜ ìœ íŠœë¸Œë¥¼ ìì£¼ ì‹œì²­í•œë‹¤", "ë™ì˜ìƒ ìŠ¤íŠ¸ë¦¬ë° ì„œë¹„ìŠ¤ë¥¼ êµ¬ë… ì¤‘ì´ë‹¤")
  - `importance`: 0.9(í•„ìˆ˜/í•µì‹¬ì£¼ì œ), 0.7(ì¤‘ìš”ì¡°ê±´), 0.5(ë‹¨ìˆœì„ í˜¸)

---
## ğŸ“‹ DB ìŠ¤í‚¤ë§ˆ ì •ë³´ (ì°¸ê³ ìš©)
{schema}
---

## ğŸ’¡ Few-Shot ì˜ˆì‹œ

### ì˜ˆì‹œ 1: ë³µí•© ì¡°ê±´ (í•„í„° + ì˜ë¯¸)
**ì¿¼ë¦¬**: "ì„œìš¸ ê²½ê¸° ì‚¬ëŠ” 20ëŒ€ ë‚¨ì„± ì¤‘ OTTë¥¼ ì¦ê²¨ ë³´ê³  ì£¼ë§ì— ë°°ë‹¬ìŒì‹ ì‹œì¼œë¨¹ëŠ” ì‚¬ëŒ 30ëª…"
**ë¶„ì„ ê²°ê³¼**:
{
  "demographic_filters": {
    "region_major": ["ì„œìš¸", "ê²½ê¸°"],
    "age_range": [20, 29],
    "gender": ["ë‚¨ì„±"]
  },
  "semantic_conditions": [
    {
      "id": "cond_1",
      "original_keyword": "OTTë¥¼ ì¦ê²¨ ë³´ê³ ",
      "importance": 0.9,
      "expanded_queries": ["ë„·í”Œë¦­ìŠ¤, ì™“ì±  ë“± OTT ì„œë¹„ìŠ¤ë¥¼ ìì£¼ ì´ìš©í•œë‹¤", "ì£¼ë§ì— ë™ì˜ìƒ ìŠ¤íŠ¸ë¦¬ë°ì„ ëª°ì•„ë³¸ë‹¤", "OTT êµ¬ë…ë£Œë¥¼ ì§€ì¶œí•œë‹¤"],
      "search_strategy": "category_specific"
    },
    {
      "id": "cond_2",
      "original_keyword": "ì£¼ë§ì— ë°°ë‹¬ìŒì‹ ì‹œì¼œë¨¹ëŠ”",
      "importance": 0.7,
      "expanded_queries": ["ë°°ë‹¬ ì•±ì„ ìì£¼ ì‚¬ìš©í•œë‹¤", "ì£¼ë§ ì‹ì‚¬ë¥¼ ì£¼ë¡œ ë°°ë‹¬ ìŒì‹ìœ¼ë¡œ í•´ê²°í•œë‹¤", "ë°°ë‹¬ì˜ë¯¼ì¡±ì´ë‚˜ ìš”ê¸°ìš”ë¥¼ ì´ìš©í•œë‹¤"],
      "search_strategy": "category_specific"
    }
  ],
  "logic_structure": {"operator": "AND", "children": [{"operator": "LEAF", "condition_id": "cond_1"}, {"operator": "LEAF", "condition_id": "cond_2"}]},
  "search_strategy_recommendation": {"strategy": "balanced"},
  "limit": 30
}

### ì˜ˆì‹œ 2: ì˜ë¯¸ ì¡°ê±´ë§Œ ìˆëŠ” ê²½ìš°
**ì¿¼ë¦¬**: "ì—¬ë¦„ íœ´ê°€ ê³„íšì´ ìˆëŠ” ì‚¬ëŒ ì°¾ì•„ì¤˜"
**ë¶„ì„ ê²°ê³¼**:
{
  "demographic_filters": {},
  "semantic_conditions": [
    {
      "id": "cond_1",
      "original_keyword": "ì—¬ë¦„ íœ´ê°€ ê³„íš",
      "importance": 0.9,
      "expanded_queries": ["ì˜¬í•´ ì—¬ë¦„ íœ´ê°€ë¥¼ ë– ë‚  ì˜ˆì •ì´ë‹¤", "í•´ì™¸ ì—¬í–‰ì´ë‚˜ êµ­ë‚´ ì—¬í–‰ ê³„íšì´ ìˆë‹¤", "íœ´ê°€ì²  ì—¬í–‰ì§€ë¥¼ ì•Œì•„ë³´ê³  ìˆë‹¤"],
      "search_strategy": "category_specific"
    }
  ],
  "logic_structure": {"operator": "LEAF", "condition_id": "cond_1"},
  "search_strategy_recommendation": {"strategy": "semantic_first"},
  "limit": 50
}

---

## ğŸ“¤ ì¶œë ¥ í˜•ì‹ (JSON Only)
```json
{
  "demographic_filters": { ... },
  "semantic_conditions": [ ... ],
  "logic_structure": { ... },
  "exclude_conditions": [],
  "search_strategy_recommendation": { ... },
  "limit": <number>
}

*** ì‹¤ì œ ë¶„ì„ ëŒ€ìƒ *** 
ì‚¬ìš©ì ì¿¼ë¦¬: 
<query>
{{QUERY}}
</query> 
"""


@lru_cache(maxsize=256)
def parse_query_intelligent(query: str) -> Dict[str, Any]:
   """ ì¿¼ë¦¬ë¥¼ ì§€ëŠ¥ì ìœ¼ë¡œ íŒŒì‹±í•˜ì—¬ êµ¬ì¡°í™”ëœ ê²€ìƒ‰ ì¡°ê±´ ìƒì„± """ 
   if CLAUDE_CLIENT is None:
       raise RuntimeError("Claude í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
   
   logging.info(f"ğŸ”„ LLM Parser v2 í˜¸ì¶œ ì¤‘: {query}")

   # í”„ë¡¬í”„íŠ¸ ìƒì„± (schemaëŠ” ë‹¨ìˆœ ë¬¸ìì—´ ì¹˜í™˜, QUERYëŠ” ì‚¬ìš©ì ì…ë ¥ ì¹˜í™˜)
   prompt = SYSTEM_PROMPT_V2.replace("{{QUERY}}", query).replace("{schema}", DB_SCHEMA_INFO)

   try:
       messages = [
           SystemMessage(content=prompt),
           HumanMessage(content="Analyze the query and provide structured search conditions in JSON.")
       ]
       
       response = CLAUDE_CLIENT.invoke(messages)
       text_output = response.content.strip()
       logging.info(f"ğŸ¤– Claude LLM ì›ë³¸ ì‘ë‹µ:\n---\n{text_output}\n---")
       
       # JSON ì¶”ì¶œ (ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±°)
       json_match = re.search(r'```(?:json)?\s*({.*?})\s*```', text_output, re.DOTALL)
       if json_match:
           json_str = json_match.group(1)
       else:
           json_match = re.search(r'({.*})', text_output, re.DOTALL)
           if json_match:
               json_str = json_match.group(1)
           else:
               json_str = text_output
       
       parsed = json.loads(json_str)
       
       # ê¸°ë³¸ê°’ ì„¤ì • ë° ë°˜í™˜ êµ¬ì¡° ìƒì„±
       result = {
           'demographic_filters': parsed.get('demographic_filters', {}),
           'semantic_conditions': parsed.get('semantic_conditions', []),
           'logic_structure': parsed.get('logic_structure', {'operator': 'AND', 'children': []}),
           'exclude_conditions': parsed.get('exclude_conditions', []),
           'search_strategy_recommendation': parsed.get('search_strategy_recommendation', {
               'strategy': 'balanced',
               'use_collections': ['welcome_subjective_vectors', 'qpoll_vectors_v2']
           }),
           'limit': parsed.get('limit', 100),
           'query_intent': parsed.get('query_intent', {})
       }
       
       logging.debug(f"âœ… LLM Parser v2 ì™„ë£Œ")
       logging.info(f"  - Demographic filters: {result['demographic_filters']}")
       intent_keywords = [c.get('original_keyword', '') for c in result['semantic_conditions']]
       logging.info(f"  - Semantic conditions: {intent_keywords}")

       # ğŸ” ë””ë²„ê¹…: Semantic Conditions ìƒì„¸ ì •ë³´ ì¶œë ¥ (DEBUG ë ˆë²¨)
       if result['semantic_conditions']:
           logging.debug("="*60)
           logging.debug("ğŸ” [ë””ë²„ê¹…] Semantic Conditions ìƒì„¸ ì •ë³´:")
           for idx, cond in enumerate(result['semantic_conditions'], 1):
               logging.debug(f"  [{idx}] original_keyword: {cond.get('original_keyword')}")
               logging.debug(f"      importance: {cond.get('importance')}")
               logging.debug(f"      search_strategy: {cond.get('search_strategy')}")
               expanded = cond.get('expanded_queries', [])
               if expanded:
                   logging.debug(f"      expanded_queries:")
                   for exp_idx, exp_q in enumerate(expanded, 1):
                       logging.debug(f"        {exp_idx}. {exp_q}")
           logging.debug("="*60)
       
       return result
       
   except json.JSONDecodeError as je:
       logging.error(f"âŒ JSON íŒŒì‹± ì‹¤íŒ¨: {je.msg}. ì›ë³¸: {text_output}")
       raise RuntimeError(f"Claude ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨: {je.msg}")
   except Exception as e:
       logging.error(f"âŒ Claude í˜¸ì¶œ ì‹¤íŒ¨: {e}", exc_info=True)
       raise RuntimeError(f"Claude í˜¸ì¶œ ì‹¤íŒ¨: {e}")


def extract_limit_from_query(query: str) -> Optional[int]:
    """ì¿¼ë¦¬ì—ì„œ ì¸ì› ìˆ˜ ì¶”ì¶œ"""
    all_limit_matches = re.findall(r'(\d+)\s*ëª…', query)
    if all_limit_matches:
        try:
            return int(all_limit_matches[-1])
        except ValueError:
            pass
    return None