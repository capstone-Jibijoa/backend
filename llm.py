import json
import re
import os
import logging
from typing import Dict, List, Optional, Any
from functools import lru_cache
from langchain_anthropic import ChatAnthropic
from langchain_core.messages import SystemMessage, HumanMessage
from dotenv import load_dotenv
# from settings import settings

load_dotenv()

# 1. Claude í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
try:
    # API KeyëŠ” í™˜ê²½ë³€ìˆ˜(.env)ì—ì„œ ìë™ìœ¼ë¡œ ë¡œë“œë©ë‹ˆë‹¤.
    #CLAUDE_CLIENT = ChatAnthropic(model="claude-sonnet-4-5", temperature=0.1, api_key=settings.ANTHROPIC_API_KEY)
    CLAUDE_CLIENT = ChatAnthropic(model="claude-sonnet-4-5", temperature=0.1)
except Exception as e:
    CLAUDE_CLIENT = None
    logging.error(f"Anthropic í´ë¼ì´ì–¸íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")


# 2. DB ìŠ¤í‚¤ë§ˆ ì •ë³´
DB_SCHEMA_INFO = """
## PostgreSQL (ì¸êµ¬í†µê³„)
- gender, birth_year, region_major, marital_status, education_level
- job_title_raw (e.g. í•™ìƒ, ì£¼ë¶€, íšŒì‚¬ì›), job_duty_raw (e.g. ì „ë¬¸ì§, ì‚¬ë¬´ì§, ê¸°ìˆ ì§)
- income_personal_monthly: ["ì›” 100ë§Œì› ë¯¸ë§Œ", "ì›” 100~199ë§Œì›", "ì›” 200~299ë§Œì›", "ì›” 300~399ë§Œì›", "ì›” 400~499ë§Œì›", "ì›” 500~599ë§Œì›", "ì›” 600~699ë§Œì›", "ì›” 700ë§Œì› ì´ìƒ"]
- car_ownership, smoking_experience, drinking_experience
"""

# 3. ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ 
SYSTEM_PROMPT_V2 = """
You are a Search Query Analyzer. Parse the query into "Demographic Filters (SQL)" and "Semantic Conditions (Vector)".

## ğŸ“‹ DB Schema
{schema}

## ğŸ› ï¸ Extraction Rules

### 1. Demographic Filters (Strict SQL)
Extract ONLY explicit matches. **ALL VALUES MUST BE TRANSLATED TO KOREAN.**
Extract ONLY explicit matches for these fields:
- **Basic**: `age` (convert to range), `gender`, `region` (e.g., ì„œìš¸, ê²½ê¸°).
- **Social**: `marital_status`, `family_size`, `children_count`.
- **Status**: `job`, `education_level`, `income_personal`, `income_household`.
- **Asset**: `car_ownership` (Only 'have car' or 'no car').
**[IMPORTANT RULE for INCOME]**
- If the query mentions **"earning", "salary", "making money" (e.g., ëˆì„ ë§ì´ ë²„ëŠ”, ì—°ë´‰, ì›”ê¸‰)** combined with a **Job/Profession**, map it to **`income_personal_monthly`**.
- Map to `income_household_monthly` ONLY when "household", "family income", or "house" (e.g., ê°€êµ¬ ì†Œë“, ì§‘ì•ˆ í˜•í¸) is explicitly mentioned.
*Note: Do NOT infer missing data. Exclude smoking/drinking/appliances here.*

### 2. Semantic Conditions (Vector Search)
Extract all other subjective intents, hobbies, habits, and specific item ownerships (e.g., specific car model, phone type).
- **Negative Handling**: Mark "don't", "no", "hate" (e.g., "ì•ˆ í•˜ëŠ”", "ì—†ëŠ”") as **`is_negative: true`**.
- **Expansion**: Generate 3 positive synonyms in `expanded_queries` even for negative conditions.
- **Importance**: 0.9 (Core), 0.7 (Important), 0.5 (Optional).

## ğŸ’¡ Few-Shot Examples

**Query**: "ì„œìš¸ ê²½ê¸° ì‚¬ëŠ” 20ëŒ€ ë‚¨ì„± ì¤‘ OTT ì¦ê²¨ ë³´ê³  ì£¼ë§ì— ë°°ë‹¬ìŒì‹ ì‹œì¼œë¨¹ëŠ” ì‚¬ëŒ 30ëª…"
**Output**:
{
  "demographic_filters": { "region_major": ["ì„œìš¸", "ê²½ê¸°"], "age_range": [20, 29], "gender": ["ë‚¨ì„±"] },
  "semantic_conditions": [
    { "original_keyword": "OTTë¥¼ ì¦ê²¨ ë³´ê³ ", "is_negative": false, "importance": 0.9, "expanded_queries": ["ë„·í”Œë¦­ìŠ¤ë‚˜ ìœ íŠœë¸Œë¥¼ ìì£¼ ë³¸ë‹¤", "ë™ì˜ìƒ ìŠ¤íŠ¸ë¦¬ë° êµ¬ë… ì¤‘ì´ë‹¤", "ì£¼ë§ì— ë“œë¼ë§ˆ ì •ì£¼í–‰í•œë‹¤"] },
    { "original_keyword": "ì£¼ë§ì— ë°°ë‹¬ìŒì‹ ì‹œì¼œë¨¹ëŠ”", "importance": 0.7, "expanded_queries": ["ë°°ë‹¬ ì•±ì„ ìì£¼ ì“´ë‹¤", "ìš”ê¸°ìš”ë‚˜ ë°°ë¯¼ì„ ì´ìš©í•œë‹¤", "ë°°ë‹¬ ìŒì‹ì„ ì„ í˜¸í•œë‹¤"] }
  ],
  "limit": 30
}

**Query**: "ê²½ê¸°ë„ ì‚¬ëŠ” 30ëŒ€ ì¤‘ ê³ ì–‘ì´ë¥¼ ì•ˆ í‚¤ìš°ëŠ” ì‚¬ëŒ"
**Output**:
{
  "demographic_filters": { "region_major": ["ê²½ê¸°"], "age_range": [30, 39] },
  "semantic_conditions": [
    { 
      "original_keyword": "ê³ ì–‘ì´ë¥¼ ì•ˆ í‚¤ìš°ëŠ”", 
      "is_negative": true, 
      "importance": 0.9, 
      "expanded_queries": ["ê³ ì–‘ì´ë¥¼ í‚¤ìš´ë‹¤", "ë°˜ë ¤ë¬˜ê°€ ìˆë‹¤", "ê³ ì–‘ì´ ì§‘ì‚¬ë‹¤"],
      "note": "Filter out people similar to expanded_queries"
    }
  ],
  "limit": 100
}

## ğŸ“¤ Output Format (JSON Only)
Return ONLY the raw JSON.
{
  "demographic_filters": { ... },
  "semantic_conditions": [ ... ],
  "limit": <number>
}

*** Target Query ***
<query>
{{QUERY}}
</query> 
"""

@lru_cache(maxsize=256)
def parse_query_intelligent(query: str) -> Dict[str, Any]:
   """ ì¿¼ë¦¬ë¥¼ ì§€ëŠ¥ì ìœ¼ë¡œ íŒŒì‹±í•˜ì—¬ êµ¬ì¡°í™”ëœ ê²€ìƒ‰ ì¡°ê±´ ìƒì„± """ 
   if CLAUDE_CLIENT is None:
       raise RuntimeError("Claude í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
   
   logging.info(f"ğŸ”„ LLM Parser v2 í˜¸ì¶œ ì¤‘: {query}")

   # í”„ë¡¬í”„íŠ¸ ìƒì„± (schemaëŠ” ë‹¨ìˆœ ë¬¸ìì—´ ì¹˜í™˜, QUERYëŠ” ì‚¬ìš©ì ì…ë ¥ ì¹˜í™˜)
   prompt = SYSTEM_PROMPT_V2.replace("{{QUERY}}", query).replace("{schema}", DB_SCHEMA_INFO)

   try:
       messages = [
           SystemMessage(content=prompt),
           HumanMessage(content="Analyze the query and provide structured search conditions in JSON.")
       ]
       
       response = CLAUDE_CLIENT.invoke(messages)
       text_output = response.content.strip()
       logging.info(f"ğŸ¤– Claude LLM ì›ë³¸ ì‘ë‹µ:\n---\n{text_output}\n---")
       
       # JSON ì¶”ì¶œ (ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±°)
       json_match = re.search(r'```(?:json)?\s*({.*?})\s*```', text_output, re.DOTALL)
       if json_match:
           json_str = json_match.group(1)
       else:
           json_match = re.search(r'({.*})', text_output, re.DOTALL)
           if json_match:
               json_str = json_match.group(1)
           else:
               json_str = text_output
       
       parsed = json.loads(json_str)
       
       # ê¸°ë³¸ê°’ ì„¤ì • ë° ë°˜í™˜ êµ¬ì¡° ìƒì„±
       result = {
           'demographic_filters': parsed.get('demographic_filters', {}),
           'semantic_conditions': parsed.get('semantic_conditions', []),
           'logic_structure': parsed.get('logic_structure', {'operator': 'AND', 'children': []}),
           'exclude_conditions': parsed.get('exclude_conditions', []),
           'search_strategy_recommendation': parsed.get('search_strategy_recommendation', {
               'strategy': 'balanced',
               'use_collections': ['welcome_subjective_vectors', 'qpoll_vectors_v2']
           }),
           'limit': parsed.get('limit', 100),
           'query_intent': parsed.get('query_intent', {})
       }
       
       logging.debug(f"âœ… LLM Parser v2 ì™„ë£Œ")
       logging.info(f"  - Demographic filters: {result['demographic_filters']}")
       intent_keywords = [c.get('original_keyword', '') for c in result['semantic_conditions']]
       logging.info(f"  - Semantic conditions: {intent_keywords}")

       # ğŸ” ë””ë²„ê¹…: Semantic Conditions ìƒì„¸ ì •ë³´ ì¶œë ¥ (DEBUG ë ˆë²¨)
       if result['semantic_conditions']:
           logging.debug("="*60)
           logging.debug("ğŸ” [ë””ë²„ê¹…] Semantic Conditions ìƒì„¸ ì •ë³´:")
           for idx, cond in enumerate(result['semantic_conditions'], 1):
               logging.debug(f"  [{idx}] original_keyword: {cond.get('original_keyword')}")
               logging.debug(f"      importance: {cond.get('importance')}")
               logging.debug(f"      search_strategy: {cond.get('search_strategy')}")
               expanded = cond.get('expanded_queries', [])
               if expanded:
                   logging.debug(f"      expanded_queries:")
                   for exp_idx, exp_q in enumerate(expanded, 1):
                       logging.debug(f"        {exp_idx}. {exp_q}")
           logging.debug("="*60)
       
       return result
       
   except json.JSONDecodeError as je:
       logging.error(f"âŒ JSON íŒŒì‹± ì‹¤íŒ¨: {je.msg}. ì›ë³¸: {text_output}")
       raise RuntimeError(f"Claude ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨: {je.msg}")
   except Exception as e:
       logging.error(f"âŒ Claude í˜¸ì¶œ ì‹¤íŒ¨: {e}", exc_info=True)
       raise RuntimeError(f"Claude í˜¸ì¶œ ì‹¤íŒ¨: {e}")


def extract_limit_from_query(query: str) -> Optional[int]:
    """ì¿¼ë¦¬ì—ì„œ ì¸ì› ìˆ˜ ì¶”ì¶œ"""
    all_limit_matches = re.findall(r'(\d+)\s*ëª…', query)
    if all_limit_matches:
        try:
            return int(all_limit_matches[-1])
        except ValueError:
            pass
    return None

def extract_relevant_columns_via_llm(question: str, all_columns_info: str) -> List[str]:
    """
    ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ í†µê³„ ë¶„ì„ì— í•„ìš”í•œ DB ì»¬ëŸ¼ëª…ë“¤ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
    """
    if not CLAUDE_CLIENT: 
        logging.error("Claude Client is not initialized.")
        return []

    system_prompt = f"""
    You are a Data Analyst. Select the most relevant database columns from the [Column List] to answer the user's [Question].
    
    [Column List]
    {all_columns_info}
    
    [Rules]
    1. Return ONLY a JSON object with a key "columns" containing a list of strings.
    2. If no column is relevant, return "columns": [].
    3. Select strictly from the provided list.
    """
    
    user_prompt = f"Question: {question}"

    try:
        response = CLAUDE_CLIENT.invoke([
            SystemMessage(content=system_prompt),
            HumanMessage(content=user_prompt)
        ])
        
        # JSON íŒŒì‹± 
        content = response.content.strip()
        if "```" in content:
            content = content.split("```")[1].replace("json", "").strip()
            
        data = json.loads(content)
        return data.get("columns", [])
    except Exception as e:
        logging.error(f"ì»¬ëŸ¼ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        return []

def generate_stats_summary(question: str, stats_context: str) -> str:
    """
    ê³„ì‚°ëœ í†µê³„ í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    if not CLAUDE_CLIENT: return "AI ëª¨ë¸ì´ ì—°ê²°ë˜ì§€ ì•Šì•„ ìš”ì•½ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    system_prompt = """
    ë‹¹ì‹ ì€ ë°ì´í„° ì¸ì‚¬ì´íŠ¸ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
    ì œê³µëœ [ë°ì´í„° í†µê³„]ë¥¼ ê·¼ê±°ë¡œ [ì‚¬ìš©ì ì§ˆë¬¸]ì— ëŒ€í•œ í•µì‹¬ ìš”ì•½ì„ ì‘ì„±í•˜ì„¸ìš”.
    
    [ì‘ì„± ì›ì¹™]
    1. ë§‰ì—°í•œ í‘œí˜„ ëŒ€ì‹  **ì œê³µëœ ìˆ˜ì¹˜(ëª…, %)**ë¥¼ ë°˜ë“œì‹œ ì¸ìš©í•˜ì—¬ ê·¼ê±°ë¥¼ ì œì‹œí•˜ì„¸ìš”. 
    2. ê°€ì¥ ë‘ë“œëŸ¬ì§„ íŠ¹ì§•(ìµœëŒ“ê°’, ê³¼ë°˜ìˆ˜ ë“±)ì„ ê°•ì¡°í•˜ì„¸ìš”.
    3. ì§ˆë¬¸ê³¼ ê´€ë ¨ ì—†ëŠ” í†µê³„ëŠ” ì–¸ê¸‰í•˜ì§€ ë§ˆì„¸ìš”.
    4. "~í•˜ëŠ” ê²ƒì´ íŠ¹ì§•ì…ë‹ˆë‹¤"ì™€ ê°™ì€ ë¶„ì„ì ì¸ ì–´ì¡°ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
    5. í•œêµ­ì–´ë¡œ ê°„ê²°í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš” (3ë¬¸ì¥ ë‚´ì™¸).
    """
    
    user_prompt = f"""
    [ì‚¬ìš©ì ì§ˆë¬¸]
    {question}
    
    [ë°ì´í„° í†µê³„ (Python ê³„ì‚° ê²°ê³¼)]
    {stats_context}
    """
    
    try:
        response = CLAUDE_CLIENT.invoke([
            SystemMessage(content=system_prompt),
            HumanMessage(content=user_prompt)
        ])
        return response.content.strip()
    except Exception as e:
        logging.error(f"í†µê³„ ìš”ì•½ ìƒì„± ì‹¤íŒ¨: {e}")
        return "ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

def generate_demographic_summary(query: str, stats_text: str, total_count: int) -> str:
    """
    í†µê³„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ 'ì¸ì‚¬ì´íŠ¸'ê°€ ë‹´ê¸´ ìš”ì•½ ë¬¸ì¥ì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    if not CLAUDE_CLIENT: return ""

    system_prompt = """
    ë‹¹ì‹ ì€ ë°ì´í„° ì¸ì‚¬ì´íŠ¸ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
    ì œê³µëœ [ë°ì´í„° í†µê³„]ë¥¼ ê·¼ê±°ë¡œ [ì‚¬ìš©ì ì§ˆë¬¸]ì— ëŒ€í•œ í•µì‹¬ ìš”ì•½ì„ ì‘ì„±í•˜ì„¸ìš”.
    
    [ì‘ì„± ì›ì¹™]
    1. ë§‰ì—°í•œ í‘œí˜„ ëŒ€ì‹  **ì œê³µëœ ìˆ˜ì¹˜(ëª…, %)**ë¥¼ ë°˜ë“œì‹œ ì¸ìš©í•˜ì—¬ ê·¼ê±°ë¥¼ ì œì‹œí•˜ì„¸ìš”. 
    2. ê°€ì¥ ë‘ë“œëŸ¬ì§„ íŠ¹ì§•(ìµœëŒ“ê°’, ê³¼ë°˜ìˆ˜ ë“±)ì„ ê°•ì¡°í•˜ì„¸ìš”.
    3. ì§ˆë¬¸ê³¼ ê´€ë ¨ ì—†ëŠ” í†µê³„ëŠ” ì–¸ê¸‰í•˜ì§€ ë§ˆì„¸ìš”.
    4. "~í•˜ëŠ” ê²ƒì´ íŠ¹ì§•ì…ë‹ˆë‹¤"ì™€ ê°™ì€ ë¶„ì„ì ì¸ ì–´ì¡°ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
    6. ë§ˆì¼€íŒ…ì„ ìœ„í•œ ì¸ì‚¬ì´íŠ¸ë¥¼ ì¶”ê°€ë¡œ ì œì•ˆí•˜ì„¸ìš”.
    5. í•œêµ­ì–´ë¡œ ê°„ê²°í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš” (5ë¬¸ì¥ ë‚´ì™¸).
    """
    
    user_prompt = f"""
    [ì‚¬ìš©ì ì§ˆë¬¸]
    {query}

    [ë¶„ì„ ëŒ€ìƒ]
    ì´ {total_count}ëª…ì˜ íŒ¨ë„

    [í†µê³„ ë°ì´í„°]
    {stats_text}

    ìœ„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•µì‹¬ ë¶„ì„ ìš”ì•½ ë§ˆì¼€íŒ… ì¸ì‚¬ì´íŠ¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.
    """

    try:
        response = CLAUDE_CLIENT.invoke([
            SystemMessage(content=system_prompt),
            HumanMessage(content=user_prompt)
        ])
        return response.content.strip()
    except Exception as e:
        logging.error(f"ìš”ì•½ ìƒì„± ì‹¤íŒ¨: {e}")
        return "ë°ì´í„° ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."