import os
import json
import time
import asyncio
loop = asyncio.get_running_loop()
import logging
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from typing import Optional, Tuple, Dict, List
from fastapi.middleware.cors import CORSMiddleware

from llm import classify_query_keywords
from search import initialize_embeddings
from search import hybrid_search as hybrid_search
from mapping_rules import QPOLL_FIELD_TO_TEXT, VECTOR_CATEGORY_TO_FIELD
from insights import (
    analyze_search_results_optimized as analyze_search_results,
    get_field_mapping
)
from db import (
    log_search_query,
    get_db_connection_context,
    init_db,
    cleanup_db,
    get_qdrant_client
)
from qdrant_client.http.models import Filter, FieldCondition, MatchValue, MatchAny
from utils import FIELD_NAME_MAP

# ë£¨íŠ¸ ë¡œê±° ì„¤ì •
logging.basicConfig(level=logging.INFO,
                    format='%(asctime)s - %(levelname)s - %(message)s',
                    datefmt='%Y-%m-%d %H:%M:%S')

# Uvicorn, FastAPI ë“± ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œê±° ë ˆë²¨ ì„¤ì • (í•„ìš”ì‹œ)
logging.getLogger("uvicorn").setLevel(logging.WARNING)
logging.getLogger("fastapi").setLevel(logging.WARNING)
# --- ë¡œê¹… ì„¤ì • ---

app = FastAPI(title="Multi-Table Hybrid Search API v3 (Refactored)")

origins = [
    "http://localhost:5173",
    "http://localhost:3000",
]

app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

def preload_models():
    """ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘ ì‹œ ëª¨ë“  AI ëª¨ë¸ì„ ë¯¸ë¦¬ ë¡œë“œí•©ë‹ˆë‹¤."""
    logging.info("="*70)
    logging.info("ğŸ”„ ëª¨ë“  AI ëª¨ë¸ì„ ë¯¸ë¦¬ ë¡œë“œí•©ë‹ˆë‹¤...")
    initialize_embeddings()
    classify_query_keywords("ëª¨ë¸ ë¡œë”© í…ŒìŠ¤íŠ¸")
    try:
        classify_query_keywords("ëª¨ë¸ ë¡œë”© í…ŒìŠ¤íŠ¸")
        logging.info("âœ… Claude (LLM) ëª¨ë¸ ì—°ê²° í™•ì¸ ì™„ë£Œ.")
    except Exception as e:
        logging.warning(f"âš ï¸  Claude (LLM) ëª¨ë¸ ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        logging.warning("   LLM ê¸°ëŠ¥ì´ ì‘ë™í•˜ì§€ ì•Šì„ ìˆ˜ ìˆì§€ë§Œ, ì„œë²„ëŠ” ê³„ì† ì‹œì‘í•©ë‹ˆë‹¤.")
    logging.info("âœ… ëª¨ë“  AI ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
    logging.info("="*70)

@app.on_event("startup")
async def startup_event():
    logging.info("ğŸš€ FastAPI ì‹œì‘...")
    init_db()
    preload_models()

@app.on_event("shutdown")
async def shutdown_event():
    logging.info("ğŸ§¹ FastAPI ì¢…ë£Œ... Connection Pool ì •ë¦¬")
    cleanup_db()


class SearchQuery(BaseModel):
    query: str
    search_mode: str = "all"

class SearchResponse(BaseModel):
    query: str
    classification: dict
    results: dict
    final_panel_ids: list[str]
    summary: dict

class AnalysisRequest(BaseModel):
    query: str
    search_mode: str = "weighted"

class AnalysisResponse(BaseModel):
    query: str
    total_count: int
    main_summary: str
    charts: list[dict]

def _prepare_display_fields(classification: Dict) -> List[Dict]:
    """
    [v2] classification ê²°ê³¼ë¡œë¶€í„° í…Œì´ë¸” í—¤ë”(display_fields)ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    - `objective_keywords`ì™€ `mandatory_keywords`ë¥¼ ìš°ì„ ì ìœ¼ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.
    - `get_field_mapping`ì„ í˜¸ì¶œí•˜ì—¬ ê° í‚¤ì›Œë“œì— ë§ëŠ” í•„ë“œì™€ ì„¤ëª…ì„ ì°¾ìŠµë‹ˆë‹¤.
    """
    
    # [ìˆ˜ì •] must_have, preferenceë¥¼ ìš°ì„ í•˜ê³  objectiveëŠ” í›„ìˆœìœ„ë¡œ ë³€ê²½
    objective_kws = classification.get('objective_keywords', [])
    must_have_kws = classification.get('must_have_keywords', [])
    preference_kws = classification.get('preference_keywords', [])
    
    # í•µì‹¬ ì£¼ì œ(must-have, preference)ë¥¼ ë¨¼ì €, í•„í„°ë§ ì¡°ê±´(objective)ì€ ë‚˜ì¤‘ì—
    header_keywords = must_have_kws + preference_kws + objective_kws

    if not header_keywords:
        logging.warning("âš ï¸ _prepare_display_fields: ë¶„ì„í•  í‚¤ì›Œë“œê°€ ì—†ìŠµë‹ˆë‹¤. ë¹ˆ í—¤ë” ë°˜í™˜.")
        return []
        
    # [ì‹ ê·œ] objective_keywords ì¤‘ ë‹¨ì¼ ê°’ë§Œ ê°–ëŠ” í•„ë“œë¥¼ ì‹ë³„í•˜ì—¬ í—¤ë”ì—ì„œ ì œì™¸
    objective_field_counts = {}
    for kw in objective_kws:
        mapping = get_field_mapping(kw)
        field = mapping.get('field')
        if field and field != 'unknown':
            if field not in objective_field_counts:
                objective_field_counts[field] = 0
            objective_field_counts[field] += 1
    
    # ê°’ì´ í•˜ë‚˜ë§Œ ìˆëŠ” í•„ë“œ(ë»”í•œ ê²°ê³¼)ëŠ” ì œì™¸ ëŒ€ìƒ
    single_value_fields_to_exclude = {field for field, count in objective_field_counts.items() if count == 1}
    logging.info(f"âœ¨ [Display Fields] ë‹¨ì¼ ê°’ í•„ë“œ ì œì™¸ ëŒ€ìƒ: {single_value_fields_to_exclude}")

    unique_fields = {}
    priority_counter = 0

    for i, keyword in enumerate(header_keywords):
        # ì´ë¯¸ 5ê°œ í—¤ë”ê°€ ì±„ì›Œì¡Œìœ¼ë©´ ì¤‘ë‹¨
        if len(unique_fields) >= 5:
            break

        mapping = get_field_mapping(keyword)
        field = mapping.get('field')

        # [ì‹ ê·œ] ì œì™¸ ëŒ€ìƒ í•„ë“œì¸ ê²½ìš° ê±´ë„ˆë›°ê¸° (ë‹¨, objective í‚¤ì›Œë“œì— ëŒ€í•´ì„œë§Œ ì ìš©)
        if keyword in objective_kws and field in single_value_fields_to_exclude:
            logging.info(f"   â†’ '{keyword}'(í•„ë“œ: {field})ëŠ” ë‹¨ì¼ ì¡°ê±´ì´ë¯€ë¡œ í—¤ë”ì—ì„œ ì œì™¸")
            continue

        if field and field != 'unknown' and field not in unique_fields:
            label = mapping.get('description')
            # QPoll í•„ë“œì˜ ê²½ìš°, descriptionì´ ì§ˆë¬¸ ì „ì²´ì´ë¯€ë¡œ FIELD_NAME_MAPì—ì„œ ì§§ì€ ì´ë¦„ìœ¼ë¡œ ëŒ€ì²´
            if mapping.get('type') == 'qpoll':
                label = FIELD_NAME_MAP.get(field, field)

            unique_fields[field] = {
                'field': field,
                'label': label,
                'priority': i # ì›ë˜ ìˆœì„œë¥¼ ìš°ì„ ìˆœìœ„ë¡œ ì‚¬ìš©
            }
            priority_counter += 1

    # [ì‹ ê·œ ì¶”ê°€] ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ë°œê²¬ëœ Category ê¸°ë°˜ìœ¼ë¡œ í•„ë“œ ë³´ê°•
    found_categories = classification.get('found_categories', [])
    if found_categories:
        logging.info(f"âœ¨ [Display Fields] ë²¡í„° ì¹´í…Œê³ ë¦¬ ê¸°ë°˜ í•„ë“œ ë³´ê°• ì‹œì‘: {found_categories}")
        for category in found_categories:
            if len(unique_fields) >= 5:
                break
            
            fields_to_add = VECTOR_CATEGORY_TO_FIELD.get(category, [])
            for field in fields_to_add:
                if len(unique_fields) >= 5:
                    break
                if field not in unique_fields:
                    label = FIELD_NAME_MAP.get(field, field)
                    logging.info(f"   â†’ ì¹´í…Œê³ ë¦¬ '{category}'ë¥¼ í†µí•´ '{label}' í•„ë“œ ì¶”ê°€")
                    unique_fields[field] = {
                        'field': field, 'label': label, 'priority': 800 + len(unique_fields)
                    }

    # [ìˆ˜ì •] ì»¬ëŸ¼ ë³´ê°• ë¡œì§ì„ ì´ í•¨ìˆ˜ë¡œ í†µí•©
    if len(unique_fields) < 4:
        FIELDS_TO_AUGMENT = ['family_size', 'job_duty_raw', 'marital_status']
        
        for field_key in FIELDS_TO_AUGMENT:
            if len(unique_fields) >= 4:
                break
            
            if field_key not in unique_fields:
                korean_name = FIELD_NAME_MAP.get(field_key, field_key)
                logging.info(f"âœ¨ [Display Fields] í…Œì´ë¸” ì»¬ëŸ¼ ë³´ê°•: '{korean_name}' ì¶”ê°€")
                unique_fields[field_key] = {
                    'field': field_key,
                    'label': korean_name,
                    'priority': 900 + len(unique_fields) # ë³´ê°• í•„ë“œëŠ” ë‚®ì€ ìš°ì„ ìˆœìœ„
                }

    final_result = sorted(list(unique_fields.values()), key=lambda x: x['priority'])
    logging.info(f"   [DEBUG_PREP] ìµœì¢… ë§¤í•‘ í•„ë“œ: {final_result}") 
    return final_result
 
 
def _build_pro_mode_response( 
    query_text: str,
    classification: Dict,
    search_results: Dict,
    display_fields: List[Dict],
    effective_search_mode: str
) -> Tuple[Dict, List[str]]:
    """
    Pro ëª¨ë“œì˜ ë³µì¡í•œ ì‘ë‹µ ë³¸ë¬¸ì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    # v2 ê²€ìƒ‰ ê²°ê³¼ êµ¬ì¡°ì— ë§ê²Œ source_countsë¥¼ stage_detailsì—ì„œ ê°€ì ¸ì˜¤ë„ë¡ ìˆ˜ì •
    source_counts = { 
        "stage1_objective": search_results.get("stage_details", {}).get("stage1_objective", 0),
        "stage2_must_have": search_results.get("stage_details", {}).get("stage2_must_have", 0),
        "stage3_preference": search_results.get("stage_details", {}).get("stage3_preference", 0),
        "stage4_negative": search_results.get("stage_details", {}).get("stage4_negative", 0),
    }
    
    summary = {
        "search_mode": effective_search_mode,
        # "search_strategy": { # [ìˆ˜ì •] classification í‚¤ êµ¬ì¡° ë³€ê²½ ëŒ€ì‘
        #     "welcome_objective": bool(classification.get('objective_keywords')),
        #     "welcome_subjective": bool(classification.get('vector_keywords')),
        #     "qpoll": bool(classification.get('qpoll_keywords'))
        # },
        "ranked_keywords": classification.get('ranked_keywords_raw', [])
    }

    response = {
        "query": query_text,
        "classification": classification,
        "display_fields": display_fields,
        "source_counts": source_counts,
        "summary": summary,
    }

    # v2 ê²€ìƒ‰ ê²°ê³¼ êµ¬ì¡°ì— ë§ê²Œ ì‘ë‹µ í¬ë§·íŒ…
    final_panel_ids = search_results.get('final_panel_ids', [])
    total_count = search_results.get('total_count', 0)
    
    # Pro ëª¨ë“œëŠ” ìµœëŒ€ 100ê°œì˜ IDë§Œ ë°˜í™˜
    panel_id_list = final_panel_ids[:100]
    response["final_panel_ids"] = panel_id_list

    # 'results' í•„ë“œ êµ¬ì¡° ë‹¨ìˆœí™”
    if effective_search_mode:
        response["results"] = {
            effective_search_mode: {
                "count": total_count,
                "panel_ids": panel_id_list,
            }
        }

    return response, panel_id_list

async def _perform_common_search(query_text: str, search_mode: str, mode: str) -> Tuple[Dict, List[str], Dict]:
    """
    /searchì™€ /search-and-analyzeê°€ ê³µìœ í•˜ëŠ” í•µì‹¬ ë¡œì§
    (LLM ë¶„ë¥˜, ë³‘ë ¬ ê²€ìƒ‰, ë¡œê·¸ ê¸°ë¡, ê²°ê³¼ í¬ë§·íŒ…)
    """
    logging.info(f"ğŸ” ê³µí†µ ê²€ìƒ‰ ì‹œì‘: {query_text} (ëª¨ë“œ: {search_mode}, ì‹¤í–‰: {mode})")
    
    # 1. LLM í‚¤ì›Œë“œ ë¶„ë¥˜
    classification = classify_query_keywords(query_text)
    logging.info(f"ğŸ¤– LLM ë¶„ë¥˜ ê²°ê³¼: {classification}")
    user_limit = classification.get('limit')
    effective_search_mode = "quota" if user_limit and user_limit > 0 else search_mode
    logging.info(f"ğŸ’¡ API: ê°ì§€ëœ Limit ê°’: {user_limit}")
    
    search_results = hybrid_search(
        query=query_text,
        limit=user_limit
    )
    
    # 3. ê²€ìƒ‰ ë¡œê·¸ ê¸°ë¡
    panel_id_list = search_results.get('final_panel_ids', []) # [ìˆ˜ì •] hybrid_search ê²°ê³¼ì—ì„œ final_panel_ids ì¶”ì¶œ
    total_count = len(panel_id_list)
    log_search_query(query_text, total_count)
    
    # 4. ì‘ë‹µ êµ¬ì„±
    # [ìˆ˜ì •] classification ê°ì²´ì— ranked_keywords_raw ì¶”ê°€
    classification['ranked_keywords_raw'] = classification.get('objective_keywords', []) + classification.get('mandatory_keywords', [])
    display_fields = _prepare_display_fields(classification)
    
    if mode == "lite":
        lite_response = {
            "query": query_text,
            "classification": classification,
            "total_count": total_count,
            "final_panel_ids": panel_id_list[:500], # í…Œì´ë¸” ì¡°íšŒë¥¼ ìœ„í•´ ìµœëŒ€ 500ê°œ
            "effective_search_mode": effective_search_mode,
            "display_fields": display_fields
        }

        logging.info("âœ… ê³µí†µ ê²€ìƒ‰ ì™„ë£Œ (Lite ëª¨ë“œ ê°„ì†Œí™”)")
        return lite_response, panel_id_list, classification

    response, panel_id_list = _build_pro_mode_response(
        query_text,
        classification,
        search_results,
        display_fields,
        effective_search_mode,
    )
    
    logging.info("âœ… ê³µí†µ ê²€ìƒ‰ ì™„ë£Œ (Pro ëª¨ë“œ ì „ì²´ ë°ì´í„°)")
    return response, panel_id_list, classification # [ìˆ˜ì •] ì›ë³¸ classification ë°˜í™˜


async def _get_ordered_welcome_data(
    ids_to_fetch: List[str], 
    fields_to_fetch: List[str] = None
) -> List[dict]:
    """
    DBì—ì„œ íŒ¨ë„ ë°ì´í„°ë¥¼ ì¡°íšŒí•˜ë˜, ì…ë ¥ëœ id ë¦¬ìŠ¤íŠ¸ ìˆœì„œë¥¼ ë³´ì¥í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤.
    - fields_to_fetchê°€ Noneì´ë©´ structured_data ì „ì²´ë¥¼,
    - fields_to_fetchê°€ ë¦¬ìŠ¤íŠ¸ë©´ í•´ë‹¹ í•„ë“œë§Œ ì„ íƒì ìœ¼ë¡œ ì¡°íšŒí•©ë‹ˆë‹¤.
    """
    if not ids_to_fetch:
        return []

    table_data = []
    try:
        with get_db_connection_context() as conn:
            if not conn:
                raise Exception("DB ì—°ê²° ì‹¤íŒ¨")

            cur = conn.cursor()

            # [ìˆ˜ì •] Lite/Pro ëª¨ë“œ êµ¬ë¶„ ì—†ì´ structured_data ì „ì²´ë¥¼ ì¡°íšŒí•˜ì—¬ ì¼ê´€ì„± í™•ë³´
            sql_query = "SELECT panel_id, structured_data FROM welcome_meta2 WHERE panel_id = ANY(%s::text[])"
            cur.execute(sql_query, (ids_to_fetch,))
            results = cur.fetchall()

            # ìˆœì„œ ì¬ì •ë ¬ì„ ìœ„í•œ ë§µ ìƒì„±
            fetched_data_map = {row[0]: row for row in results}

            # ì…ë ¥ëœ ID ìˆœì„œëŒ€ë¡œ ê²°ê³¼ ì¬êµ¬ì„±
            for pid in ids_to_fetch:
                if pid in fetched_data_map:
                    row_data = fetched_data_map[pid]
                    panel_id_val, structured_data_val = row_data

                    # ìµœì¢…ì ìœ¼ë¡œ í…Œì´ë¸”ì— í‘œì‹œë  ë°ì´í„° ê°ì²´
                    display_data = {'panel_id': panel_id_val}

                    # fields_to_fetchê°€ ì œê³µë˜ë©´ (Lite ëª¨ë“œ), í•´ë‹¹ í•„ë“œë§Œ ì¶”ì¶œ
                    if fields_to_fetch:
                        if isinstance(structured_data_val, dict):
                            for field in fields_to_fetch:
                                if field != 'panel_id':
                                    display_data[field] = structured_data_val.get(field)
                    # fields_to_fetchê°€ Noneì´ë©´ (Pro ëª¨ë“œ), structured_data ì „ì²´ë¥¼ ë³‘í•©
                    else:
                        if isinstance(structured_data_val, dict):
                            display_data.update(structured_data_val)

                    table_data.append(display_data)

            cur.close()

    except Exception as db_e:
        logging.error(f"Table Data ì¡°íšŒ ì‹¤íŒ¨: {db_e}", exc_info=True)
    
    return table_data

async def _get_qpoll_responses_for_table(
    ids_to_fetch: List[str], 
    qpoll_fields: List[str]
) -> Dict[str, Dict[str, str]]:
    """
    ì£¼ì–´ì§„ panel_id ëª©ë¡ê³¼ Q-Poll í•„ë“œ ëª©ë¡ì— ëŒ€í•´ Qdrantì—ì„œ ì‘ë‹µì„ ì¡°íšŒí•©ë‹ˆë‹¤.
    (í…Œì´ë¸” ë°ì´í„° ë³‘í•©ìš©)
    ë°˜í™˜ í˜•íƒœ: {panel_id: {qpoll_field: sentence}}
    """
    if not ids_to_fetch or not qpoll_fields:
        return {}
    
    questions_to_fetch = [QPOLL_FIELD_TO_TEXT[f] for f in qpoll_fields if f in QPOLL_FIELD_TO_TEXT]
    
    if not questions_to_fetch:
        return {}

    loop = asyncio.get_running_loop()
    
    def qdrant_call():
        qpoll_client = get_qdrant_client()
        if not qpoll_client: return {}
        
        COLLECTION_NAME = "qpoll_vectors_v2" # í™˜ê²½ë³€ìˆ˜ ì‚¬ìš© ê¶Œì¥: os.getenv("QDRANT_COLLECTION_NAME")
        
        # 1. í•„í„° êµ¬ì„±: ì£¼ì–´ì§„ panel_id ì¤‘ í•˜ë‚˜ì´ê³ , ì§ˆë¬¸ í…ìŠ¤íŠ¸ ì¤‘ í•˜ë‚˜ì¸ ê²½ìš°
        query_filter = Filter(
            must=[
                FieldCondition(key="panel_id", match=MatchAny(any=ids_to_fetch)),
                FieldCondition(key="question", match=MatchAny(any=questions_to_fetch))
            ]
        )
        
        # 2. Qdrant ìŠ¤í¬ë¡¤ (ì‘ë‹µ ìˆ˜ ì œí•œ)
        qpoll_results, _ = qpoll_client.scroll(
            collection_name=COLLECTION_NAME,
            scroll_filter=query_filter,
            limit=len(ids_to_fetch) * len(questions_to_fetch), # ì¶©ë¶„í•œ í¬ê¸°ë¡œ ì„¤ì •
            with_payload=True, with_vectors=False
        )

        result_map = {pid: {} for pid in ids_to_fetch}
        
        # 3. ê²°ê³¼ íŒŒì‹± ë° ë³‘í•©
        text_to_field_map = {v: k for k, v in QPOLL_FIELD_TO_TEXT.items()}
        
        for point in qpoll_results:
            pid = point.payload.get("panel_id")
            question = point.payload.get("question")
            sentence = point.payload.get("sentence")

            if pid and question and sentence:
                field_key = text_to_field_map.get(question)
                if field_key:
                    result_map[pid][field_key] = sentence
                    
        return result_map

    return await loop.run_in_executor(None, qdrant_call)

@app.post("/api/search")
async def search_panels(search_query: SearchQuery):
    """
    ğŸš€ Lite ëª¨ë“œ: ë¹ ë¥¸ ê²€ìƒ‰ (ì°¨íŠ¸ ë¶„ì„ ì—†ì´ í…Œì´ë¸” ë°ì´í„°ë§Œ ë°˜í™˜)
    """
    logging.info(f"ğŸš€ [Lite ëª¨ë“œ] ë¹ ë¥¸ ê²€ìƒ‰ ì‹œì‘: {search_query.query}")
    
    valid_modes = ["all", "weighted", "union", "intersection"]
    if search_query.search_mode not in valid_modes:
        raise HTTPException(
            status_code=400, 
            detail=f"Invalid search_mode. Must be one of: {valid_modes}"
        )
    
    try:
        start_time = time.time()
        
        # 1. ê³µí†µ ê²€ìƒ‰ í•¨ìˆ˜ í˜¸ì¶œ (mode="lite")
        lite_response, _, _ = await _perform_common_search(
            search_query.query, 
            search_query.search_mode,
            mode="lite"
        )
        
        search_time = time.time() - start_time
        logging.info(f"â±ï¸  [Lite ëª¨ë“œ] ê²€ìƒ‰ ì™„ë£Œ: {search_time:.2f}ì´ˆ")
        
        # 2. í…Œì´ë¸” ë°ì´í„° ì¡°íšŒ
        ids_to_fetch = lite_response.get('final_panel_ids', [])
        display_fields = lite_response.get('display_fields', [])
        logging.info(f"lite_response: {lite_response}")
        logging.info(f"display_fields: {display_fields}")
        
        qpoll_fields = [item['field'] for item in display_fields if item['field'] in QPOLL_FIELD_TO_TEXT]
        welcome_fields = [item['field'] for item in display_fields if item['field'] not in QPOLL_FIELD_TO_TEXT]
        
        # [ìµœì¢… ìˆ˜ì •] ëª¨ë“  ì»¬ëŸ¼ ë³´ê°• ë¡œì§ì„ _prepare_display_fieldsë¡œ í†µí•©í–ˆìœ¼ë¯€ë¡œ, ì—¬ê¸°ì„œëŠ” ëª¨ë‘ ì œê±°í•©ë‹ˆë‹¤.
        
        db_start = time.time()
        
        # Welcome ë°ì´í„° ì¡°íšŒ
        welcome_table_data = await _get_ordered_welcome_data(ids_to_fetch, welcome_fields)
        
        # QPoll ë°ì´í„° ì¡°íšŒ
        qpoll_responses_map = await _get_qpoll_responses_for_table(ids_to_fetch, qpoll_fields)
        
        # ë°ì´í„° ë³‘í•© (Welcome ë°ì´í„° ìˆœì„œ ìœ ì§€)
        table_data = []
        for welcome_row in welcome_table_data:
            pid = welcome_row.get('panel_id')
            if pid and pid in qpoll_responses_map:
                welcome_row.update(qpoll_responses_map[pid])
            table_data.append(welcome_row)
            
        db_time = time.time() - db_start
        logging.info(f"âœ… [Lite ëª¨ë“œ] í†µí•© í…Œì´ë¸” ë°ì´í„° {len(table_data)}ê°œ ì¡°íšŒ ì™„ë£Œ: {db_time:.2f}ì´ˆ")
        
        # 3. Lite ëª¨ë“œ ìµœì¢… ì‘ë‹µ êµ¬ì„±
        lite_response['tableData'] = table_data
        lite_response['mode'] = "lite" 
        del lite_response['final_panel_ids'] # ID ëª©ë¡ì€ ì‘ë‹µì—ì„œ ì œê±°
        
        total_time = time.time() - start_time
        logging.info(f"âœ… [Lite ëª¨ë“œ] ì „ì²´ ì™„ë£Œ: {total_time:.2f}ì´ˆ - ì´ {lite_response['total_count']}ê°œ ê²°ê³¼ ì¤‘ {len(table_data)}ê°œ í…Œì´ë¸” ë°ì´í„° ë°˜í™˜")
        
        return lite_response
        
    except HTTPException as e:
        raise e
    except Exception as e:
        logging.error(f"[Lite ëª¨ë“œ] /api/search ì‹¤íŒ¨: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")


@app.post("/api/search-and-analyze")
async def search_and_analyze(request: AnalysisRequest):
    """
    ğŸ“Š Pro ëª¨ë“œ: ê²€ìƒ‰ + ì¸ì‚¬ì´íŠ¸ ë¶„ì„ (ì°¨íŠ¸ + í…Œì´ë¸” ë°ì´í„° ë°˜í™˜)
    """
    logging.info(f"ğŸ“Š [Pro ëª¨ë“œ] ê²€ìƒ‰ + ë¶„ì„ ì‹œì‘: {request.query}")
    
    valid_modes = ["all", "weighted", "union", "intersection"]
    if request.search_mode not in valid_modes:
        raise HTTPException(
            status_code=400, 
            detail=f"Invalid search_mode. Must be one of: {valid_modes}"
        )
    
    try:
        # 1. ê³µí†µ ê²€ìƒ‰ í•¨ìˆ˜ í˜¸ì¶œ (mode="pro")
        response, panel_id_list, classification = await _perform_common_search(
            request.query, 
            request.search_mode,
            mode="pro"
        )
        
        display_fields = response.get('display_fields', [])
        
        # [ìµœì¢… ìˆ˜ì •] ëª¨ë“  ì»¬ëŸ¼ ë³´ê°• ë¡œì§ì„ _prepare_display_fieldsë¡œ í†µí•©í–ˆìœ¼ë¯€ë¡œ, ì—¬ê¸°ì„œëŠ” ëª¨ë‘ ì œê±°í•©ë‹ˆë‹¤.
        
        # 2. ì°¨íŠ¸ ë°ì´í„° ìƒì„±
        logging.info("ğŸ“Š [Pro ëª¨ë“œ] ì°¨íŠ¸ ë°ì´í„° ìƒì„± ì‹œì‘")
        analysis_result, status_code = analyze_search_results(
            request.query, 
            classification,
            panel_id_list[:5000] # ë¶„ì„ì€ ìµœëŒ€ 5000ê°œ
        )
        
        if status_code == 200:
            response['charts'] = analysis_result.get('charts', [])
            response['analysis_summary'] = analysis_result.get('main_summary', '')
            logging.info(f"âœ… [Pro ëª¨ë“œ] ì°¨íŠ¸ {len(response['charts'])}ê°œ ìƒì„± ì™„ë£Œ")
        else:
            response['charts'] = []
            response['analysis_summary'] = 'ì°¨íŠ¸ ìƒì„± ì‹¤íŒ¨'
            logging.warning("[Pro ëª¨ë“œ] ì°¨íŠ¸ ìƒì„± ì‹¤íŒ¨")
        
        # 3. Table Data ìƒì„± (ë¦¬íŒ©í† ë§ëœ í•¨ìˆ˜ ì‚¬ìš©)
        logging.info(f"ğŸ“Š [Pro ëª¨ë“œ] Table Data ìƒì„± ì‹œì‘ (íŒ¨ë„ {len(panel_id_list)}ê°œ ëŒ€ìƒ)")
        ids_to_fetch = response['final_panel_ids'] # Pro ëª¨ë“œëŠ” 100ê°œë§Œ
        
        # Welcome ë°ì´í„° ì¡°íšŒ (ì „ì²´ structured_data)
        welcome_table_data = await _get_ordered_welcome_data(ids_to_fetch, fields_to_fetch=None)
        
        # Q-Poll í•„ë“œ ëª©ë¡ ìƒì„± (Pro ëª¨ë“œëŠ” ê²€ìƒ‰ëœ í‚¤ì›Œë“œë§Œ ê°€ì ¸ì˜µë‹ˆë‹¤.)
        qpoll_fields = [
            item['field'] for item in display_fields 
            if item['field'] in QPOLL_FIELD_TO_TEXT
        ]

        # QPoll ë°ì´í„° ì¡°íšŒ
        qpoll_responses_map = await _get_qpoll_responses_for_table(ids_to_fetch, qpoll_fields)

        # ë°ì´í„° ë³‘í•©
        table_data = []
        for welcome_row in welcome_table_data:
            pid = welcome_row.get('panel_id')
            if pid and pid in qpoll_responses_map:
                welcome_row.update(qpoll_responses_map[pid])
            table_data.append(welcome_row)

        # 4. ìµœì¢… ì‘ë‹µ êµ¬ì„±
        response['tableData'] = table_data
        response['mode'] = 'pro'
        
        logging.info(f"âœ… [Pro ëª¨ë“œ] ì°¨íŠ¸ {len(response.get('charts', []))}ê°œ, í†µí•© í…Œì´ë¸” ë°ì´í„° {len(table_data)}ê°œ ìƒì„± ì™„ë£Œ")
        
        return response
        
    except HTTPException as e:
        raise e
    except Exception as e:
        logging.error(f"[Pro ëª¨ë“œ] /api/search-and-analyze ì‹¤íŒ¨: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")


@app.post("/api/debug/classify")
async def debug_classify(search_query: SearchQuery):
    """
    ì§ˆì˜ë¥¼ í‚¤ì›Œë“œë¡œ ë¶„ë¥˜ë§Œ í•˜ê³  ê²°ê³¼ë¥¼ ë°˜í™˜ (ê²€ìƒ‰ì€ ìˆ˜í–‰í•˜ì§€ ì•ŠìŒ)
    """
    try:
        classification = classify_query_keywords(search_query.query)
        return {
            "query": search_query.query,
            "classification": classification
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ë¶„ë¥˜ ì‹¤íŒ¨: {str(e)}")


async def _get_welcome_data(panel_id: str) -> Dict:
    """[ë¦¬íŒ©í† ë§] PostgreSQLì—ì„œ Welcome ë°ì´í„°ë¥¼ ë¹„ë™ê¸°ì ìœ¼ë¡œ ì¡°íšŒí•©ë‹ˆë‹¤."""
    loop = asyncio.get_running_loop()
    
    def db_call():
        with get_db_connection_context() as conn:
            if not conn:
                raise HTTPException(status_code=500, detail="DB ì—°ê²° ì‹¤íŒ¨")
            
            cur = conn.cursor()
            cur.execute(
                "SELECT panel_id, structured_data FROM welcome_meta2 WHERE panel_id = %s",
                (panel_id,)
            )
            result = cur.fetchone()
            cur.close()
            
            if not result:
                raise HTTPException(status_code=404, detail=f"panel_id {panel_id}ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
            panel_id_value, structured_data = result
            panel_data = {"panel_id": panel_id_value}
            if isinstance(structured_data, dict):
                panel_data.update(structured_data)
            return panel_data

    return await loop.run_in_executor(None, db_call)


async def _get_qpoll_data(panel_id: str) -> Dict:
    """[ë¦¬íŒ©í† ë§] Qdrantì—ì„œ QPoll ë°ì´í„°ë¥¼ ë¹„ë™ê¸°ì ìœ¼ë¡œ ì¡°íšŒí•©ë‹ˆë‹¤."""
    loop = asyncio.get_running_loop()
    qpoll_data = {"qpoll_ì‘ë‹µ_ê°œìˆ˜": 0}

    def qdrant_call():
        try:
            qdrant_client = get_qdrant_client()
            if not qdrant_client:
                logging.warning("âš ï¸  Qdrant í´ë¼ì´ì–¸íŠ¸ ì—†ìŒ")
                return qpoll_data

            logging.info(f"ğŸ” QPoll ë°ì´í„° ì¡°íšŒ ì‹œì‘ (panel_id: {panel_id})")
            qpoll_results, _ = qdrant_client.scroll(
                collection_name="qpoll_vectors_v2",
                scroll_filter=Filter(must=[FieldCondition(key="panel_id", match=MatchValue(value=panel_id))]),
                limit=100, with_payload=True, with_vectors=False
            )

            if qpoll_results:
                logging.info(f"âœ… QPoll ì‘ë‹µ {len(qpoll_results)}ê°œ ë°œê²¬")
                for idx, point in enumerate(qpoll_results, 1):
                    if point.payload:
                        qpoll_data[f"qpoll_{idx:03d}_ì§ˆë¬¸"] = point.payload.get("question", "")
                        qpoll_data[f"qpoll_{idx:03d}_ì‘ë‹µ"] = point.payload.get("sentence", "")
                qpoll_data["qpoll_ì‘ë‹µ_ê°œìˆ˜"] = len(qpoll_results)
            else:
                logging.warning("âš ï¸  QPoll ì‘ë‹µ ì—†ìŒ")
            
            return qpoll_data

        except Exception as qpoll_error:
            logging.error(f"âŒ QPoll ì¡°íšŒ ì‹¤íŒ¨ (panel_id: {panel_id}): {qpoll_error}", exc_info=True)
            qpoll_data["qpoll_ì¡°íšŒ_ì˜¤ë¥˜"] = str(qpoll_error)
            return qpoll_data

    return await loop.run_in_executor(None, qdrant_call)


@app.get("/api/panels/{panel_id}")
async def get_panel_details(panel_id: str):
    """
    [ê°œì„ ] íŠ¹ì • panel_idì˜ íŒ¨ë„ ìƒì„¸ ì •ë³´ë¥¼ ë³‘ë ¬ë¡œ ì¡°íšŒí•©ë‹ˆë‹¤.
    - Welcome(PostgreSQL)ê³¼ QPoll(Qdrant) ë°ì´í„°ë¥¼ ë™ì‹œì— ì¡°íšŒí•˜ì—¬ ì„±ëŠ¥ ê°œì„ 
    """
    try:
        logging.info(f"âš¡ï¸ íŒ¨ë„ ìƒì„¸ ì •ë³´ ë³‘ë ¬ ì¡°íšŒ ì‹œì‘ (panel_id: {panel_id})")
        
        # Welcome ë°ì´í„°ì™€ QPoll ë°ì´í„°ë¥¼ ë™ì‹œì— ì¡°íšŒ
        results = await asyncio.gather(
            _get_welcome_data(panel_id),
            _get_qpoll_data(panel_id),
            return_exceptions=True  # í•œìª½ì—ì„œ ì—ëŸ¬ê°€ ë‚˜ë„ ë‹¤ë¥¸ ìª½ì€ ê³„ì† ì§„í–‰
        )

        # ê²°ê³¼ ì·¨í•©
        panel_data, qpoll_data = {}, {}
        for result in results:
            if isinstance(result, HTTPException):
                raise result # 404 Not Found ë“±ì€ ì¦‰ì‹œ ë°˜í™˜
            elif isinstance(result, Exception):
                raise HTTPException(status_code=500, detail=f"ì¡°íšŒ ì¤‘ ë‚´ë¶€ ì˜¤ë¥˜ ë°œìƒ: {result}")
            
            if "qpoll_ì‘ë‹µ_ê°œìˆ˜" in result:
                qpoll_data = result
            else:
                panel_data = result

        panel_data.update(qpoll_data)
        return panel_data
        
    except HTTPException:
        raise
    except Exception as e:
        logging.error(f"íŒ¨ë„ ìƒì„¸ ì¡°íšŒ ì‹¤íŒ¨: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")


@app.get("/")
def read_root():
    return {
        "service": "Multi-Table Hybrid Search & Analysis API",
        "version": "3.0 (Refactored)",
        "status": "running",
        "optimizations_applied": [
            "DB Connection Pool (psycopg2-pool)",
            "Parallel Search (ThreadPoolExecutor)",
            "DB Aggregate Queries (analysis_logic)"
        ],
        "endpoints": {
            "search": "/api/search (Lite)",
            "search_and_analyze": "/api/search-and-analyze (Pro)",
            "classify": "/api/debug/classify",
            "panel_detail": "/api/panels/{panel_id}",
            "health": "/health"
        }
    }

@app.get("/health")
def health_check():
    """ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸"""
    try:
        with get_db_connection_context() as conn:
            db_status = "ok" if conn else "error"
        
        return {
            "status": "healthy",
            "database": db_status
        }
    except Exception as e:
        return {
            "status": "unhealthy",
            "error": str(e)
        }